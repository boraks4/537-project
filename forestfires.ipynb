{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestfires.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boraks4/539-project/blob/main/forestfires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credits to https://stackoverflow.com/a/57539179\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/boraks4/539-project.git'.format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "merjZ6yJcTtX",
        "outputId": "b8793607-e3a6-425a-d49a-96db6d6fd781"
      },
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User name: boraks4\n",
            "Password: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 539-project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dMW3uMDa4bW",
        "outputId": "44fb44e0-6fa5-4049-9d02-055f061a4d80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/539-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "svgckzvrYDhP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = pd.read_csv('forestfires.csv', sep=',', header=0)\n",
        "# TODO: Is this the encoding we want for months, days?\n",
        "fires.month=fires.month.map({'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12})\n",
        "fires.day=fires.day.map({'mon':1,'tue':2,'wed':3,'thu':4,'fri':5,'sat':6,'sun':7}) \n",
        "fires[['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area']] \\\n",
        "  = StandardScaler().fit_transform(fires[['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area']])\n",
        "print(fires)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Iaed6PPYT_R",
        "outputId": "d5b7e74e-a8ac-4395-eee8-067ea800c070"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    7  5      3    5 -0.805959 -1.323326 -1.830477 -0.860946 -1.842640   \n",
            "1    7  4     10    2 -0.008102 -1.179541  0.488891 -0.509688 -0.153278   \n",
            "2    7  4     10    6 -0.008102 -1.049822  0.560715 -0.509688 -0.739383   \n",
            "3    8  6      3    5  0.191362 -1.212361 -1.898266 -0.004756 -1.825402   \n",
            "4    8  6      3    7 -0.243833 -0.931043 -1.798600  0.126966 -1.291012   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "512  4  3      8    7 -1.640083 -0.846648  0.474768 -1.563460  1.536084   \n",
            "513  2  4      8    7 -1.640083 -0.846648  0.474768 -1.563460  0.519019   \n",
            "514  7  4      8    7 -1.640083 -0.846648  0.474768 -1.563460  0.398350   \n",
            "515  1  4      8    6  0.680957  0.549003  0.269382  0.500176  1.156839   \n",
            "516  6  3     11    2 -2.020879 -1.685913 -1.780442 -1.739089 -1.222058   \n",
            "\n",
            "           RH      wind      rain      area  \n",
            "0    0.411724  1.498614 -0.073268 -0.202020  \n",
            "1   -0.692456 -1.741756 -0.073268 -0.202020  \n",
            "2   -0.692456 -1.518282 -0.073268 -0.202020  \n",
            "3    3.233519 -0.009834  0.603155 -0.202020  \n",
            "4    3.356206 -1.238940 -0.073268 -0.202020  \n",
            "..        ...       ...       ...       ...  \n",
            "512 -0.753800 -0.736124 -0.073268 -0.100753  \n",
            "513  1.638592  0.995798 -0.073268  0.651674  \n",
            "514  1.577248  1.498614 -0.073268 -0.026532  \n",
            "515 -0.140366 -0.009834 -0.073268 -0.202020  \n",
            "516 -0.815143  0.269509 -0.073268 -0.202020  \n",
            "\n",
            "[517 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min = fires['area'].min()\n",
        "zeros = fires[fires['area'] == min]\n",
        "zeros = zeros.assign(size=0)\n",
        "\n",
        "no_zeros = fires[fires['area'] != min]\n",
        "no_zeros = no_zeros.assign(size=pd.qcut(no_zeros['area'], 3, labels=[1, 2, 3]))\n",
        "\n",
        "fires_quant = pd.concat([zeros, no_zeros])\n",
        "fires_quant = fires_quant.drop(['area'], axis=1)\n",
        "print(fires_quant)\n",
        "print(fires_quant['size'].value_counts())"
      ],
      "metadata": {
        "id": "PWIF62Np7_Jx",
        "outputId": "4dff3dcf-7517-4304-a66d-76cdac233f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    7  5      3    5 -0.805959 -1.323326 -1.830477 -0.860946 -1.842640   \n",
            "1    7  4     10    2 -0.008102 -1.179541  0.488891 -0.509688 -0.153278   \n",
            "2    7  4     10    6 -0.008102 -1.049822  0.560715 -0.509688 -0.739383   \n",
            "3    8  6      3    5  0.191362 -1.212361 -1.898266 -0.004756 -1.825402   \n",
            "4    8  6      3    7 -0.243833 -0.931043 -1.798600  0.126966 -1.291012   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "509  5  4      8    5  0.064430  0.875644  0.825821 -0.421874  0.381112   \n",
            "510  6  5      8    5  0.064430  0.875644  0.825821 -0.421874 -0.118801   \n",
            "512  4  3      8    7 -1.640083 -0.846648  0.474768 -1.563460  1.536084   \n",
            "513  2  4      8    7 -1.640083 -0.846648  0.474768 -1.563460  0.519019   \n",
            "514  7  4      8    7 -1.640083 -0.846648  0.474768 -1.563460  0.398350   \n",
            "\n",
            "           RH      wind      rain  size  \n",
            "0    0.411724  1.498614 -0.073268     0  \n",
            "1   -0.692456 -1.741756 -0.073268     0  \n",
            "2   -0.692456 -1.518282 -0.073268     0  \n",
            "3    3.233519 -0.009834  0.603155     0  \n",
            "4    3.356206 -1.238940 -0.073268     0  \n",
            "..        ...       ...       ...   ...  \n",
            "509  1.638592  2.001430  4.661696     1  \n",
            "510  1.086501  0.772325 -0.073268     1  \n",
            "512 -0.753800 -0.736124 -0.073268     2  \n",
            "513  1.638592  0.995798 -0.073268     3  \n",
            "514  1.577248  1.498614 -0.073268     3  \n",
            "\n",
            "[517 rows x 13 columns]\n",
            "0    247\n",
            "1     90\n",
            "2     90\n",
            "3     90\n",
            "Name: size, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# label = []\n",
        "# for a in fires['area']:\n",
        "#   if a > 50:\n",
        "#     label.append(3) # 'catastrophic'\n",
        "#   elif a > 10: \n",
        "#     label.append(2) # 'large'\n",
        "#   elif a > 0:\n",
        "#     label.append(1) # 'medium'\n",
        "#   else:\n",
        "#     label.append(0) # 'small'\n",
        "# fires['classification'] = label\n",
        "# fires = fires.drop(['area'], axis=1)\n",
        "# pd.options.display.max_columns = len(fires.columns)\n",
        "# pd.options.display.width = 100\n",
        "# print(fires)\n"
      ],
      "metadata": {
        "id": "kopGlpGvv5kJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paste in hw8 solution"
      ],
      "metadata": {
        "id": "S7v1o-A_BazT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7rx1rzqy25o"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = fires_quant.iloc[:,:-1]\n",
        "print(X)\n",
        "y = fires_quant.iloc[:,-1]\n"
      ],
      "metadata": {
        "id": "KuYJ7JkDDMK6",
        "outputId": "3ae843f8-f0cd-469b-d169-18f7004f6585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    7  5      3    5 -0.805959 -1.323326 -1.830477 -0.860946 -1.842640   \n",
            "1    7  4     10    2 -0.008102 -1.179541  0.488891 -0.509688 -0.153278   \n",
            "2    7  4     10    6 -0.008102 -1.049822  0.560715 -0.509688 -0.739383   \n",
            "3    8  6      3    5  0.191362 -1.212361 -1.898266 -0.004756 -1.825402   \n",
            "4    8  6      3    7 -0.243833 -0.931043 -1.798600  0.126966 -1.291012   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "509  5  4      8    5  0.064430  0.875644  0.825821 -0.421874  0.381112   \n",
            "510  6  5      8    5  0.064430  0.875644  0.825821 -0.421874 -0.118801   \n",
            "512  4  3      8    7 -1.640083 -0.846648  0.474768 -1.563460  1.536084   \n",
            "513  2  4      8    7 -1.640083 -0.846648  0.474768 -1.563460  0.519019   \n",
            "514  7  4      8    7 -1.640083 -0.846648  0.474768 -1.563460  0.398350   \n",
            "\n",
            "           RH      wind      rain  \n",
            "0    0.411724  1.498614 -0.073268  \n",
            "1   -0.692456 -1.741756 -0.073268  \n",
            "2   -0.692456 -1.518282 -0.073268  \n",
            "3    3.233519 -0.009834  0.603155  \n",
            "4    3.356206 -1.238940 -0.073268  \n",
            "..        ...       ...       ...  \n",
            "509  1.638592  2.001430  4.661696  \n",
            "510  1.086501  0.772325 -0.073268  \n",
            "512 -0.753800 -0.736124 -0.073268  \n",
            "513  1.638592  0.995798 -0.073268  \n",
            "514  1.577248  1.498614 -0.073268  \n",
            "\n",
            "[517 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "unnecessary, already one-hot starting with 0\n",
        "cats = np.unique(y)\n",
        "# reformmat y label so starts at 0 for one-hot encoding\n",
        "y = y - cats[0]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "W47hS7daDQId",
        "outputId": "43de6622-9d55-49bf-9576-2f0dd1dce669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nunnecessary, already one-hot starting with 0\\ncats = np.unique(y)\\n# reformmat y label so starts at 0 for one-hot encoding\\ny = y - cats[0]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# hyperparameters\n",
        "\n",
        "# splitting data\n",
        "splits = (.6,.2,.2) # train, test, validatate at 60/20/20 division\n",
        "rand_state = 0\n",
        "\n",
        "# optimizer\n",
        "lr = 0.001\n",
        "\n",
        "# model creation\n",
        "num_hidden_layers = 1\n",
        "neurons_per_hidden_layer = 4\n",
        "\n",
        "# model trainin\n",
        "num_epochs = 1000\n"
      ],
      "metadata": {
        "id": "nzrcaQTpH4qv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/55119651/downsampling-for-more-than-2-classes\n",
        "def downsample(X, y, label):\n",
        "  data = pd.concat([X, y], axis=1)\n",
        "  g = data.groupby(label, group_keys=False)\n",
        "  balanced = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()))).reset_index(drop=True)\n",
        "  return balanced.iloc[:, :-1], balanced.iloc[:, -1]\n",
        "\n",
        "def pipeline(X, y, label):\n",
        "  X, y = downsample(X, y, label)\n",
        "  return X, pd.get_dummies(y, prefix=label)\n",
        "\n",
        "# make one-hot\n",
        "y_oh = pd.get_dummies(y, prefix='size')\n",
        "\n",
        "# partition into train, validate, test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=splits[0], random_state=rand_state, shuffle=True, stratify=y_oh)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, train_size=(splits[1] / (splits[1] + splits[2])), random_state=rand_state, shuffle=True, stratify=y_temp)\n",
        "\n",
        "label='size'\n",
        "\n",
        "X_train, y_train = pipeline(X_train, y_train, 'size')\n",
        "X_test, y_test = pipeline(X_test, y_test, 'size')\n",
        "X_val, y_val = pipeline(X_val, y_val, 'size')\n",
        "\n",
        "batch_size = math.floor(X_train.shape[0] / 10)\n",
        "print(batch_size)"
      ],
      "metadata": {
        "id": "jlB1FP7kDRWI",
        "outputId": "f8b41d78-3cd2-4065-9965-2b2a08a0da08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    4  6      3    7 -0.243833 -0.931043 -1.798600  0.126966 -1.428919   \n",
            "1    1  3      8    4  0.753489  1.743042  0.607926  1.070970  1.260269   \n",
            "2    1  3      3    1 -0.552096 -0.916977 -1.792143 -0.882899 -1.825402   \n",
            "3    6  3      9    1 -0.370765 -0.298077  0.653522 -0.421874 -1.325489   \n",
            "4    8  5     10    1 -1.041690 -1.220176  0.469119 -1.321971 -0.377377   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "211  4  4      8    2  0.807889  0.475547  0.233470  1.905206  0.088059   \n",
            "212  3  4      8    2  0.989220  1.097573  0.497365  1.158784  2.311811   \n",
            "213  6  5      3    7 -0.098768 -1.145157 -1.873249 -0.399920 -1.118628   \n",
            "214  2  2      9    6  0.336427  0.159846  0.510277 -0.092570 -0.118801   \n",
            "215  6  5      4    4 -1.658216 -1.590578 -1.988249 -1.387832 -2.256361   \n",
            "\n",
            "           RH      wind      rain  \n",
            "0    0.105008  0.492982 -0.073268  \n",
            "1   -0.631113  0.995798 -0.073268  \n",
            "2    1.699935 -0.512650 -0.073268  \n",
            "3    2.067995  2.001430 -0.073268  \n",
            "4    0.166351  0.492982 -0.073268  \n",
            "..        ...       ...       ...  \n",
            "211  1.638592  2.001430 -0.073268  \n",
            "212 -1.060516 -1.015466 -0.073268  \n",
            "213  0.595754 -0.233308 -0.073268  \n",
            "214  0.105008 -1.238940 -0.073268  \n",
            "215  0.595754  0.995798 -0.073268  \n",
            "\n",
            "[216 rows x 12 columns]\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "id": "47OG36GcDSHu",
        "outputId": "e5f8c28f-a5da-4ba2-fb38-dfa4907617c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 12)\n",
            "(72, 12)\n",
            "(72, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Preprocessing - normaization?"
      ],
      "metadata": {
        "id": "00mPJfUPRYUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X.shape[1]\n",
        "num_classes = 4\n",
        "# define the keras model\n",
        "# N_input - neurons_per_hidden_layer - N_labels configuration, relu and sigmoid activation for the \n",
        "# hidden layer and output layer respectively\n",
        "\n",
        "#TODO: dynamic number of layers :)\n",
        "net = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=neurons_per_hidden_layer, input_dim=input_dim, activation = 'relu'), # input layer\n",
        "     tf.keras.layers.Dense(units=neurons_per_hidden_layer, activation = 'relu'), # deep layer\n",
        "    tf.keras.layers.Dense(units=num_classes, activation='softmax') # output layer\n",
        "    ])"
      ],
      "metadata": {
        "id": "Cc9wmG7KDTox"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the keras model\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr\n",
        ")\n",
        "\n",
        "net.compile(loss='CategoricalCrossentropy', optimizer=opt, \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QPzedSr2DUmS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the keras model on the dataset\n",
        "history = net.fit(X_train, y_train, epochs=num_epochs, verbose=1, batch_size=batch_size, validation_data=(X_val,y_val))"
      ],
      "metadata": {
        "id": "UM01KzR6QF_3",
        "outputId": "37f87667-9ba4-45b2-a9c5-557fccc8627b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "11/11 [==============================] - 1s 37ms/step - loss: 2.1181 - accuracy: 0.2407 - val_loss: 2.0522 - val_accuracy: 0.2500\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.9524 - accuracy: 0.2222 - val_loss: 1.8873 - val_accuracy: 0.2361\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.8161 - accuracy: 0.2315 - val_loss: 1.7735 - val_accuracy: 0.2500\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7195 - accuracy: 0.2407 - val_loss: 1.6909 - val_accuracy: 0.2500\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.6445 - accuracy: 0.2315 - val_loss: 1.6292 - val_accuracy: 0.3056\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5840 - accuracy: 0.2315 - val_loss: 1.5834 - val_accuracy: 0.3056\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5375 - accuracy: 0.2361 - val_loss: 1.5515 - val_accuracy: 0.2500\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 1.5024 - accuracy: 0.2454 - val_loss: 1.5216 - val_accuracy: 0.2639\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 1.4779 - accuracy: 0.2454 - val_loss: 1.4947 - val_accuracy: 0.2778\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 1.4559 - accuracy: 0.2407 - val_loss: 1.4791 - val_accuracy: 0.2778\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.4420 - accuracy: 0.2500 - val_loss: 1.4675 - val_accuracy: 0.2778\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4293 - accuracy: 0.2639 - val_loss: 1.4569 - val_accuracy: 0.2778\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4203 - accuracy: 0.2639 - val_loss: 1.4488 - val_accuracy: 0.2639\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.4135 - accuracy: 0.2685 - val_loss: 1.4433 - val_accuracy: 0.2361\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.4075 - accuracy: 0.2870 - val_loss: 1.4396 - val_accuracy: 0.2500\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4027 - accuracy: 0.2870 - val_loss: 1.4365 - val_accuracy: 0.2500\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3984 - accuracy: 0.2731 - val_loss: 1.4347 - val_accuracy: 0.2500\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3949 - accuracy: 0.2685 - val_loss: 1.4324 - val_accuracy: 0.2917\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3919 - accuracy: 0.2593 - val_loss: 1.4314 - val_accuracy: 0.2917\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3891 - accuracy: 0.2546 - val_loss: 1.4288 - val_accuracy: 0.2778\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3866 - accuracy: 0.2500 - val_loss: 1.4271 - val_accuracy: 0.2917\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3836 - accuracy: 0.2685 - val_loss: 1.4258 - val_accuracy: 0.2917\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3814 - accuracy: 0.2731 - val_loss: 1.4254 - val_accuracy: 0.2917\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3796 - accuracy: 0.2685 - val_loss: 1.4243 - val_accuracy: 0.3056\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3775 - accuracy: 0.2685 - val_loss: 1.4238 - val_accuracy: 0.3056\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3751 - accuracy: 0.2593 - val_loss: 1.4237 - val_accuracy: 0.3194\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3721 - accuracy: 0.2685 - val_loss: 1.4225 - val_accuracy: 0.2778\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3690 - accuracy: 0.2731 - val_loss: 1.4218 - val_accuracy: 0.2639\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3642 - accuracy: 0.3009 - val_loss: 1.4220 - val_accuracy: 0.2778\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3613 - accuracy: 0.3148 - val_loss: 1.4209 - val_accuracy: 0.2917\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3590 - accuracy: 0.3241 - val_loss: 1.4198 - val_accuracy: 0.2778\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3575 - accuracy: 0.3380 - val_loss: 1.4193 - val_accuracy: 0.2500\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3561 - accuracy: 0.3241 - val_loss: 1.4191 - val_accuracy: 0.2639\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3553 - accuracy: 0.3194 - val_loss: 1.4211 - val_accuracy: 0.2778\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3537 - accuracy: 0.3287 - val_loss: 1.4231 - val_accuracy: 0.2917\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3528 - accuracy: 0.3426 - val_loss: 1.4237 - val_accuracy: 0.2917\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3517 - accuracy: 0.3380 - val_loss: 1.4252 - val_accuracy: 0.2639\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3503 - accuracy: 0.3380 - val_loss: 1.4254 - val_accuracy: 0.2639\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3500 - accuracy: 0.3472 - val_loss: 1.4229 - val_accuracy: 0.2917\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3486 - accuracy: 0.3611 - val_loss: 1.4240 - val_accuracy: 0.3056\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3477 - accuracy: 0.3704 - val_loss: 1.4266 - val_accuracy: 0.2778\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3475 - accuracy: 0.3472 - val_loss: 1.4248 - val_accuracy: 0.2917\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3466 - accuracy: 0.3657 - val_loss: 1.4242 - val_accuracy: 0.2639\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3457 - accuracy: 0.3611 - val_loss: 1.4259 - val_accuracy: 0.2778\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3447 - accuracy: 0.3565 - val_loss: 1.4237 - val_accuracy: 0.3056\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3452 - accuracy: 0.3565 - val_loss: 1.4227 - val_accuracy: 0.2778\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3449 - accuracy: 0.3426 - val_loss: 1.4257 - val_accuracy: 0.3056\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3437 - accuracy: 0.3611 - val_loss: 1.4242 - val_accuracy: 0.2917\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3428 - accuracy: 0.3472 - val_loss: 1.4260 - val_accuracy: 0.2917\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3415 - accuracy: 0.3472 - val_loss: 1.4290 - val_accuracy: 0.2778\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3419 - accuracy: 0.3241 - val_loss: 1.4281 - val_accuracy: 0.2917\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3398 - accuracy: 0.3380 - val_loss: 1.4294 - val_accuracy: 0.2778\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3395 - accuracy: 0.3333 - val_loss: 1.4283 - val_accuracy: 0.2917\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3388 - accuracy: 0.3426 - val_loss: 1.4292 - val_accuracy: 0.2778\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3395 - accuracy: 0.3380 - val_loss: 1.4344 - val_accuracy: 0.2917\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3383 - accuracy: 0.3426 - val_loss: 1.4319 - val_accuracy: 0.2778\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3368 - accuracy: 0.3426 - val_loss: 1.4304 - val_accuracy: 0.2778\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3366 - accuracy: 0.3333 - val_loss: 1.4309 - val_accuracy: 0.2639\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3358 - accuracy: 0.3519 - val_loss: 1.4327 - val_accuracy: 0.2639\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3351 - accuracy: 0.3333 - val_loss: 1.4328 - val_accuracy: 0.2778\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3351 - accuracy: 0.3380 - val_loss: 1.4341 - val_accuracy: 0.2639\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3343 - accuracy: 0.3241 - val_loss: 1.4335 - val_accuracy: 0.2500\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3336 - accuracy: 0.3287 - val_loss: 1.4341 - val_accuracy: 0.2500\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3330 - accuracy: 0.3333 - val_loss: 1.4352 - val_accuracy: 0.2500\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3326 - accuracy: 0.3287 - val_loss: 1.4334 - val_accuracy: 0.2361\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3326 - accuracy: 0.3380 - val_loss: 1.4298 - val_accuracy: 0.3056\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3335 - accuracy: 0.3426 - val_loss: 1.4314 - val_accuracy: 0.2222\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3314 - accuracy: 0.3333 - val_loss: 1.4393 - val_accuracy: 0.2778\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3309 - accuracy: 0.3519 - val_loss: 1.4393 - val_accuracy: 0.2222\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3305 - accuracy: 0.3426 - val_loss: 1.4406 - val_accuracy: 0.2361\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3295 - accuracy: 0.3380 - val_loss: 1.4409 - val_accuracy: 0.2361\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3287 - accuracy: 0.3333 - val_loss: 1.4404 - val_accuracy: 0.2222\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3288 - accuracy: 0.3380 - val_loss: 1.4391 - val_accuracy: 0.2500\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3277 - accuracy: 0.3472 - val_loss: 1.4430 - val_accuracy: 0.2361\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3282 - accuracy: 0.3380 - val_loss: 1.4411 - val_accuracy: 0.2361\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3260 - accuracy: 0.3472 - val_loss: 1.4433 - val_accuracy: 0.2222\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3261 - accuracy: 0.3380 - val_loss: 1.4442 - val_accuracy: 0.2361\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3251 - accuracy: 0.3380 - val_loss: 1.4425 - val_accuracy: 0.2361\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3247 - accuracy: 0.3426 - val_loss: 1.4443 - val_accuracy: 0.2222\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3245 - accuracy: 0.3565 - val_loss: 1.4408 - val_accuracy: 0.2500\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3238 - accuracy: 0.3657 - val_loss: 1.4437 - val_accuracy: 0.2500\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3229 - accuracy: 0.3472 - val_loss: 1.4458 - val_accuracy: 0.2500\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3234 - accuracy: 0.3472 - val_loss: 1.4456 - val_accuracy: 0.2500\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3217 - accuracy: 0.3565 - val_loss: 1.4488 - val_accuracy: 0.2361\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3219 - accuracy: 0.3426 - val_loss: 1.4461 - val_accuracy: 0.2639\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3210 - accuracy: 0.3472 - val_loss: 1.4497 - val_accuracy: 0.2639\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3210 - accuracy: 0.3519 - val_loss: 1.4525 - val_accuracy: 0.2361\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3194 - accuracy: 0.3472 - val_loss: 1.4519 - val_accuracy: 0.2500\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3193 - accuracy: 0.3426 - val_loss: 1.4514 - val_accuracy: 0.2639\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3186 - accuracy: 0.3565 - val_loss: 1.4553 - val_accuracy: 0.2639\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3175 - accuracy: 0.3565 - val_loss: 1.4568 - val_accuracy: 0.2500\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3170 - accuracy: 0.3611 - val_loss: 1.4556 - val_accuracy: 0.2778\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3163 - accuracy: 0.3704 - val_loss: 1.4561 - val_accuracy: 0.2778\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3172 - accuracy: 0.3611 - val_loss: 1.4586 - val_accuracy: 0.2778\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3153 - accuracy: 0.3611 - val_loss: 1.4593 - val_accuracy: 0.2778\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3145 - accuracy: 0.3704 - val_loss: 1.4621 - val_accuracy: 0.2778\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3142 - accuracy: 0.3657 - val_loss: 1.4644 - val_accuracy: 0.2778\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3136 - accuracy: 0.3843 - val_loss: 1.4595 - val_accuracy: 0.2778\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3129 - accuracy: 0.3750 - val_loss: 1.4629 - val_accuracy: 0.2361\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3130 - accuracy: 0.3611 - val_loss: 1.4670 - val_accuracy: 0.2361\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3114 - accuracy: 0.3611 - val_loss: 1.4666 - val_accuracy: 0.2500\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3114 - accuracy: 0.3519 - val_loss: 1.4703 - val_accuracy: 0.2500\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3110 - accuracy: 0.3611 - val_loss: 1.4677 - val_accuracy: 0.2222\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3097 - accuracy: 0.3611 - val_loss: 1.4718 - val_accuracy: 0.2361\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3104 - accuracy: 0.3657 - val_loss: 1.4770 - val_accuracy: 0.2639\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3089 - accuracy: 0.3657 - val_loss: 1.4728 - val_accuracy: 0.2500\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3074 - accuracy: 0.3704 - val_loss: 1.4701 - val_accuracy: 0.2361\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3082 - accuracy: 0.3796 - val_loss: 1.4658 - val_accuracy: 0.2361\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3071 - accuracy: 0.3843 - val_loss: 1.4664 - val_accuracy: 0.2500\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3081 - accuracy: 0.3796 - val_loss: 1.4679 - val_accuracy: 0.2361\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3068 - accuracy: 0.3750 - val_loss: 1.4668 - val_accuracy: 0.2361\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3048 - accuracy: 0.3843 - val_loss: 1.4737 - val_accuracy: 0.2361\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3048 - accuracy: 0.3843 - val_loss: 1.4724 - val_accuracy: 0.2500\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3034 - accuracy: 0.3889 - val_loss: 1.4761 - val_accuracy: 0.2222\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3022 - accuracy: 0.3843 - val_loss: 1.4792 - val_accuracy: 0.2639\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3021 - accuracy: 0.3889 - val_loss: 1.4776 - val_accuracy: 0.2222\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3009 - accuracy: 0.3843 - val_loss: 1.4793 - val_accuracy: 0.2222\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3012 - accuracy: 0.3796 - val_loss: 1.4862 - val_accuracy: 0.2361\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3000 - accuracy: 0.3935 - val_loss: 1.4842 - val_accuracy: 0.2500\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2995 - accuracy: 0.3843 - val_loss: 1.4867 - val_accuracy: 0.2500\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2993 - accuracy: 0.3889 - val_loss: 1.4818 - val_accuracy: 0.2500\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2977 - accuracy: 0.4120 - val_loss: 1.4900 - val_accuracy: 0.2639\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2975 - accuracy: 0.4120 - val_loss: 1.4846 - val_accuracy: 0.2500\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.2961 - accuracy: 0.4120 - val_loss: 1.4871 - val_accuracy: 0.2500\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2952 - accuracy: 0.4167 - val_loss: 1.4848 - val_accuracy: 0.2361\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2939 - accuracy: 0.4120 - val_loss: 1.4879 - val_accuracy: 0.2639\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.2926 - accuracy: 0.4120 - val_loss: 1.4928 - val_accuracy: 0.2778\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2934 - accuracy: 0.4167 - val_loss: 1.4916 - val_accuracy: 0.2639\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2920 - accuracy: 0.4213 - val_loss: 1.4882 - val_accuracy: 0.2639\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2911 - accuracy: 0.4120 - val_loss: 1.4900 - val_accuracy: 0.2778\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2898 - accuracy: 0.4167 - val_loss: 1.4953 - val_accuracy: 0.2778\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.2900 - accuracy: 0.4120 - val_loss: 1.4947 - val_accuracy: 0.2778\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.2885 - accuracy: 0.4167 - val_loss: 1.4927 - val_accuracy: 0.2639\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2891 - accuracy: 0.4213 - val_loss: 1.4962 - val_accuracy: 0.2917\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2879 - accuracy: 0.4213 - val_loss: 1.4943 - val_accuracy: 0.2778\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2865 - accuracy: 0.4213 - val_loss: 1.4944 - val_accuracy: 0.2917\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2860 - accuracy: 0.4259 - val_loss: 1.4955 - val_accuracy: 0.2917\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2866 - accuracy: 0.4259 - val_loss: 1.5006 - val_accuracy: 0.2917\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2854 - accuracy: 0.4167 - val_loss: 1.4931 - val_accuracy: 0.2778\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2855 - accuracy: 0.4167 - val_loss: 1.5015 - val_accuracy: 0.2917\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2842 - accuracy: 0.4167 - val_loss: 1.5014 - val_accuracy: 0.2917\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2822 - accuracy: 0.4120 - val_loss: 1.5054 - val_accuracy: 0.2917\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2828 - accuracy: 0.4306 - val_loss: 1.5044 - val_accuracy: 0.2917\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2827 - accuracy: 0.4120 - val_loss: 1.5004 - val_accuracy: 0.2778\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2823 - accuracy: 0.4352 - val_loss: 1.5027 - val_accuracy: 0.3194\n",
            "Epoch 146/1000\n",
            " 1/11 [=>............................] - ETA: 0s - loss: 1.2559 - accuracy: 0.5714"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5ad36129b415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the keras model on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3316\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can visualize the results with a confusion matrix.\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_confusion_matrix(y_classified, y_true):\n",
        "  # Compute confusion matrix\n",
        "  c_mat = np.zeros((num_classes,num_classes))\n",
        "  for i in range(len(y_true)):\n",
        "    c_mat[y_classified[i], y_true[i] ] += 1\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in c_mat.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in c_mat.flatten()/np.sum(c_mat)]\n",
        "  labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  labels = np.asarray(labels).reshape(c_mat.shape[0], c_mat.shape[1])\n",
        "\n",
        "  plt.figure(figsize=(12,10))\n",
        "  sn.heatmap(c_mat, annot=labels, fmt='', cmap='rocket_r')\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.ylabel('Output Class')\n",
        "  plt.xlabel('Target Class')"
      ],
      "metadata": {
        "id": "O91LTNFgDXOn"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the trained model using keras built-in function\n",
        "score = net.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1]) \n",
        "\n",
        "y_classified = np.argmax(net.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test.to_numpy(), axis=1)\n",
        "# plot confusion matrix\n",
        "plot_confusion_matrix(y_classified, y_true)"
      ],
      "metadata": {
        "id": "01q6CPi0DYZd",
        "outputId": "5e5ba59a-33d3-4dc0-d27a-448ec120db6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5496 - accuracy: 0.1806\n",
            "Test loss: 1.5495566129684448\n",
            "Test accuracy: 0.1805555522441864\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApUAAAJcCAYAAACotl/bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hU1dbH8d+aSSeU0BGkCopgLyCCDTti7w0r6lXsXdSLXfF6bVjAglTba0PsKFjxCoqggKD0HkogkDqZ/f4xY0xgAiFhzkwm38/zzEPmzDln1uYeuStrN3POCQAAAKgOX6wDAAAAQM1HUgkAAIBqI6kEAABAtZFUAgAAoNpIKgEAAFBtJJUAAACoNpJKAFFhZulmNs7M1pvZW9W4z3lm9tmOjC0WzOxjM+sX6zgAIFpIKoFazszONbMpZrbRzJaHk5+eO+DWp0tqJqmRc+6Mqt7EOTfaOXf0DoinHDM7zMycmb272fG9wscnVvI+/zazUds6zzl3nHPutSqGCwBxj6QSqMXM7EZJT0p6SKEEsLWk5ySdtANu30bSHOdcYAfcK1qyJR1kZo3KHOsnac6O+gIL4d9aAAmPf+iAWsrM6ku6T9LVzrl3nHObnHPFzrlxzrlbwuekmtmTZrYs/HrSzFLDnx1mZkvM7CYzWxWucl4c/myQpHsknRWugF66eUXPzNqGK4JJ4fcXmdk8M8s1s/lmdl6Z49+Wua6Hmf0U7lb/ycx6lPlsopndb2bfhe/zmZk13spfQ5Gk9ySdHb7eL+ksSaM3+7t6yswWm9kGM5tqZr3Cx4+VdGeZdv5aJo4Hzew7SXmS2oePXRb+/Hkz+78y93/UzCaYmVX6f0AAiDMklUDtdZCkNEnvbuWcuyR1l7S3pL0kHShpYJnPm0uqL6mlpEslDTGzLOfcvQpVP99wzmU6517eWiBmVkfS05KOc87VldRD0rQI5zWUND58biNJT0gav1ml8VxJF0tqKilF0s1b+25JIyRdGP75GEm/SVq22Tk/KfR30FDSGElvmVmac+6Tzdq5V5lrLpDUX1JdSQs3u99NkvYIJ8y9FPq76+fYNxdADUZSCdRejSSt3kb39HmS7nPOrXLOZUsapFCy9Lfi8OfFzrmPJG2UtGsV4wlK6mpm6c655c653yOc00fSXOfcSOdcwDk3VtJsSX3LnPOqc26Ocy5f0psKJYMVcs59L6mhme2qUHI5IsI5o5xza8Lf+R9Jqdp2O4c7534PX1O82f3yFPp7fELSKEkDnHNLtnE/AIhrJJVA7bVGUuO/u58rsJPKV9kWho+V3mOzpDRPUub2BuKc26RQt/OVkpab2Xgz260S8fwdU8sy71dUIZ6Rkq6RdLgiVG7N7GYzmxXucs9RqDq7tW51SVq8tQ+dcz9KmifJFEp+AaBGI6kEaq8fJBVKOnkr5yxTaMLN31pry67hytokKaPM++ZlP3TOfeqcO0pSC4Wqj8MqEc/fMS2tYkx/GynpX5I+ClcRS4W7p2+VdKakLOdcA0nrFUoGJamiLuutdmWb2dUKVTyXhe8PADUaSSVQSznn1is0mWaImZ1sZhlmlmxmx5nZY+HTxkoaaGZNwhNe7lGou7Yqpkk6xMxahycJ3fH3B2bWzMxOCo+tLFSoGz0Y4R4fSeoUXgYpyczOkrS7pA+rGJMkyTk3X9KhCo0h3VxdSQGFZoonmdk9kuqV+XylpLbbM8PbzDpJekDS+Qp1g99qZlvtpgeAeEdSCdRi4fGBNyo0+SZboS7baxSaES2FEp8pkqZLmiHp5/CxqnzX55LeCN9rqsongr5wHMskrVUowbsqwj3WSDpBoYkuaxSq8J3gnFtdlZg2u/e3zrlIVdhPJX2i0DJDCyUVqHzX9t8Lu68xs5+39T3h4QajJD3qnPvVOTdXoRnkI/+eWQ8ANZEx2RAAAADVRaUSAAAA1UZSCQAAUIuZ2SvhTSx+K3NssJnNNrPpZvaumTXY1n1IKgEAAGq34ZKO3ezY55K6Ouf2VGhM+R2bX7Q5kkoAAIBazDn3tUKTJMse+6zMOsSTJbXa1n22tuhxTC096AhmEGELmbvxexC21Gj0rFiHgDgzqMVhsQ4BcequhaNt22dFV1JKS09znJLiZVcotG3s34Y654Zuxy0uUWj1jq2K26QSAAAA1RdOILcniSxlZncptFbv6G2dS1IJAACALZjZRQqtDdzbVWINSpJKAAAAD8W8/70SzOxYhTaYOHTz7WsrwgA1AACAWszMxkr6QdKuZrbEzC6V9KxC29R+bmbTzOyFbd2HSiUAAICHzOKrVumcOyfC4Ze39z5UKgEAAFBtVCoBAAA8FG+Vyh2FSiUAAACqjUolAACAh6xGzP/eflQqAQAAUG1UKgEAADzEmEoAAACgAlQqAQAAPOSjUgkAAABERlIJAACAaqP7GwAAwEMsKQQAAABUgEolAACAh5ioAwAAAFSASiUAAICHWPwcAAAAqACVSgAAAA/5mP0NAAAAREalEgAAwEOMqQQAAAAqQKUSAADAQ6xTCQAAAFSASiUAAICHGFMJAAAAVIBKJQAAgIdYpxIAAACoAEklAAAAqo3ubwAAAA8xUQcAAACoAJVKAAAADxkTdQAAAIDIqFQCAAB4iG0aAQAAgApQqQQAAPAQs78BAACAClCpBAAA8BDbNAIAAAAVoFIJAADgIcZUAgAAABWgUgkAAOAhxlQCAAAAFaBSCQAA4CGzxKzpJWarAAAA4CmSSgAAAFQb3d8AAAAeMibqAAAAAJFRqQQAAPCQj8XPAQAAgMioVAIAAHiIMZUAAABABahUAgAAeIgxlQAAAEAFqFTGuWbvjJHLy5MrCUolJcq+5KpYh4R4YD5l3vucgutWK++pgbGOBjEybOh/1Of4I7Uqe7X23qe3JOnRhweqzwlHqaioSPPmLdSll92o9es3xDhSxMqBlx6rvc8+XM45Zc9erHG3DFVJYXGsw6r1GFOJmFl99Y3K7tefhBKlUo46RSXLF8U6DMTYiBFvqs8J55U79sWEr7XX3kdo3/2O0ty583T7bdfEKDrEWt1mWTrg4mP0ygkDNezo22V+n7r0PSjWYSGBkVQCNYxlNVbyXt1U9PVHsQ4FMfbNtz9q7bqccsc+/+JrlZSUSJIm//izWrZsEYvQECd8fr+S0lJkfp+S01OVu3JdrEOCQmMqvXx5he7veOecGj01WHJOm94bp7z3x8c6IsRY+jn/Uv6bw2RpGbEOBXHu4ovO1ptvfRDrMBAjuSvXafLQ8Rrww9MqLijS/G9maP43M2IdFhIYSWWcy77yOgWzV8uX1UCNnxqswMLFKpo2PdZhIUaS9uqmYG6Oggvnyr/rXrEOB3HsjtuvVSAQ0Jgx78Q6FMRIWr0MdTp6Pw3peb0KNuTp1OeuVddTDtZv734X69BqPcZUIiaC2atDf67LUf6kb5Wy+24xjgix5O/YVcl7H6S6g0cp46q7lNR5b6X3vz3WYSHOXHjBmepz/JG64ELGU9ZmbXt2Vc7ibOWtzVUwUKI/PvlJrfbrGOuwkMCoVMYxS0uTfCaXly9LS1Nqt/2V+8qIWIeFGCp8+2UVvv2yJMm/615KPfYM5Q99JMZRIZ4cc/Rhuvnmq3RE79OUn18Q63AQQxuWrVHLfXZRUlqKAgVFantwFy2fMT/WYUGJu04lSWUc8zXMUqNH7gu98fuV99kEFU7+KbZBAYgbo0YO0aGHHKTGjRtqwbwpGnTf47rt1muUmpqqTz5+XZL0448/6+prqGbXRsum/aXZH/1Pl45/UMGSEq38faF+GfNlrMNCAjPnXKxjiGjpQUfEZ2CIqczdGLGBLTUaPSvWISDODGpxWKxDQJy6a+HomJcJ92x+kKc5zvQVP3jS5qhVKs1sN0knSWoZPrRU0gfOOf71BwAAtRYTdbaDmd0m6XVJJul/4ZdJGmtmFfbDmFl/M5tiZlNGrVwWjdAAAAAQBdGqVF4qqYtzrtxeUGb2hKTfJUWcWeCcGyppqET3NwAASEw+KpXbJShppwjHW4Q/q5Uss44aPnivmr4+XE3HvqqUrruX/7xupho+cp+ajhymJi8/p6T2bcvfwOdTk9deVKPHHyw9lPXvO9V05DDVu/LS0mN1LzpfaYccHM2mYAeqO3iUMu8fpsxBL6jOPUO2+Ny/616qN+R9ZQ56QZmDXlDqief/82F6HWX86x5lPvSKMh98Wf4OnSVJaWdcpsz7hir9sttKT00+qLdSjjo16u1B1Qwb+h8tW/Krpv0yodzxq/91sX6bMUm/TvtSjzx8V8Rr69evpzdeH6rfZkzSjOkT1b3bfpKkMaOf15SfPtOUnz7Tn3Mma8pPn0mSehy0v36e+rkm//CRdtmlXek9Ph4/Rpags1JrqhMGX67rpz6nyz/7pxaz2/EHqv/nj+rO+SPVYo9223Xt1q5vtX8nXfbJw7pk3P3KattMkpRaL0PnjLxd4rlAJUSrUnm9pAlmNlfS4vCx1pJ2kVRrF05rcMM1Kpj8k/LuGiQlJcnSUst9XrffeSqe86fW3n6PktrsrPo3X6c1A24u/TzzzFMVWLBIvjqhnVSSOrSXKyzUqgsuV6OnHpPVqSNLS1Vyl87KHT7K07ahejY9epPcxg0Vfh6YM0N5Tw3c4nj6eVer+LefVPzcfZI/SUpJldLryNemozbe01/pF98oX6t2Cq5cqpSex2jTE3dEsxmohhEj3tRzz72qV199qvTYYYf20Il9j9G++x2loqIiNWnSKOK1/33iPn366Vc66+z+Sk5OVkZGuiTp3POuKj1n8KP3aP2G0DN2ww1XqO+JF6ptm1a64vILdMtt9+muO67TI48+o3idvFlb/frWN5ry2ufq+8SVpcey5yzR21c8qeMfumS7r93a9d0uP15vXDRY9Vs11r7nH6kJD4xWzwEn67sh70s8FztUov7yFpVKpXPuE0mdJA2S9Gn49W9Ju4Y/q3WsTh2l7L2n8saF92sOBOQ2bip3TnLbNiqc+kvo44WLldS8uXxZWZIkX5PGSj24uzZ9UGa/50BAlpoqmcmSkqRgiepdfrFyhw33okmItfQ6Suq0h4q//jj0viQg5W+SXFDmD/++mJImBQJKPfYMFX7xnhTeExrxJ9I+3ldccaEeGzxERUVFkqTs7DVbXFevXl316tlNr7w6VpJUXFys9eu3/AXl9NP76vU33g+fE1BGRroyMtJVHChW+/Zt1GrnnTTp6x92dLNQTYv/N1v5ORvLHVvz5zKtnbe8Stdu7fpgcYmS01OUnJ6qYHFADVo3Vb0WjbRoMvNrUTlRm/3tnAtKmhyt+9c0STs1VzBnvRoMvFXJHTuoePYcrf/vELmCfxYnLv7zL6Uf1ktFv85Q8u67yd+8mfxNGyu4bp0aXH+1Njz7oizjn/2eAwsXKZizXk2Gv6j8Tz5XUquWks9UPGduLJqIqnJOdW5+VHJOhRPHq3jSlvu7+3fZXZmDXlQwZ40K3nhRwWUL5WvcXMHc9Uq/9Bb5d+6gkoVzlD/6OakgX8XTf1TmoBcUmPmLXP4m+dt3VuG40TFoHKqjY8f26tnzQN1/360qKCjUrbfdrylTfy13Trt2rbV69Rq9/NJ/teeeu+vnn6frhhvvUV5efuk5vXp208pV2frzz9DC148+9qyGv/KU8vML1O/ia/XYo3frnnsf87RtiD/fP/eBTnziKhUXFumD659X77vO1cTH34x1WAmJMZWoHr9fyZ06atM7Hyi73xVy+QXKvPCccqfkjhgry8xUk9eGKvP0U0LJYTCotIO7q2Rdjor/2DJZXP/kEGX366+NY99S3f6XaMPQV5XZ7zxlPXCPMk7s41XrUA0bH7peG/99lTY9cadSjzhR/k57lPu8ZOFc5d58rjbee4WKJrynjGsHSZLM75e/TUcVfTVOG/99pVxhgVL7nC1JKvr4TW2890oVvPGi0k69SAXvDVfyIccp/aq7ldr3PM/biKpJSvIrK6uBevTsq9tuf0Bjx7yw5Tl+v/bZZw+9+OIIHXDgMdq0KU+33Vp+lNFZZ52sN8JVSkn69dffdXCvvjry6DPUvl1rrVi+SmamMaOf12vDn1bTpo2j3jbEn5UzF2r4Kfdq9NkPqkHrptq4KkdmplOeHaATn7xKdRrXi3WIiHMklR4pWZWtkuxsFc+cLUnK/+prpXQqvwery8tTzoOPKbtff62772H5shoosHS5UvbsqvRePdTsnTFqeP/dStlvH2XdW35sXFqvHiqePUe+9HQltdpJ6wbep/TDDwl1jyOuuZxQl6bLzVHxz9/J336z/d0L8qTCUEU7MP1/Mn+SLLOegmuz5dZlq2Re6Jkq/ulr+duUf6Z8rXeRZAouX6LkAw5V/vP3y9ekhXzNWgrxb+mS5XrvvdDwhp+mTFMwGFTjxg3LnbNk6XItWbJc//spNHTmnXfGa5+9//nFxO/365STj9Obb30Q8TvuvOM6PfDQk7p74A26/Y4H9PLLYzTgmksjnovao+eAk/Xt0++q1/WnasLDYzVt7Fc64OJjYh1WwjAzT19eIan0SHDtOpWsXKWk1jtLklL331fFCxaWO8cy60hJoREJGSf2UdG06XJ5edrw/EtacdJZWnnquVp79/0qmvqL1g16+J8L/X5lnnWaNo56XUpN+WdAtd8nJbMTZ1xLSZPS0kt/Tuq6n4JLFpQ7xepllf7sb7erZD65jRvkNqxTcG22fM1bSZKSdt9XwWXln6m0Uy5SwbvDJb9fZuH/3J0LTehB3Hv/g0912GE9JIW6wlNSUrR69dpy56xcma0lS5apU6cOkqQjjuipWbPmlH5+ZO9e+uOPP7V06ZZj6C644Ax9/MmXWrcuRxkZ6QoGnYLBoDLS06PYKsS7PU7rpT+/mqaC9ZuUnJYiFwzKBZ2S0vh3A1tHxuGh9U88o6x/3ylLTlJg6XKte/AxZZzSV5KU9+44Jbdto6y7b5NzUmD+Aq17aHCl7lvn9JOV99FncoWFCvw5T5aapqajXlLB9z9uMRkI8cXqZ6nONf8OvfH7VTz5SwV++0kph50gSSqa+KGSDzhEKYf3lUpK5IqLlPfCA6XX5496Vun975AlJSuYvVx5L//zzCTt00MlC+aUVkJLFv+pzPuHqWTxPAUXz/OsjaicSPt4vzr8db007D+a9ssEFRUV65JLr5cktWjRTENfGKy+J10oSbruhrs14rVnlJKSrPnzF+nSy24sve+ZZ55UOkGnrPT0NPW74Ewde3xoGM6TTw7VuA9GqKioWBdcWGsX6Yg7Jz99tdoc1FnpWXU1YPIz+vq/b6sgZ5OOHtRPGQ3r6sxXb9HKmQv1+oWPKrNpA/V57HK9cdHgCq/99Y1J2vWY/SNeL0lJaSna84xDNPb80DJEP770sc4efqtKigN679otlzxD1STqjjrs/Y0ahb2/EQl7f2Nz7P2NisTD3t8H7nSopznO/5ZNqtl7fwMAAGBLzP4GAAAAKkClEgAAwEPsqAMAAABUgKQSAAAA1Ub3NwAAgIeYqAMAAABUgEolAACAh6hUAgAAABUgqQQAAPCQefzaZjxmr5jZKjP7rcyxhmb2uZnNDf+Zta37kFQCAADUbsMlHbvZsdslTXDOdZQ0Ifx+qxhTCQAA4CFfnC1+7pz72szabnb4JEmHhX9+TdJESbdt7T5UKgEAABKYmfU3syllXv0rcVkz59zy8M8rJDXb1gVUKgEAADxkHs/+ds4NlTS0Gtc7M3PbOo9KJQAAADa30sxaSFL4z1XbuoCkEgAAwEM+maevKvpAUr/wz/0kvb/tdgEAAKDWMrOxkn6QtKuZLTGzSyU9IukoM5sr6cjw+61iTCUAAICHLP5mf59TwUe9t+c+VCoBAABQbVQqAQAAPMTe3wAAAEAFqFQCAAB4yOt1Kr1CpRIAAADVRlIJAACAaqP7GwAAwEOJWtFL1HYBAADAQ1QqAQAAPBRvi5/vKFQqAQAAUG1UKgEAADzE4ucAAABABahUAgAAeIjFzwEAAIAKUKkEAADwUKJW9BK1XQAAAPAQlUoAAAAPMfsbAAAAqACVSgAAAA+xow4AAABQASqVAAAAHkrUil6itgsAAAAeIqkEAABAtdH9DQAA4CG2aQQAAAAqQKUSAADAQyx+DgAAAFSASiUAAICHErWil6jtAgAAgIeoVAIAAHiI2d8AAABABahUAgAAeIjZ3wAAAEAFqFQCAAB4KDHrlFQqAQAAsANQqQQAAPCQzxKzVkmlEgAAANVGpRIAAMBDiVrRS9R2AQAAwENxW6lsOu6lWIcAoIbIHxzrCBBvAhPHxDoEoNaJ26QSAAAgEbFNIwAAAFABKpUAAAAeStSKXqK2CwAAAB6iUgkAAOAhxlQCAAAAFaBSCQAA4KFEreglarsAAADgISqVAAAAHvIxphIAAACIjEolAACAhxKzTkmlEgAAADsAlUoAAAAPMaYSAAAAqACVSgAAAA8lakUvUdsFAAAAD5FUAgAAoNro/gYAAPCQMVEHAAAAiIxKJQAAgIcStaKXqO0CAACAh6hUAgAAeCgxR1RSqQQAAMAOQKUSAADAQ2zTCAAAAFSASiUAAICHErWil6jtAgAAgIeoVAIAAHgoMUdUUqkEAADADkClEgAAwEPM/gYAAAAqQKUSAADAQ4la0UvUdgEAAMBDJJUAAACoNrq/AQAAPJSY03SoVAIAAGAHoFIJAADgIZYUAgAAACpApRIAAMBDPhfrCKKDSiUAAACqjUolAACAhxK1opeo7QIAAEAlmNkNZva7mf1mZmPNLK0q9yGpBAAA8JB5/NpqLGYtJV0raX/nXFdJfklnV6VdJJUAAAC1W5KkdDNLkpQhaVlVbkJSCQAA4CGfxy8z629mU8q8+v8di3NuqaTHJS2StFzSeufcZ1VpFxN1AAAAEphzbqikoZE+M7MsSSdJaicpR9JbZna+c27U9n4PlUoAAAAP+WSevrbhSEnznXPZzrliSe9I6lG1dgEAAKC2WiSpu5llmJlJ6i1pVlVuRPc3AACAh+Jp52/n3I9m9raknyUFJP2iCrrKt4WkEgAAoBZzzt0r6d7q3ofubwAAAFQblUoAAAAPJWpFL1HbBQAAAA9RqQQAAPCQz8U6guigUgkAAIBqo1IJAADgoXhaUmhHolIJAACAaqNSGee+nTxFjzz5gkqCQZ3W91hddsGZsQ4JcYDnApHwXKCsFTmbNPDt77R2Y4Fk0mkHdNR5PTrHOiwocSt6JJVxrKSkRA/8Z4iGPfmQmjdtrLMuu06H9+ymDu3axDo0xBDPBSLhucDm/D7TTcftp84tG2lTYbHOGTJe3XdpoQ5NG8Q6NCSoRE2WE8KMWXPUutVO2rllCyUnJ+u43ofqy28mxzosxBjPBSLhucDmmtTLUOeWjSRJdVKT1b5Jfa3akBfjqCCFki8vX14hqYxjq7JXq3nTJqXvmzVtrFXZa2IYEeIBzwUi4bnA1ixdt1Gzl6/VHq0axzoUJDC6vwEASGB5hcW6ecwk3dLnAGWmpcQ6HIh1KhEDTZs01opV2aXvV65araZNGsUwIsQDngtEwnOBSIpLgrppzCQdv1c79e7SOtbhIMGRVMaxrrt10qIly7Rk2QoVFxfr4wmTdHjP7rEOCzHGc4FIeC6wOeecBr3zg9o1ra8Leu4e63BQhnn88grd33EsKcmvO2+4SlfcOFAlJSU65YSjtUt7ZnLWdjwXiITnApubtjBbH06bp47NGujMZz6UJA04eh/12rVljCNDojLn4rNjv3j1vPgMDAAQ9wITx8Q6BMSp9NMHxnxDm+d2Pt/THOdfi0d50ma6vwEAAFBtnieVZnbxVj7rb2ZTzGzKSyPGehkWAAAAqiEWYyoHSXo10gfOuaGShkp0fwMAgMSUqN3EUWmXmU2v4DVDUrNofGdN8O3kKTrh7Mt03JmX6KWRb27xeVFRkW66+2Edd+YlOufy67V0+crSz4aNeEPHnXmJTjj7Mn3341RJ0tp1Obrgqpt08vlXasLX35eeO+C2QSx6XIPwXCASngtsbkXOJl320mc69ckPdOpTH2j097O2OGf4N7/rzGc+1JnPfKjTnvpA+w4cpfV5hZKkkd/N1KlPfaDTnvpAt7/xjQqLSyRJd7z5jc54epye/uyX0vsM+2q6vpy5yJuGIWFEK1luJulCSX0jvGrlv15/78v7/H/u1wejX9RHX0zUX/MXljvnnQ8/U726mfr4zVd0wVkn64nnXpEk/TV/oT6eMEnvj3pBLzzxgO5//FmVlJTooy8m6cyT+2jsS09q5JvvSZImfjtZu3XqwPp0NQTPBSLhuUAkf+/l/c71J2rklcfpjcl/6K9VOeXOuahXF7054AS9OeAEXXv0PtqvXVPVz0jVyvV5GvvDbI351/H6v+tOVEnQ6ZMZCzRnxTqlJSXprWv76vclq5VbUKTsDXmasXi1jtiddS2jxZy3L69EK6n8UFKmc27hZq8FkiZG6TvjWmX25f3ymx900vFHSpKOPqyXfpw6Tc45ffnNZB3X+1ClpKSo1U7N1brVTpoxa46SkvwqKChQUVGx/D6fAoESjXzzPV1y3umxaCKqgOcCkfBcIJLt3cv74+kLdOye7UrflwSdCotLFCgJqqA4oCZ105Xk86kgEFAw6BQIOvnN9NyEX3VV772i3h4knqgklc65S51z31bw2bnR+M54V5l9eVdlr1HzpqF9WZOS/Mqsk6Gc9RtCx5ttfu1q9TnqcH35zWRdfv1duvzCs/T6ux+q7zG9lZ6W5k2jUG08F4iE5wLbsq29vPOLAvp+7jIdGd5Fp1n9DF3Yc3cdO/gdHfXI28pMS1aPjjupfdP6yqqTprOHjNehu7XSojW5cs6VJq+IDp/HL6+w+HkNVjezjp5//D5J0voNuXpp5Ft6+uG7de8jT2lDbq76nXOa9u7aOcZRwms8F4iE5yJxVGYv769nL9HerZuofkaqJGlDfqEmzlqs8TeforppKbpl7CSNnzZPffZur1v7HFB63bUjvtTAk7tr2FczNGfFOnXfpYVOO6CjJ+1CzZeoE5DiTmX25W3apJFWrFotSQoESrRxU54a1K8XOr5y82vL/3b64vCx6t/vbH30xUTtu0Pyo9EAACAASURBVOfuenDgzXru5VFRbBF2BJ4LRMJzgYpUdi/vT6Yv0LF7/dP1PfnPFWqZlamGddKU7Pepd5fWmrYwu9w1X81crM4tGym/KKAla3M1+JxD9MVvC5VfFIhae2qrRK1UklR6pDL78h7es7ve/+gLSdJnE79Rt/32kpnp8J7d9fGESSoqKtKSZSu0aMky7dG5U+l1Cxcv1crs1Tpw3z2VX1Ao8/lkJhUWFnnaRmw/ngtEwnOBSCq7l3duQZGmLlipwzu3Kj3WokGGpi9erfyigJxz+vGvFWrftH7p58UlQY3+fpYu6tVFBcUBWXj/laBzKi4JRq1NSCx0f3ukon15nx02Ql1266TDe3XXqSccozvuH6zjzrxE9evV1eBBt0uSdmnfRscc0UsnnneFkvx+3XXjv+T3+0vv/fTQ13Rt/36SpOOPOkzX3n6fXh75pq657IKYtBWVx3OBSHguEElFe3mvyNkkSTqjW+iXhy9nLtZBu7RQekpy6bV77NxER3Zpo3OGjJffZ9ptp4blurXfmPyH+u7bQekpSerUPEsFxSU6/elx6tmppeqlR+5iR9X5EnQlbvb+BgAkHPb+RkXiYe/vV1t6u/f3xUu92fubSiUAAICHYp7VRgljKgEAAFBtVCoBAAA8lKgVvURtFwAAADxEpRIAAMBDiTr7m0olAAAAqo2kEgAAANVG9zcAAICHWFIIAAAAqACVSgAAAA/5lJgzdahUAgAAoNqoVAIAAHiIJYUAAACAClCpBAAA8FCiVvQStV0AAADwEJVKAAAAD7FOJQAAAFABKpUAAAAe8rnEnP5NpRIAAADVRqUSAADAQ4la0UvUdgEAAMBDVCoBAAA8xOxvAAAAoAIklQAAAKg2ur8BAAA85BNLCgEAAAARUakEAADwkC8xC5XbrlSaWQczSw3/fJiZXWtmDaIfGgAAAGqKynR//5+kEjPbRdJQSTtLGhPVqAAAABKUyXn68kplksqgcy4g6RRJzzjnbpHUIrphAQAAoCapzJjKYjM7R1I/SX3Dx5KjFxIAAEDiStRZ0pVp18WSDpL0oHNuvpm1kzQyumEBAACgJtlmpdI5N1PStZJkZlmS6jrnHo12YAAAAImo1lYqzWyimdUzs4aSfpY0zMyeiH5oAAAAqCkqkyzXd85tkHSqpBHOuW6SjoxuWAAAAImpNs/+TjKzFpLOlPRhlOMBAABADVSZ2d/3SfpU0rfOuZ/MrL2kudENCwAAIDEl6pjKykzUeUvSW2Xez5N0WjSDAgAAQM2yzaTSzNIkXSqpi6S0v4875y6JYlwAAAAJyctxjl6qTAV2pKTmko6RNElSK0m50QwKAAAANUtlkspdnHN3S9rknHtNUh9J3aIbFgAAAGqSSm3TGP4zx8y6SlohqWn0QgIAAEhcvgTt/q5MUjk0vJPO3ZI+kJQp6Z6oRgUAAIAapTKzv18K/zhJUvvohgMAAJDYfBbrCKKjwqTSzG7c2oXOObZqBAAAgKStVyrrehYFAABALZGoSwpVmFQ65wZ5GQgAAABqrgqXFDKzwWZ2RYTjV5jZI9ENCwAAIDH5PH55ZWvfdYSkoRGOD5N0QnTCAQAAQE20tTGVqc65LTr9nXNBM0vQeUsAAADRZZaYYyq3VqnMN7OOmx8MH8uPXkgAAACoabZWqbxH0sdm9oCkqeFj+0u6Q9L10Q4MAAAgEfkStFK5tdnfH5vZyZJukTQgfPg3Sac552Z4ERwAAABqhq3uqOOc+01SP49iAQAASHiJOjHFy5nmAAAAiDNm1sDM3jaz2WY2y8wOqsp9trn3NwAAAHacOBxT+ZSkT5xzp5tZiqSMqtxkm5VKMzu4MscAAABQs5hZfUmHSHpZkpxzRc65nKrcqzKVymck7VuJYzvUqr6XRfP2qKG+XdAi1iEgDp34TOdYhwAAleb1OpVm1l9S/zKHhjrn/t7gpp2kbEmvmtleCq34c51zbtP2fk+FSWW4P72HpCZmdmOZj+pJ8m/vFwEAAMB74QQy0i6JUigX3FfSAOfcj2b2lKTbJd29vd+zte7vFEmZ4S+rW+a1QdLp2/tFAAAAiDtLJC1xzv0Yfv+2qtgbvbV1KidJmmRmw51zC6tycwAAAJQXTxN1nHMrzGyxme3qnPtDUm9JM6tyr8qMqRxuETr/nXNHVOULAQAAEFcGSBodnvk9T9LFVblJZZLKm8v8nCbpNEmBqnwZAABAbWdxtvq5c26aQltxV8s2k0rn3NTNDn1nZv+r7hcDAAAgcWwzqTSzhmXe+iTtJ6l+1CICAABIYF4vKeSVynR/T5XkFNqqMiBpvqRLoxkUAAAAapbKdH+38yIQAACA2iCeZn/vSJXp/k6T9C9JPRWqWH4j6QXnXEGUYwMAAEANUZnu7xGSchXamlGSzpU0UtIZ0QoKAAAgUcXb7O8dpTJJZVfn3O5l3n9lZlVaFBMAAACJqTJJ5c9m1t05N1mSzKybpCnRDQsAACAx1ebZ3/tJ+t7MFoXft5b0h5nNkOScc3tGLToAAADUCJVJKo+NehQAAAC1RK2d/S3pAefcBWUPmNnIzY8BAACg9qpMUtml7BszS1KoSxwAAADbyXyJWan0VfSBmd1hZrmS9jSzDWaWG36/UtL7nkUIAACAuFdhUumce9g5V1fSYOdcPedc3fCrkXPuDg9jBAAAQJyrTPf3x2Z2yOYHnXNfRyEeAACAhFabFz+/pczPaZIOlDRV0hFRiQgAAAA1zjaTSudc37LvzWxnSU9GLSIAAIAEVusm6mzFEkmdd3QgAAAAqLm2Wak0s2ck/Z1S+yTtLennaAYFAACQqGrzNo1l9/kOSBrrnPsuSvEAAACgBqpMUvmGpF3CP//pnCuIYjwAAAAJLVG3adza4udJZvaYQmMoX5M0QtJiM3vMzJK9ChAAAADxb2sTdQZLaiipnXNuP+fcvpI6SGog6XEvggMAAEg05vP25ZWtfdUJki53zuX+fcA5t0HSVZKOj3ZgAAAAqDm2NqbSOee26PR3zpVYok5bAgAAiLJETaO2VqmcaWYXbn7QzM6XNDt6IQEAAKCm2Vql8mpJ75jZJQptyyhJ+0tKl3RKtAMDAABIRIm6o06FSaVzbqmkbmZ2hKQu4cMfOecmeBIZAAAAaozK7P39paQvPYgFAAAg4ZnFOoLo8HCiOQAAABIVSSUAAACqrTLbNAIAAGAHSdSJOlQqAQAAUG1UKgEAADxEpRIAAACoAJVKAAAAD7GkEAAAAFABKpUAAAAeYkwlAAAAUAEqlQAAAB6yBC3pJWizAAAA4CUqlQAAAB4yY0wlAAAAEBGVSgAAAA8xphIAAACoAJVKAAAAD7FOJQAAAFABkkoAAABUG93fAAAAHmKiDgAAAFABKpUAAABeYvFzAAAAIDIqlXGu2Ttj5PLy5EqCUkmJsi+5KtYhIcbqdmihg14YUPo+s01T/Tb4bc0Z9kkMo0KsrcjZpIFvf6e1Gwskk047oKPO69E51mEhhngm4leijqkkqawBVl99o4LrN8Q6DMSJ3L+W67Oj7pQkmc/U95dnteTjKTGOCrHm95luOm4/dW7ZSJsKi3XOkPHqvksLdWjaINahIUZ4JuA1kkqgBmvaq6s2LVilvCWrYx0KYqxJvQw1qZchSaqTmqz2Tepr1YY8EohajGciflGpRGw4p0ZPDZac06b3xinv/fGxjghxpPVJ3bXwve9jHQbizNJ1GzV7+Vrt0apxrENBnOCZgBdIKuNc9pXXKZi9Wr6sBmr81GAFFi5W0bTpsQ4LccCX7FfLY/bT9IfeiHUoiCN5hcW6ecwk3dLnAGWmpcQ6HMQBnon4k6iVygRtVuIIZoe6NYPrcpQ/6Vul7L5bjCNCvGh+xN5aN2OBClcz3hYhxSVB3TRmko7fq516d2kd63AQB3gm4CWSyjhmaWmyjPTSn1O77a/iefNjHBXiRZuTD9Kid+n6RohzToPe+UHtmtbXBT13j3U4iAM8E3HM5/HLI3R/xzFfwyw1euS+0Bu/X3mfTVDh5J9iGxTigj89Vc0O6aopt74c61AQJ6YtzNaH0+apY7MGOvOZDyVJA47eR712bRnjyBArPBPwmjkXn6u6Lz3oiPgMDDH17YIWsQ4BcejEZ1h7D0DlpJ8+0GIdw5o+h3qa4zQaP8mTNketKGpmu5lZbzPL3Oz4sdH6TgAAAMRGVJJKM7tW0vuSBkj6zcxOKvPxQ1u5rr+ZTTGzKaNWLotGaAAAALHFmMrtcrmk/ZxzG82sraS3zaytc+4pSRWWYJ1zQyUNlej+BgAAqEmilVT6nHMbJck5t8DMDlMosWyjrSSVic4y6yjrjpuV1KGd5JxyHhysot9m/vN53Uxl3XWrklq2kCsq1roHH1Ng3oJ/buDzqcmrzyuYvVprbr5LkpT17zuV3KGdCr6brA0vhCZt1L3ofBXPm6+Cr7/zsnmooo6XHaMO5x0umWne6K+22MN716v6qM2pB0uSfEk+1e3YUu93vVL+jFR1e/oqpTWpLzmnv0Z9qbkvfSpJ2vOus9XiiL2U8/tC/XjtC5KkNqcdrNSGddkjvAaozJ7Nw7/5XR9NC60GURIMan72Bn115xmqn5Gqkd/N1LtT/pRJ6tg8S4NO7aHUZL/uePMb/bkiR712a6Vrj95HkjTsq+nq0KyBjtid5WbiHc8F4l20ksqVZra3c26aJIUrlidIekXSHlH6zrjX4IZrVDD5J+XdNUhKSpKlpZb7vG6/81Q850+tvf0eJbXZWfVvvk5rBtxc+nnmmacqsGCRfHVC224ldWgvV1ioVRdcrkZPPSarU0eWlqrkLp2VO3yUp21D1dTftZU6nHe4Pj/+HgWLAjpkzG1a9vkv2rhgZek5fzw/Xn88H9pJaaej9lGn/sepKGeT0lKS9eug0Vo3Y4GS6qTp6E8f0Mqvf1P+8rXK2qOtPu19hw54/DLV321nbVywQu3OOkSTzn0sVk3FdqjMns0X9eqii3p1kSRNmrVYo76fpfoZqVq5Pk9jf5itd647UWnJSbpl7Nf6ZMYCdd6podKSkvTWtX11xSufK7egSAVFAc1YvFqXH75nrJqK7cBzkThY/Hz7XChpRdkDzrmAc+5CSYdE6TvjmtWpo5S991TeuI9CBwIBuY2byp2T3LaNCqf+Evp44WIlNW8uX1aWJMnXpLFSD+6uTR989M8FgYAsNVUykyUlScES1bv8YuUOG+5Fk7AD1O24k9b8/JdK8ovkSoLKnjxLrY4/oMLzW5/cQ4ve+0GSVLAqR+tmLJAkBTYVaMPcZUpvniUXdPIl+yWFlh4KBgLa9ao+mvvKZ3KBkqi3CdXXpF6GOrdsJKn8ns0V+Xj6Ah27Z7vS9yVBp8LiEgVKgiooDqhJ3XQl+XwqCAQUDDoFgk5+Mz034Vdd1XuvqLcHOwbPBeJdVJJK59wS59yKCj6rlX2ySTs1VzBnvRoMvFVNXntRDe64SZaWVu6c4j//UvphvSRJybvvJn/zZvI3De3T2uD6q7Xh2RelYLD0/MDCRQrmrFeT4S+q4NsflNSqpeQzFc+Z613DUC3r/1iiJt12VUpWpvzpKWpxxN7K2KlhxHP96SlqfvieWjL+f1t8ltGqsRrs0UZrfv5LgU0FWj7hVx39+UMqWJWj4g35arTPLlr6ydRoNwdRsK09m/OLAvp+7jIdGd4tpVn9DF3Yc3cdO/gdHfXI28pMS1aPjjupfdP6yqqTprOHjNehu7XSojW5cs6VJimoWXguajgm6qBa/H4ld+qonP88reKZs1X/+quVeeE5yh36aukpuSPGqv4N16jJa0MV+Gt+KDkMBpV2cHeVrMtR8R9zlbJP+d8e1z85pPTnhoMfVM6jTyiz33lK7thBhf+bqrwPxnvWRGy/3LnLNGvIOB36+u0K5BUq5/eFcmV+cShrp6P21eqf5qgop3yFOykjVQe/fL1+uWekAhvzJUmzn/tQs58LLXZ8wOOX6bfBb6v9uYep2aF7aP2sxZr55HvRbRh2iMrs2fz17CXau3UT1c8IDafZkF+oibMWa/zNp6huWopuGTtJ46fNU5+92+vWPv9Uwa8d8aUGntxdw76aoTkr1qn7Li102gEdPWkXqofnAvEqQXv140/JqmyVZGereOZsSVL+V18rpVP5/1BdXp5yHnxM2f36a919D8uX1UCBpcuVsmdXpffqoWbvjFHD++9Wyn77KOveO8pdm9arh4pnz5EvPV1JrXbSuoH3Kf3wQ0Ld44hr88dO0ufHDNRXp9yvovWblPtXxCK/Wp/cvbTr+2+W5FePl6/Xwne+09KPpmxxTYOubSQzbfhzuVr17aYfrnhGmW2aKrNds6i0BTtOZfds/mT6Ah271z9dnJP/XKGWWZlqWCdNyX6fendprWkLs8td89XMxercspHyiwJasjZXg885RF/8tlD5RYGotQc7Bs9FYjCfefryCkmlR4Jr16lk5Soltd5ZkpS6/74qXrCw3DmWWUdKChWPM07so6Jp0+Xy8rTh+Ze04qSztPLUc7X27vtVNPUXrRv08D8X+v3KPOs0bRz1upSaIv29S5LfJyVTjI53qY3qSZIyWjZSq+MP0MII+3kn101Xk+6dt+jCPvCJy5U7d6nmvPhxxHvvcesZmvHYW/Il+2W+0H/uLuiUlM4vG/Gssns25xYUaeqClTq8c6vSYy0aZGj64tXKLwrIOacf/1qh9k3rl35eXBLU6O9n6aJeXVRQHJCF//8m6JyKSyJXyREfeC4Q78g4PLT+iWeU9e87ZclJCixdrnUPPqaMU/pKkvLeHafktm2Udfdtck4KzF+gdQ8NrtR965x+svI++kyusFCBP+fJUtPUdNRLKvj+xy0mAyH+HPzydUrJqitXHNDUO4areEOeOlzYW5L014gJkqSWxx2glZNmqCS/sPS6xgd2Utszeiln5iId/XloT4EZD7+h5V/+Grrm2P209td5KliZI0nK+X2hjvnyEa2ftUg5Mxd52URsp4r2bF4RHvpwRrdOkqQvZy7WQbu0UHpKcum1e+zcREd2aaNzhoyX32fabaeG5bov35j8h/ru20HpKUnq1DxLBcUlOv3pcerZqaXqpUfuSkV84LlIIAla0mPvb9Qo7P2NSNj7G0BlxcPe3+vOOMzTHCfrrYmetJlKJQAAgIe8HOfopQQtwAIAAMBLVCoBAAC8lKAlvQRtFgAAALxEpRIAAMBLjKkEAAAAIqNSCQAA4CFmfwMAAAAVIKkEAABAtdH9DQAA4KU4LOmZmV/SFElLnXMnVOUecdgsAAAAeOw6SbOqcwOSSgAAAC/5zNvXNphZK0l9JL1UrWZV52IAAADENzPrb2ZTyrz6b3bKk5JulRSszvcwphIAAMBDXi8p5JwbKmloxFjMTpC0yjk31cwOq873UKkEAACovQ6WdKKZLZD0uqQjzGxUVW5EUgkAAOClOBpT6Zy7wznXyjnXVtLZkr50zp1fpWZV5SIAAACgLMZUAgAAeClOt2l0zk2UNLGq11OpBAAAQLVRqQQAAPCQWXxWKquLSiUAAACqjUolAACAl+J0TGV1UakEAABAtVGpBAAA8BKVSgAAACAykkoAAABUG93fAAAAXvIlZk0vMVsFAAAAT1GpBAAA8BITdQAAAIDIqFQCAAB4yKhUAgAAAJFRqQQAAPASlUoAAAAgMiqVAAAAXrLErOklZqsAAADgKSqVAAAAXmJMJQAAABAZlUoAAAAvUakEAAAAIqNSCQAA4CHzJWZNLzFbBQAAAE+RVAIAAKDa6P4GAADwEhN1AAAAgMioVAIAAHiJbRoBAACAyKhUAgAAeIkxlQAAAEBkVCoBAAC8xOLnAAAAQGRUKgEAALzEmEoAAAAgMiqVAAAAXmKdSgAAACAyKpUAAABeStAxlXGbVA5f1iLWISAO7RLrABCXisZPjHUIiDNzPqsb6xAQpw44PdYRJK64TSoBAAASkbFOJQAAABAZSSUAAACqje5vAAAALyXoRB0qlQAAAKg2KpUAAABeYvFzAAAAIDIqlQAAAF5iTCUAAAAQGZVKAAAAL7H4OQAAABAZlUoAAAAvGWMqAQAAgIioVAIAAHiJMZUAAABAZFQqAQAAvESlEgAAAIiMSiUAAICX2FEHAAAAiIykEgAAANVG9zcAAICXLDFreonZKgAAAHiKSiUAAICXWFIIAAAAiIxKJQAAgIeMJYUAAACAyKhUAgAAeInZ3wAAAEBkVCoBAAC8xOxvAAAAIDIqlQAAAF6iUgkAAABERqUSAADAS8Y6lQAAAEBEVCoBAAC8xJhKAAAAIDIqlQAAAF5iRx0AAAAgMpJKAAAAVBvd3wAAAF5iog4AAAAQGZVKAAAAL1GpBAAAQCIxs53N7Cszm2lmv5vZdVW9F5VKAAAAL8XXNo0BSTc55342s7qSpprZ5865mdt7IyqVAAAAtZRzbrlz7ufwz7mSZklqWZV7UakEAADwksdjKs2sv6T+ZQ4Ndc4NjXBeW0n7SPqxKt9DUgkAAJDAwgnkFklkWWaWKen/JF3vnNtQle8hqQQAAPBSnM3+NrNkhRLK0c65d6p6n/hqFQAAADxjZibpZUmznHNPVOdeVCoBAAC8ZHFV0ztY0gWSZpjZtPCxO51zH23vjUgqAQAAainn3LeSdsgaRySVAAAAXoqzMZU7SmK2CgAAAJ6iUgkAAOCl+BpTucMkZqsAAADgKZJKAAAAVBvd3wAAAF5iog4AAAAQGZXKOHfgpcdq77MPl3NO2bMXa9wtQ1VSWBzrsBBDdTu00EEvDCh9n9mmqX4b/LbmDPskhlEhLphPmfc+p+C61cp7amCso0Ec8NfLUNvHr1b6rq0lJ82/6VltmvpHrMNCgk7UIamMY3WbZemAi4/Ri71vVaCwWKcMGaAufQ/S9Le/jnVoiKHcv5brs6PulCSZz9T3l2e15OMpMY4K8SDlqFNUsnyRLC0j1qEgTrS+7zKt/+oX/dV/sCw5Sb70lFiHhASWmKlyAvH5/UpKS5H5fUpOT1XuynWxDglxpGmvrtq0YJXylqyOdSiIMctqrOS9uqno6+3eWQ0Jyl83Q3W77a7VY7+QJLnigEo25MU4KkgKjan08uURKpVxLHflOk0eOl4DfnhaxQVFmv/NDM3/Zkasw0IcaX1Sdy187/tYh4E4kH7Ov5T/5jCqlCiV0rqpitdsULv/DlD67m2VN/0vLbrnZQXzC2MdGhIUlco4llYvQ52O3k9Del6vpw+8Rsnpqep6ysGxDgtxwpfsV8tj9tPicT/GOhTEWNJe3RTMzVFw4dxYh4I4Yn6/6uzRXqtGfKKZx9ykYF6hWlxzaqzDgpSwlUqSyv9v777jpKqvPo5/zs5WWKrSV+miBhBUMBYwNpoxoj4aS+xKNCqiUR98TEyIXYyJDbFgMEpQo6JGJEgURY0gkSJVmixtKS4syy7bZuY8f8ywARlQWKawfN+v17y487vt3OW+4Oy5v/v7pbA2J3WmaOUGtm7cQjgY4ut/TifvmI7JDktSRPNTu7FpznIqvi1OdiiSZIGOncnodjz1hr9MnevvIv2IbuQMGprssCTJKgsKqSwopHRm5JeNjeP/TZ0u7ZIcldRmevydworXFNKqewfSszMJllfS5sQfUTDnm2SHJSmi9cDjWTFOj74FKl4fRcXrowAIdDqKrH7nU/bsg0mOSpItuKGIyjXfkt2+JeVL11D/pK6ULVqV7LAE9Pa3JN6aWUtZ+N4XXD3+PsKhEOvm5TPzbx8mOyxJAYGcLJr17sx/7hiV7FBEJIXl//Y52j1xC5aRTsWKdXxz6xPJDklqMXP3ZMcQ032tL0nNwCSpOlQmOwJJRf36rUt2CJJiFr1fL9khSIrqsXqcJTuGsn+NTGiOk3P6dQm55rhVKs2sJ+DuPt3MjgT6AQvdXeNdiIiIiNQycUkqzex3QH8g3cwmAccBk4GhZtbd3e/bxX6DgEEAZzfuSY/cDvEIT0RERCR51Kdyj/wP0A3IAtYCee5ebGaPANOAmEmluz8LPAt6/C0iIiKyP4lXUhl09xCw1cyWunsxgLuXmVk4TudMOT8dfi0dTu1OaWExz/WJDO9x+ICe9L7lPA7u0JK//OzuXb7NHWvf3e2fd+xh9Lv3SsJVQcbd9CSblq8jq34dzn1qMGMvewhStO+sQMdr+tL+klPAjGVjJu80h3en68+k9bmR8UnT0tOo17EVb3e+jkCdLI57/HqymzQAd5a+/CGLn58IQNe7LqTFqUdRNC+faYNHAtD6vBPJalxPc4TvJ+oNfxkvL4NwCA+FKP3DDTusD3Q6irqD/0D42wIAqr78lIp3Xo6szKlLnSt/TVpeG3Cn7IVHCC1dQPb515DepSehFUspe/4hADKOPw3LbUDlpDcTeXmyl5pdexZNLjoddyhbmM83tz6BV1RVr29yaV+aXt4fwmFCpeUsv2ME5YtXUbdbR9o8fH1kI4PVf3yVon9OI71xfTqMGkqgfl1WPzyGoolfANDhhTvJv3MkVZrFLT4SOHZkIsUrqaw0szruvhU4ZlujmTUADpikcvbfP+E/L07irEevq27bsGgVr//yzwy4/6o93nd3+x937QBevWI4DfIO5uhfnM4H947hpJsG8tlTbyuhTGENOuXR/pJTmDTgbsKVQXr/7X9ZM2kmJcv/++LJ10+P5+unxwPQ8ozuHDaoP5VFpWRnZjB72Bg2zVlOet1s+ky8l3VT5lJWsJFGXdow8bQ76fHINTQ4/BBKlq+l7c978/HFDyfrUmUvlD70a7xk1+OQBhfNYetjv9mpPeeSG6iaO52qEX+AQDpkZkFOXdJad6Tk7kHkXHkraXltCa9bTeZJfSl99M54XobsIxnNG9PsqjOZc8pgvLyS9iNvo/HZJ1H42uTqbQrHTWHDS5FfLhue0YNDf3cli35xD2UL85nX/zYIhclo2ogfTfoTsyZNp/HAu2PWGgAADttJREFUXmx4aSKb3vucji/9lqKJX9DgjGPZOneZEkrZY/FKlXtHE0rcffskMgO4PE7nTDkrv1hIWVHJDm2FS9awcVnBXu27u/3DVSEycjLJyMkiXBWk4aFNqd/iIFZMXbD3FyBxV69jSwpnLCVUVomHwmyYuoC8AT12uf2hA09gxVufA1C+vohNc5YDECwtp3jxGnKaN8LDTlpGAIgMPRQOBul0/ZksfuF9PBiK+zVJkuXUJf2wLlRNmRD5HgpCWSl4GAtE6wiZ2RAMktXvfCr+9RaEdF/sLyw9QFp2JgTSSMvJomrtxh3Wh0vKqpfT6mRV1xTC5ZUQivx3bFkZ1cUGDwZJy8mMtIXDEEij+TVnsXbEuMRckNQqcalUunvMiUXd/Vvg23ic80D37xHv8LNHr6eqopJ3hjzNaXddzEePvJbssOR7bP56FV2HXkBmo1xC5ZW0OLUbm2Yvi7ltICeT5qd0ZcZdo3daVyfvYBp2aU3hjKUES8sp+GA2fSbdz/pP51FVXMZB3Tsw/09vxflqZJ9yp+5tka4rFR+Np+rj8TttEuhwJLnDniFcVEj5q88QXpNP2sHNCW/ZTM7VtxM4pD2h/EWUjRkB5WVUfTWN3GEjCc6fiZeVEmh3BBX/GJOEi5O9UbV2I2tHvs1RXzxLuLyS4o9nUTxl9k7bNb28P80G/Yy0zHQWXnB3dXvd7h1p+8cbycxrwrLBj0EozMZxn9DuqVtockkfVt7/V5pe3p9v3/gokoRK/OhFHUll6+bnM/qc3wFwSM/DKVlfhJlxzpM3EQoG+eDeMZRqOr+Us2XxGhY89Q9OfmUowa0VFM3Lx8Oxe4i0PONovp2+iMqi0h3a0+tkceKoIcy8+yWC0SrFwhHvsnDEuwD0eOQa5g5/nXYX/4RmJ3dh84KVzP+zEsxUV3L/ELyoEKvXkLq3PUS4YAWhRXOq14fyF7Pltouhopz0rj2pM3gYJUOvwAIBAq07Uj7mSULLFpJ98a/IOvNCKsaNpnLCa1ROiPyymXPlrZS/NZqM3v1J/9GxhFctU4KZ4gIN6tKwb0+++vF1hIpLaf/M7Rx07skUvvnxDtutf3EC61+cQOOBvWh58/l8M+RxAEpnLmbuqTeT3SGPtn8ezObJMwht2criy+6rPn6LG85lydUP0ebhXxFoWJe1z7xD6ZdfJ/xaZf9UO1PlA9xJNw3k08fH0WvIuXzwwFhmjZ1Mjyv7Jjss2YVvxn7MpL6/YfI591C5uZQtS9fG3O7QgT+ufvS9jaUHOGHUEPLf/IzV7/1np30adm4NZhQvKSDvrOP4/JdPkNu6Kbltm8XlWmTf8aLCyJ9biqia8RmBdofvuEH5VqgoByD41RdYIB3LrU944wZ80wZCyxYCUDV9CoHWHXfYNe3QDoARLlhFRo+TKXv6HtKatCCtWau4X5fsvfq9jqJixTqCG4vxYIhNE6aSe2ynXW6/8e1Padi3507t5UtWEd5aTk6nQ3dobznkAgoef53GA3uxZfoCvrn5cVrd+vN9fh1C5EWdRH4SdVkJO5MkRJfzerFk8izKN5eSkZ2Jh8N42EnPzkp2aLILWQfVB6BOq4PIG9CD/BjzeWfUy6HJj49g9T+/3KG956PXsmXxahY9MyHmsbvccT5zHv47aRkBLPoPi4ed9BzdDyktMxuyc6qX0zsfQ3jV8h02sfqNqpcDbTuBpeElxXjxJsIbN5DWPA+A9COPJrwmf4d9s8+5gvJxoyEQwLY9hnOPvNAjKaty9QZyjz4s0qcSInN5L95xLu+sti2qlxucfgwV30T64Gce0hQCkb/rzFZNyG7fisqV63fYL7PFQWz5fB6BnKxI/0r36nOJ/BB6/B1HAx+/gdbHH0FOo3rcNPUJpvzpdcqLSukz7HLqNK7HBX+5nXXz83nlsofIbdqQMx++llevGL7LfWe/+jGd+h4bc3+A9OxMup7fm7G/eBCAac9P4MLRdxCqCvLW4KeS9nOQ3Ttx1M1kNqqHVwX58s7RVBVvpf1lpwGw9K8fANCqfw/WfTyHUNl/uysf3PMw2pzfi6L5K+gz6X4A5jzwKgUfRvpYtep3DBtnL6N8XREARfPy6fvhg2xesIKi+SsSeYmyh6xBI+re+PvIl0CAqqkfEpw7ncyf/BSAyo/eJaNHbzJPOQtCIbyqkq0j763ev+zlJ8kZdCeWnkF4QwFbRw2vXpfe/QRCyxdVV0JDK5eQe89zhFYuI7wydn9eSQ2lMxezcfznHDnxj3gwzNZ5y9gw5n1a3nYRW2cvoWjSdJpdMYD6vbriwRDBzSUsiz76rtfzCFrccC4eDOHhMPn/9wzBTVuqj533v5ew6qFI94fCtz6h4wtDaXHDuax+ZGxSrrW2MwskO4S40Nzfsl/R3N8Si+b+lu/S3N+yK6kw93f5Jy8lNMfJ7nXp/j33t4iIiIjEUEsHP6+dVyUiIiIiCaVKpYiIiEgiqVIpIiIiIhKbKpUiIiIiiVRLZ9SpnVclIiIiIgmlSqWIiIhIIqlPpYiIiIhIbKpUioiIiCSS+lSKiIiIiMSmpFJEREREakyPv0VEREQSKS2Q7AjiQpVKEREREakxVSpFREREEkkv6oiIiIiIxKZKpYiIiEgiafBzEREREZHYVKkUERERSST1qRQRERERiU2VShEREZEEMtM4lSIiIiIiMalSKSIiIpJIevtbRERERCQ2VSpFREREEklvf4uIiIiIxKZKpYiIiEgiqU+liIiIiEhsSipFREREpMb0+FtEREQkkfSijoiIiIhIbKpUioiIiCRSmqZpFBERERGJSZVKERERkURSn0oRERERkdhUqRQRERFJJA1+LiIiIiISmyqVIiIiIglk6lMpIiIiIhKbKpUiIiIiiaQ+lSIiIiIisalSKSIiIpJI6lMpIiIiIhKbKpUiIiIiiaS5v0VEREREYlNSKSIiIiI1psffIiIiIomkF3VERERERGJTpVJEREQkkTT4uYiIiIhIbKpUioiIiCSQqU+liIiIiEhsqlSKiIiIJJL6VIqIiIiIxKZKpYiIiEgiqU+liIiIiNQ2ZtbPzL42syVmNnRvj6NKpYiIiEgipQWSHUE1MwsATwFnAKuA6Wb2jrvP39NjqVIpIiIicuDqCSxx92XuXgm8Apy9NwdK2UrlXfljLNkxpAozG+TuzyY7Dkktui8kFt0XET2SHUCK0X2RWjIObpfQHMfMBgGDtmt6drv7oRWwcrt1q4Dj9uY8qlTuHwZ9/yZyANJ9IbHovpBYdF8cwNz9WXc/drtPXH7BUFIpIiIicuBaDRyy3fe8aNseU1IpIiIicuCaDnQ0s7ZmlglcCLyzNwdK2T6VsgP1g5FYdF9ILLovJBbdFxKTuwfN7EZgIhAAXnD3eXtzLHP3fRqciIiIiBx49PhbRERERGpMSaWIiIiI1JiSyhS3r6ZOktrDzF4ws/VmNjfZsUjqMLNDzGyymc03s3lmdnOyY5LkM7NsM/vCzGZH74thyY5Jai/1qUxh0amTFrHd1EnARXszdZLUHmbWGygB/urunZMdj6QGM2sBtHD3GWZWD/gSGKh/Lw5sZmZAXXcvMbMM4FPgZnefmuTQpBZSpTK17bOpk6T2cPcpwMZkxyGpxd0L3H1GdHkLsIDITBlyAPOIkujXjOhH1SSJCyWVqS3W1En6T0JEdsvM2gDdgWnJjURSgZkFzGwWsB6Y5O66LyQulFSKiNQiZpYLvAEMcffiZMcjyefuIXfvRmSmlJ5mpm4zEhdKKlPbPps6SURqv2ifuTeAMe7+ZrLjkdTi7kXAZKBfsmOR2klJZWrbZ1MniUjtFn0hYxSwwN0fTXY8khrMrImZNYwu5xB58XNhcqOS2kpJZQpz9yCwbeqkBcBrezt1ktQeZjYW+BzoZGarzOzqZMckKeFE4FLgVDObFf0MSHZQknQtgMlm9hWRQsUkd383yTFJLaUhhURERESkxlSpFBEREZEaU1IpIiIiIjWmpFJEREREakxJpYiIiIjUmJJKEREREakxJZUiss+Y2UHbDWez1sxWb/c9cx+fq6GZ/Wo365ub2StmttTMvjSz98zsMDNrY2Zz92UsIiKiIYVEJE7M7PdAibs/8gO2TY+Oy7onx28DvOvuO005Fx0I/N/Ai+4+Mtp2FFAfWLmr/UREZO+pUikicWVm15rZdDObbWZvmFmdaPtoMxtpZtOAh82svZlNNbM5ZnavmZVsd4zbo8f4ysyGRZsfBNpHq6DDv3PaU4CqbQklgLvPdvdPvhNbGzP7xMxmRD8nRNtbmNmU6LHnmlkvMwtEY54bjfGWOPy4RET2W+nJDkBEar033f05ADO7F7gaeCK6Lg84wd1DZvYu8Ji7jzWz67btbGZ9gI5AT8CAd8ysNzAU6Ozu3WKcszPw5Q+IbT1whruXm1lHYCxwLHAxMNHd7zOzAFAH6Aa02lbh3Db1nYiIRCipFJF46xxNJhsCuUSmHd3m7+4eii4fDwyMLv8N2PbYvE/0MzP6PZdIkrliH8SWATxpZt2AEHBYtH068IKZZQBvufssM1sGtDOzJ4DxwPv74PwiIrWGHn+LSLyNBm509y7AMCB7u3WlP2B/Ax5w927RTwd3H/U9+8wDjvkBx74FWAccRaRCmQng7lOA3sBqYLSZXebum6LbfQRcBzz/A44vInLAUFIpIvFWDyiIVv0u2c12U4HzossXbtc+EbjKzHIBzKyVmTUFtkSPHcuHQJaZDdrWYGZdzazXd7ZrABS4exi4FAhEt20NrIs+tn8eONrMDgbS3P0N4DfA0d9z3SIiBxQllSISb78FpgGfAQt3s90Q4FYz+wroAGwGcPf3iTwO/9zM5gCvA/XcvRD4LPrizA4v6nhkWItzgNOjQwrNAx4A1n7nnCOAy81sNnA4/62c/gSYbWYzgZ8DjwGtgI/MbBbwMnDnHv8kRERqMQ0pJCIpIfpWeJm7u5ldCFzk7mcnOy4REflh9KKOiKSKY4i8NGNAEXBVkuMREZE9oEqliIiIiNSY+lSKiIiISI0pqRQRERGRGlNSKSIiIiI1pqRSRERERGpMSaWIiIiI1Nj/A+j+pHe6F0vhAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bcvu_gzYDaex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}