{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestfires.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boraks4/539-project/blob/main/forestfires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credits to https://stackoverflow.com/a/57539179\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/boraks4/539-project.git'.format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "merjZ6yJcTtX",
        "outputId": "87fb476a-4dec-419e-bfb7-c5a5b7bb99cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User name: boraks4\n",
            "Password: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 539-project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dMW3uMDa4bW",
        "outputId": "a2092c24-7ce9-4c0f-e4de-d8a882fd7978"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '539-project'\n",
            "/content/539-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "svgckzvrYDhP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = pd.read_csv('forestfires.csv', sep=',', header=0)\n",
        "# TODO: Is this the encoding we want for months, days?\n",
        "fires.month=fires.month.map({'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12})\n",
        "fires.day=fires.day.map({'mon':1,'tue':2,'wed':3,'thu':4,'fri':5,'sat':6,'sun':7}) \n",
        "\n",
        "print(fires)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Iaed6PPYT_R",
        "outputId": "e287477b-482b-4839-98e1-7ee6f6f4dda1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
            "0    7  5      3    5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00\n",
            "1    7  4     10    2  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00\n",
            "2    7  4     10    6  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00\n",
            "3    8  6      3    5  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00\n",
            "4    8  6      3    7  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...    ...\n",
            "512  4  3      8    7  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44\n",
            "513  2  4      8    7  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29\n",
            "514  7  4      8    7  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16\n",
            "515  1  4      8    6  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00\n",
            "516  6  3     11    2  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00\n",
            "\n",
            "[517 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = fires[fires['area'] == 0]\n",
        "zeros = zeros.assign(size=0)\n",
        "\n",
        "no_zeros = fires[fires['area'] != 0]\n",
        "no_zeros = no_zeros.assign(size=pd.qcut(no_zeros['area'], 3, labels=[1, 2, 3]))\n",
        "    \n",
        "fires_quant = pd.concat([zeros, no_zeros])\n",
        "fires_quant = fires_quant.drop(['area'], axis=1)\n",
        "print(fires_quant)\n",
        "print(fires_quant['size'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWIF62Np7_Jx",
        "outputId": "b1b5a3ec-3412-489f-a130-15c7b1b0ff3f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC  ISI  temp  RH  wind  rain  size\n",
            "0    7  5      3    5  86.2   26.2   94.3  5.1   8.2  51   6.7   0.0     0\n",
            "1    7  4     10    2  90.6   35.4  669.1  6.7  18.0  33   0.9   0.0     0\n",
            "2    7  4     10    6  90.6   43.7  686.9  6.7  14.6  33   1.3   0.0     0\n",
            "3    8  6      3    5  91.7   33.3   77.5  9.0   8.3  97   4.0   0.2     0\n",
            "4    8  6      3    7  89.3   51.3  102.2  9.6  11.4  99   1.8   0.0     0\n",
            "..  .. ..    ...  ...   ...    ...    ...  ...   ...  ..   ...   ...   ...\n",
            "509  5  4      8    5  91.0  166.9  752.6  7.1  21.1  71   7.6   1.4     1\n",
            "510  6  5      8    5  91.0  166.9  752.6  7.1  18.2  62   5.4   0.0     1\n",
            "512  4  3      8    7  81.6   56.7  665.6  1.9  27.8  32   2.7   0.0     2\n",
            "513  2  4      8    7  81.6   56.7  665.6  1.9  21.9  71   5.8   0.0     3\n",
            "514  7  4      8    7  81.6   56.7  665.6  1.9  21.2  70   6.7   0.0     3\n",
            "\n",
            "[517 rows x 13 columns]\n",
            "0    247\n",
            "1     90\n",
            "2     90\n",
            "3     90\n",
            "Name: size, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# label = []\n",
        "# for a in fires['area']:\n",
        "#   if a > 50:\n",
        "#     label.append(3) # 'catastrophic'\n",
        "#   elif a > 10: \n",
        "#     label.append(2) # 'large'\n",
        "#   elif a > 0:\n",
        "#     label.append(1) # 'medium'\n",
        "#   else:\n",
        "#     label.append(0) # 'small'\n",
        "# fires['classification'] = label\n",
        "# fires = fires.drop(['area'], axis=1)\n",
        "# pd.options.display.max_columns = len(fires.columns)\n",
        "# pd.options.display.width = 100\n",
        "# print(fires)\n"
      ],
      "metadata": {
        "id": "kopGlpGvv5kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paste in hw8 solution"
      ],
      "metadata": {
        "id": "S7v1o-A_BazT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7rx1rzqy25o"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = fires_quant.iloc[:,:-1]\n",
        "print(X)\n",
        "y = fires_quant.iloc[:,-1]\n",
        "print(y)"
      ],
      "metadata": {
        "id": "KuYJ7JkDDMK6",
        "outputId": "fc5bb1b5-db52-4131-9ab0-1c40795eee21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC  ISI  temp  RH  wind  rain\n",
            "0    7  5      3    5  86.2   26.2   94.3  5.1   8.2  51   6.7   0.0\n",
            "1    7  4     10    2  90.6   35.4  669.1  6.7  18.0  33   0.9   0.0\n",
            "2    7  4     10    6  90.6   43.7  686.9  6.7  14.6  33   1.3   0.0\n",
            "3    8  6      3    5  91.7   33.3   77.5  9.0   8.3  97   4.0   0.2\n",
            "4    8  6      3    7  89.3   51.3  102.2  9.6  11.4  99   1.8   0.0\n",
            "..  .. ..    ...  ...   ...    ...    ...  ...   ...  ..   ...   ...\n",
            "509  5  4      8    5  91.0  166.9  752.6  7.1  21.1  71   7.6   1.4\n",
            "510  6  5      8    5  91.0  166.9  752.6  7.1  18.2  62   5.4   0.0\n",
            "512  4  3      8    7  81.6   56.7  665.6  1.9  27.8  32   2.7   0.0\n",
            "513  2  4      8    7  81.6   56.7  665.6  1.9  21.9  71   5.8   0.0\n",
            "514  7  4      8    7  81.6   56.7  665.6  1.9  21.2  70   6.7   0.0\n",
            "\n",
            "[517 rows x 12 columns]\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "509    1\n",
            "510    1\n",
            "512    2\n",
            "513    3\n",
            "514    3\n",
            "Name: size, Length: 517, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "unnecessary, already one-hot starting with 0\n",
        "cats = np.unique(y)\n",
        "# reformmat y label so starts at 0 for one-hot encoding\n",
        "y = y - cats[0]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "W47hS7daDQId",
        "outputId": "d3ec62ee-67d5-409d-ce0e-9ff9083ef208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nunnecessary, already one-hot starting with 0\\ncats = np.unique(y)\\n# reformmat y label so starts at 0 for one-hot encoding\\ny = y - cats[0]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# hyperparameters\n",
        "\n",
        "# splitting data\n",
        "splits = (.6,.2,.2) # train, test, validatate at 60/20/20 division\n",
        "rand_state = 0\n",
        "\n",
        "# optimizer\n",
        "lr = 0.001\n",
        "\n",
        "# model creation\n",
        "num_hidden_layers = 2\n",
        "neurons_per_hidden_layer = 5\n",
        "\n",
        "# model trainin\n",
        "num_epochs = 1000\n",
        "batches = 1\n"
      ],
      "metadata": {
        "id": "nzrcaQTpH4qv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import CondensedNearestNeighbour "
      ],
      "metadata": {
        "id": "amoLEWf0NCzc"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/55119651/downsampling-for-more-than-2-classes\n",
        "# def downsample(X, y, label):\n",
        "#   data = pd.concat([X, y], axis=1)\n",
        "#   g = data.groupby(label, group_keys=False)\n",
        "#   balanced = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()))).reset_index(drop=True)\n",
        "#   return balanced.iloc[:, :-1], balanced.iloc[:, -1]\n",
        "\n",
        "def pipeline(X, y, label):\n",
        "  cnn = CondensedNearestNeighbour(random_state=rand_state) \n",
        "  X_res, y_res = cnn.fit_resample(X, y) \n",
        "  return X_res, pd.get_dummies(y_res, prefix=label)\n",
        "\n",
        "# partition into train, validate, test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=splits[0], random_state=rand_state, shuffle=True, stratify=y)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, train_size=(splits[1] / (splits[1] + splits[2])), random_state=rand_state, shuffle=True, stratify=y_temp)\n",
        "\n",
        "label='size'\n",
        "\n",
        "X_train, y_train = pipeline(X_train, y_train, 'size')\n",
        "X_test, y_test = pipeline(X_test, y_test, 'size')\n",
        "X_val, y_val = pipeline(X_val, y_val, 'size')\n",
        "\n",
        "print(X_train)\n",
        "print(y_train.sum(axis=0))\n",
        "\n",
        "scale_cols = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']\n",
        "\n",
        "scaler = MinMaxScaler((0, 1)).fit(X_train[scale_cols])\n",
        "X_train[scale_cols] = scaler.transform(X_train[scale_cols])\n",
        "X_test[scale_cols] = scaler.transform(X_test[scale_cols])\n",
        "X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
        "\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "\n",
        "batch_size = math.floor(X_train.shape[0] / batches)\n",
        "print(batch_size)"
      ],
      "metadata": {
        "id": "jlB1FP7kDRWI",
        "outputId": "b610ea93-d475-4fb9-8df0-f7fa54c4e42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain\n",
            "0    3  4      7    3  91.9  133.6  520.5   8.0  14.2  58   4.0   0.0\n",
            "1    4  4      3    5  85.9   19.5   57.3   2.8  13.7  43   5.8   0.0\n",
            "2    8  6      8    7  91.4  142.4  601.4  10.6  18.2  43   4.9   0.0\n",
            "3    3  4      9    7  92.4  124.1  680.7   8.5  22.5  42   5.4   0.0\n",
            "4    3  4      8    7  91.4  142.4  601.4  10.6  11.6  87   4.5   0.0\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...\n",
            "176  5  4      8    2  95.1  141.3  605.8  17.7  26.4  34   3.6   0.0\n",
            "177  9  4      6    6  90.5   61.1  252.6   9.4  24.5  50   3.1   0.0\n",
            "178  1  3      8    5  95.9  158.0  633.6  11.3  27.5  29   4.5   0.0\n",
            "179  9  4      9    2  84.4   73.4  671.9   3.2  24.3  36   3.1   0.0\n",
            "180  5  4      2    5  85.2    4.9   15.8   6.3   7.5  46   8.0   0.0\n",
            "\n",
            "[181 rows x 12 columns]\n",
            "size_0    60\n",
            "size_1    54\n",
            "size_2    34\n",
            "size_3    33\n",
            "dtype: int64\n",
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    3  4      7    3  0.908096  0.453911  0.604255  0.136445  0.345324   \n",
            "1    4  4      3    5  0.776805  0.055517  0.056738  0.043088  0.327338   \n",
            "2    8  6      8    7  0.897155  0.484637  0.699882  0.183124  0.489209   \n",
            "3    3  4      9    7  0.919037  0.420740  0.793617  0.145422  0.643885   \n",
            "4    3  4      8    7  0.897155  0.484637  0.699882  0.183124  0.251799   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "176  5  4      8    2  0.978118  0.480796  0.705083  0.310592  0.784173   \n",
            "177  9  4      6    6  0.877462  0.200768  0.287589  0.161580  0.715827   \n",
            "178  1  3      8    5  0.995624  0.539106  0.737943  0.195691  0.823741   \n",
            "179  9  4      9    2  0.743982  0.243715  0.783215  0.050269  0.708633   \n",
            "180  5  4      2    5  0.761488  0.004539  0.007683  0.105925  0.104317   \n",
            "\n",
            "           RH      wind  rain  \n",
            "0    0.506329  0.364706   0.0  \n",
            "1    0.316456  0.576471   0.0  \n",
            "2    0.316456  0.470588   0.0  \n",
            "3    0.303797  0.529412   0.0  \n",
            "4    0.873418  0.423529   0.0  \n",
            "..        ...       ...   ...  \n",
            "176  0.202532  0.317647   0.0  \n",
            "177  0.405063  0.258824   0.0  \n",
            "178  0.139241  0.423529   0.0  \n",
            "179  0.227848  0.258824   0.0  \n",
            "180  0.354430  0.835294   0.0  \n",
            "\n",
            "[181 rows x 12 columns]\n",
            "     size_0  size_1  size_2  size_3\n",
            "0         1       0       0       0\n",
            "1         1       0       0       0\n",
            "2         1       0       0       0\n",
            "3         1       0       0       0\n",
            "4         1       0       0       0\n",
            "..      ...     ...     ...     ...\n",
            "176       0       0       0       1\n",
            "177       0       0       0       1\n",
            "178       0       0       0       1\n",
            "179       0       0       0       1\n",
            "180       0       0       0       1\n",
            "\n",
            "[181 rows x 4 columns]\n",
            "181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "47OG36GcDSHu",
        "outputId": "d460a3b8-278b-4671-96d9-ff55060845eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(181, 12)\n",
            "(60, 12)\n",
            "(63, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Preprocessing - normaization?"
      ],
      "metadata": {
        "id": "00mPJfUPRYUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X.shape[1]\n",
        "num_classes = 4\n",
        "# define the keras model\n",
        "# N_input - neurons_per_hidden_layer - N_labels configuration, relu and sigmoid activation for the \n",
        "# hidden layer and output layer respectively\n",
        "\n",
        "#TODO: dynamic number of layers :)\n",
        "net = tf.keras.models.Sequential()\n",
        "net.add(tf.keras.layers.Dense(units=neurons_per_hidden_layer, input_dim=input_dim, activation = 'relu')) # input layer\n",
        "for l in range(num_hidden_layers):\n",
        "  net.add(tf.keras.layers.Dense(units=neurons_per_hidden_layer, activation = 'relu')) # deep layer\n",
        "net.add(tf.keras.layers.Dense(units=num_classes, activation='softmax')) # output layer"
      ],
      "metadata": {
        "id": "Cc9wmG7KDTox"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# compile the keras model\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr\n",
        ")\n",
        "\n",
        "net.compile(loss='CategoricalCrossentropy', optimizer=opt, \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QPzedSr2DUmS"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the keras model on the dataset\n",
        "callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history = net.fit(X_train, y_train, epochs=num_epochs, verbose=1, batch_size=batch_size, \n",
        "                  validation_data=(X_val,y_val), callbacks=[callback])"
      ],
      "metadata": {
        "id": "UM01KzR6QF_3",
        "outputId": "0f64a274-66e6-4a2f-a704-67a11b22dcab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 1s 624ms/step - loss: 1.9570 - accuracy: 0.3039 - val_loss: 1.8412 - val_accuracy: 0.3000\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9362 - accuracy: 0.3039 - val_loss: 1.8218 - val_accuracy: 0.3000\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9157 - accuracy: 0.3039 - val_loss: 1.8026 - val_accuracy: 0.3000\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8957 - accuracy: 0.3039 - val_loss: 1.7839 - val_accuracy: 0.3000\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.8761 - accuracy: 0.2928 - val_loss: 1.7655 - val_accuracy: 0.3000\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.8572 - accuracy: 0.2928 - val_loss: 1.7474 - val_accuracy: 0.3000\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8390 - accuracy: 0.2928 - val_loss: 1.7298 - val_accuracy: 0.2833\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8210 - accuracy: 0.2928 - val_loss: 1.7127 - val_accuracy: 0.2833\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.8034 - accuracy: 0.2928 - val_loss: 1.6961 - val_accuracy: 0.2833\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7861 - accuracy: 0.2928 - val_loss: 1.6799 - val_accuracy: 0.2833\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7692 - accuracy: 0.2928 - val_loss: 1.6642 - val_accuracy: 0.2833\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7528 - accuracy: 0.2928 - val_loss: 1.6490 - val_accuracy: 0.2833\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.7368 - accuracy: 0.2873 - val_loss: 1.6343 - val_accuracy: 0.3000\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7213 - accuracy: 0.2873 - val_loss: 1.6202 - val_accuracy: 0.3000\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7061 - accuracy: 0.2873 - val_loss: 1.6066 - val_accuracy: 0.3000\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.6912 - accuracy: 0.2873 - val_loss: 1.5934 - val_accuracy: 0.3000\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6768 - accuracy: 0.2818 - val_loss: 1.5804 - val_accuracy: 0.2833\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6629 - accuracy: 0.2818 - val_loss: 1.5679 - val_accuracy: 0.3000\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.6494 - accuracy: 0.2762 - val_loss: 1.5559 - val_accuracy: 0.2833\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.6362 - accuracy: 0.2762 - val_loss: 1.5448 - val_accuracy: 0.2833\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6235 - accuracy: 0.2707 - val_loss: 1.5347 - val_accuracy: 0.2833\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6115 - accuracy: 0.2707 - val_loss: 1.5257 - val_accuracy: 0.2833\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6000 - accuracy: 0.2707 - val_loss: 1.5172 - val_accuracy: 0.2833\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.5889 - accuracy: 0.2707 - val_loss: 1.5092 - val_accuracy: 0.2833\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.5784 - accuracy: 0.2707 - val_loss: 1.5015 - val_accuracy: 0.2667\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.5684 - accuracy: 0.2652 - val_loss: 1.4944 - val_accuracy: 0.2667\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.5588 - accuracy: 0.2652 - val_loss: 1.4878 - val_accuracy: 0.2667\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.5497 - accuracy: 0.2486 - val_loss: 1.4813 - val_accuracy: 0.2667\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.5407 - accuracy: 0.2376 - val_loss: 1.4743 - val_accuracy: 0.2833\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.5318 - accuracy: 0.2431 - val_loss: 1.4676 - val_accuracy: 0.3000\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5234 - accuracy: 0.2431 - val_loss: 1.4613 - val_accuracy: 0.3000\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5155 - accuracy: 0.2431 - val_loss: 1.4553 - val_accuracy: 0.3333\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.5081 - accuracy: 0.2376 - val_loss: 1.4498 - val_accuracy: 0.3333\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5008 - accuracy: 0.2376 - val_loss: 1.4447 - val_accuracy: 0.3333\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.4938 - accuracy: 0.2431 - val_loss: 1.4399 - val_accuracy: 0.3333\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4874 - accuracy: 0.2486 - val_loss: 1.4353 - val_accuracy: 0.3333\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4814 - accuracy: 0.2431 - val_loss: 1.4310 - val_accuracy: 0.3333\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4757 - accuracy: 0.2486 - val_loss: 1.4269 - val_accuracy: 0.3167\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4704 - accuracy: 0.2376 - val_loss: 1.4226 - val_accuracy: 0.3167\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4655 - accuracy: 0.2376 - val_loss: 1.4186 - val_accuracy: 0.3000\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4607 - accuracy: 0.2376 - val_loss: 1.4147 - val_accuracy: 0.3000\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4561 - accuracy: 0.2376 - val_loss: 1.4112 - val_accuracy: 0.3167\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4516 - accuracy: 0.2265 - val_loss: 1.4079 - val_accuracy: 0.2833\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4475 - accuracy: 0.2155 - val_loss: 1.4049 - val_accuracy: 0.2667\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4436 - accuracy: 0.2155 - val_loss: 1.4021 - val_accuracy: 0.2833\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4400 - accuracy: 0.2155 - val_loss: 1.3995 - val_accuracy: 0.2833\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4364 - accuracy: 0.2320 - val_loss: 1.3967 - val_accuracy: 0.2833\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4327 - accuracy: 0.2320 - val_loss: 1.3940 - val_accuracy: 0.3167\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.4292 - accuracy: 0.2376 - val_loss: 1.3916 - val_accuracy: 0.3000\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4262 - accuracy: 0.2541 - val_loss: 1.3892 - val_accuracy: 0.3000\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4235 - accuracy: 0.2597 - val_loss: 1.3870 - val_accuracy: 0.3000\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.4209 - accuracy: 0.2597 - val_loss: 1.3849 - val_accuracy: 0.3000\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4187 - accuracy: 0.2652 - val_loss: 1.3828 - val_accuracy: 0.3000\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4165 - accuracy: 0.2597 - val_loss: 1.3810 - val_accuracy: 0.3000\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4142 - accuracy: 0.2486 - val_loss: 1.3793 - val_accuracy: 0.3000\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4122 - accuracy: 0.2541 - val_loss: 1.3777 - val_accuracy: 0.2833\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4103 - accuracy: 0.2541 - val_loss: 1.3760 - val_accuracy: 0.3000\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4084 - accuracy: 0.2541 - val_loss: 1.3744 - val_accuracy: 0.2833\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4066 - accuracy: 0.2486 - val_loss: 1.3730 - val_accuracy: 0.2667\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4049 - accuracy: 0.2541 - val_loss: 1.3716 - val_accuracy: 0.3000\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4033 - accuracy: 0.2541 - val_loss: 1.3706 - val_accuracy: 0.3000\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4018 - accuracy: 0.2541 - val_loss: 1.3695 - val_accuracy: 0.3000\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4005 - accuracy: 0.2541 - val_loss: 1.3682 - val_accuracy: 0.3000\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3991 - accuracy: 0.2486 - val_loss: 1.3669 - val_accuracy: 0.3167\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3978 - accuracy: 0.2541 - val_loss: 1.3656 - val_accuracy: 0.3167\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3965 - accuracy: 0.2597 - val_loss: 1.3644 - val_accuracy: 0.3167\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3953 - accuracy: 0.2597 - val_loss: 1.3633 - val_accuracy: 0.3333\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3941 - accuracy: 0.2597 - val_loss: 1.3622 - val_accuracy: 0.3500\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3929 - accuracy: 0.2707 - val_loss: 1.3609 - val_accuracy: 0.3500\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3918 - accuracy: 0.2707 - val_loss: 1.3598 - val_accuracy: 0.3500\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3907 - accuracy: 0.2707 - val_loss: 1.3588 - val_accuracy: 0.3500\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3897 - accuracy: 0.2707 - val_loss: 1.3579 - val_accuracy: 0.3500\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3888 - accuracy: 0.2762 - val_loss: 1.3570 - val_accuracy: 0.3500\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3880 - accuracy: 0.2818 - val_loss: 1.3563 - val_accuracy: 0.3333\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3872 - accuracy: 0.2762 - val_loss: 1.3556 - val_accuracy: 0.3333\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3865 - accuracy: 0.2762 - val_loss: 1.3550 - val_accuracy: 0.3333\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3859 - accuracy: 0.2707 - val_loss: 1.3544 - val_accuracy: 0.3333\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3852 - accuracy: 0.2707 - val_loss: 1.3539 - val_accuracy: 0.3333\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3845 - accuracy: 0.2707 - val_loss: 1.3534 - val_accuracy: 0.3167\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3839 - accuracy: 0.2707 - val_loss: 1.3529 - val_accuracy: 0.3167\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3833 - accuracy: 0.2707 - val_loss: 1.3525 - val_accuracy: 0.3167\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3827 - accuracy: 0.2762 - val_loss: 1.3521 - val_accuracy: 0.3167\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3822 - accuracy: 0.2873 - val_loss: 1.3518 - val_accuracy: 0.3167\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3816 - accuracy: 0.2873 - val_loss: 1.3515 - val_accuracy: 0.3167\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3810 - accuracy: 0.2873 - val_loss: 1.3513 - val_accuracy: 0.3167\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3805 - accuracy: 0.2762 - val_loss: 1.3511 - val_accuracy: 0.3167\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3799 - accuracy: 0.2707 - val_loss: 1.3509 - val_accuracy: 0.3167\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3793 - accuracy: 0.2707 - val_loss: 1.3507 - val_accuracy: 0.3167\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3787 - accuracy: 0.2762 - val_loss: 1.3506 - val_accuracy: 0.3333\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3782 - accuracy: 0.2762 - val_loss: 1.3504 - val_accuracy: 0.3333\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3777 - accuracy: 0.2818 - val_loss: 1.3503 - val_accuracy: 0.3500\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3772 - accuracy: 0.2762 - val_loss: 1.3502 - val_accuracy: 0.3500\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3768 - accuracy: 0.2762 - val_loss: 1.3500 - val_accuracy: 0.3667\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3764 - accuracy: 0.2818 - val_loss: 1.3498 - val_accuracy: 0.3667\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3759 - accuracy: 0.2818 - val_loss: 1.3496 - val_accuracy: 0.3667\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3755 - accuracy: 0.2818 - val_loss: 1.3494 - val_accuracy: 0.3667\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3751 - accuracy: 0.2873 - val_loss: 1.3491 - val_accuracy: 0.3500\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3747 - accuracy: 0.2928 - val_loss: 1.3489 - val_accuracy: 0.3667\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3743 - accuracy: 0.2928 - val_loss: 1.3486 - val_accuracy: 0.3667\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3739 - accuracy: 0.2928 - val_loss: 1.3483 - val_accuracy: 0.3667\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3735 - accuracy: 0.2983 - val_loss: 1.3481 - val_accuracy: 0.3667\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3731 - accuracy: 0.2983 - val_loss: 1.3478 - val_accuracy: 0.3667\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3727 - accuracy: 0.2983 - val_loss: 1.3476 - val_accuracy: 0.3667\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3723 - accuracy: 0.2928 - val_loss: 1.3473 - val_accuracy: 0.3667\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3720 - accuracy: 0.2928 - val_loss: 1.3471 - val_accuracy: 0.3833\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3716 - accuracy: 0.3039 - val_loss: 1.3469 - val_accuracy: 0.3833\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3712 - accuracy: 0.2928 - val_loss: 1.3468 - val_accuracy: 0.3833\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3708 - accuracy: 0.2928 - val_loss: 1.3465 - val_accuracy: 0.3833\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3705 - accuracy: 0.2928 - val_loss: 1.3463 - val_accuracy: 0.3833\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3701 - accuracy: 0.2873 - val_loss: 1.3462 - val_accuracy: 0.3833\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3698 - accuracy: 0.2983 - val_loss: 1.3460 - val_accuracy: 0.3833\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3694 - accuracy: 0.2928 - val_loss: 1.3458 - val_accuracy: 0.3833\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3690 - accuracy: 0.2928 - val_loss: 1.3457 - val_accuracy: 0.4000\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3687 - accuracy: 0.2928 - val_loss: 1.3456 - val_accuracy: 0.4000\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3683 - accuracy: 0.2928 - val_loss: 1.3455 - val_accuracy: 0.4000\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3679 - accuracy: 0.2873 - val_loss: 1.3455 - val_accuracy: 0.4000\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3676 - accuracy: 0.2873 - val_loss: 1.3454 - val_accuracy: 0.4167\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3672 - accuracy: 0.2818 - val_loss: 1.3454 - val_accuracy: 0.4167\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3669 - accuracy: 0.2873 - val_loss: 1.3454 - val_accuracy: 0.4167\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3666 - accuracy: 0.2818 - val_loss: 1.3454 - val_accuracy: 0.4167\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3662 - accuracy: 0.2818 - val_loss: 1.3454 - val_accuracy: 0.4000\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3659 - accuracy: 0.2818 - val_loss: 1.3454 - val_accuracy: 0.4000\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3656 - accuracy: 0.2762 - val_loss: 1.3455 - val_accuracy: 0.4000\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3653 - accuracy: 0.2762 - val_loss: 1.3455 - val_accuracy: 0.3667\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3650 - accuracy: 0.2818 - val_loss: 1.3456 - val_accuracy: 0.3667\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3647 - accuracy: 0.2873 - val_loss: 1.3457 - val_accuracy: 0.3667\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3645 - accuracy: 0.2873 - val_loss: 1.3457 - val_accuracy: 0.3667\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3642 - accuracy: 0.2928 - val_loss: 1.3458 - val_accuracy: 0.3500\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3639 - accuracy: 0.2983 - val_loss: 1.3459 - val_accuracy: 0.3333\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3637 - accuracy: 0.2983 - val_loss: 1.3459 - val_accuracy: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can visualize the results with a confusion matrix.\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_confusion_matrix(y_classified, y_true):\n",
        "  # Compute confusion matrix\n",
        "  c_mat = np.zeros((num_classes,num_classes))\n",
        "  for i in range(len(y_true)):\n",
        "    c_mat[y_classified[i], y_true[i] ] += 1\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in c_mat.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in c_mat.flatten()/np.sum(c_mat)]\n",
        "  labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  labels = np.asarray(labels).reshape(c_mat.shape[0], c_mat.shape[1])\n",
        "\n",
        "  plt.figure(figsize=(12,10))\n",
        "  sn.heatmap(c_mat, annot=labels, fmt='', cmap='rocket_r')\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.ylabel('Output Class')\n",
        "  plt.xlabel('Target Class')"
      ],
      "metadata": {
        "id": "O91LTNFgDXOn"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the trained model using keras built-in function\n",
        "score = net.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1]) \n",
        "\n",
        "y_classified = np.argmax(net.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test.to_numpy(), axis=1)\n",
        "# plot confusion matrix\n",
        "plot_confusion_matrix(y_classified, y_true)"
      ],
      "metadata": {
        "id": "01q6CPi0DYZd",
        "outputId": "e33daed6-f694-47ec-ced9-2ccc91276462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3534 - accuracy: 0.3492\n",
            "Test loss: 1.3534141778945923\n",
            "Test accuracy: 0.3492063581943512\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2a1bb25c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bcvu_gzYDaex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}