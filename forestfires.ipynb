{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestfires.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boraks4/539-project/blob/main/forestfires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "\n",
        "import math"
      ],
      "metadata": {
        "id": "2FaXlb5Wi4lO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Credits to https://stackoverflow.com/a/57539179\n",
        "# Doesn't seem like we need this anymore\n",
        "def connect_github_and_imports():\n",
        "  import os\n",
        "  from getpass import getpass\n",
        "  import urllib\n",
        "\n",
        "  user = input('User name: ')\n",
        "  password = getpass('Password: ')\n",
        "  password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "  cmd_string = 'git clone https://{0}:{1}@github.com/boraks4/539-project.git'.format(user, password)\n",
        "\n",
        "  os.system(cmd_string)\n",
        "  cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "  %cd 539-project\n",
        "# connect_github_and_imports()"
      ],
      "metadata": {
        "id": "merjZ6yJcTtX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(X, y, label):\n",
        "  cnn = CondensedNearestNeighbour(random_state=0) \n",
        "  X_res, y_res = cnn.fit_resample(X, y) \n",
        "  return X_res, pd.get_dummies(y_res, prefix=label)\n",
        "\n",
        "# splits: train, test, validatate at 60/20/20 division\n",
        "def preprocess_data(print_ = False, splits = (.6,.2,.2)):\n",
        "  # read from file; convert dates to category\n",
        "  fires = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv')\n",
        "  fires.month=fires.month.map({'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12})\n",
        "  fires.day=fires.day.map({'mon':1,'tue':2,'wed':3,'thu':4,'fri':5,'sat':6,'sun':7})\n",
        "  if print_:\n",
        "    print(\"raw from .csv\")\n",
        "    print(fires)\n",
        "  \n",
        "  # group the data based on fire size\n",
        "  zeros = fires[fires['area'] == 0]\n",
        "  zeros = zeros.assign(size=0)\n",
        "\n",
        "  no_zeros = fires[fires['area'] != 0]\n",
        "  no_zeros = no_zeros.assign(size=pd.qcut(no_zeros['area'], 3, labels=[1, 2, 3]))\n",
        "      \n",
        "  fires_quant = pd.concat([zeros, no_zeros])\n",
        "  fires_quant = fires_quant.drop(['area'], axis=1)\n",
        "  if(print_):\n",
        "    print(fires_quant)\n",
        "    print(fires_quant['size'].value_counts())\n",
        "  \n",
        "  # separate the labels from the feature set\n",
        "  X = fires_quant.iloc[:,:-1]\n",
        "  y = fires_quant.iloc[:,-1]\n",
        "  if(print_):\n",
        "    print(\"\\nseparated features from labels\")\n",
        "    print(X)\n",
        "    print(y)\n",
        "  \n",
        "  # partition into train, validate, test sets\n",
        "  X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=splits[0], random_state=0, shuffle=True, stratify=y)\n",
        "  X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, train_size=(splits[1] / (splits[1] + splits[2])), random_state=0, shuffle=True, stratify=y_temp)\n",
        "\n",
        "    # normalize data\n",
        "  scale_cols = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']\n",
        "\n",
        "  scaler = MinMaxScaler((0, 1)).fit(X_train[scale_cols])\n",
        "  X_train[scale_cols] = scaler.transform(X_train[scale_cols])\n",
        "  X_test[scale_cols] = scaler.transform(X_test[scale_cols])\n",
        "  X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
        "\n",
        "  if(print_):\n",
        "    print(\"\\npost normalization!\")\n",
        "    print(X_train)\n",
        "    print(y_train)\n",
        "\n",
        "  # account for underfitting\n",
        "  X_train, y_train = pipeline(X_train, y_train, 'size')\n",
        "  X_test, y_test = pipeline(X_test, y_test, 'size')\n",
        "  X_val, y_val = pipeline(X_val, y_val, 'size')\n",
        "\n",
        "  if(print_):\n",
        "    \n",
        "    print(\"\\nX_val shape:\")\n",
        "    print(X_val.shape)\n",
        "    print(\"X_test shape:\")\n",
        "    print(X_test.shape)\n",
        "    print(\"X_train shape:\")\n",
        "    print(X_train.shape)\n",
        "    print(\"\\nX_train\")\n",
        "    print(X_train)\n",
        "    \n",
        "    print(y_train.sum(axis=0))\n",
        "    \n",
        "  \n",
        "  return X_train, y_train, X_test, y_test, X_val, y_val"
      ],
      "metadata": {
        "id": "qXGFzApWWEXd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import CondensedNearestNeighbour "
      ],
      "metadata": {
        "id": "amoLEWf0NCzc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/55119651/downsampling-for-more-than-2-classes\n",
        "# def downsample(X, y, label):\n",
        "#   data = pd.concat([X, y], axis=1)\n",
        "#   g = data.groupby(label, group_keys=False)\n",
        "#   balanced = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()))).reset_index(drop=True)\n",
        "#   return balanced.iloc[:, :-1], balanced.iloc[:, -1]"
      ],
      "metadata": {
        "id": "jlB1FP7kDRWI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the model"
      ],
      "metadata": {
        "id": "ucjs_rHzc6PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the keras model\n",
        "# N_input - neurons_per_hidden_layer - N_labels configuration, relu and sigmoid activation for the \n",
        "# hidden layer and output layer respectively\n",
        "\n",
        "def construct_dnn(neurons_per_hidden_layer, num_hidden_layers, lr):\n",
        "  input_dim = 12 # Is this correct?\n",
        "  num_classes = 4\n",
        "\n",
        "  net = tf.keras.models.Sequential()\n",
        "  net.add(tf.keras.layers.Dense(units=neurons_per_hidden_layer, input_dim=input_dim, activation = 'relu')) # input layer\n",
        "  for l in range(num_hidden_layers):\n",
        "    net.add(tf.keras.layers.Dense(units=neurons_per_hidden_layer, activation = 'relu')) # deep layer\n",
        "  net.add(tf.keras.layers.Dense(units=num_classes, activation='softmax')) # output layer\n",
        "\n",
        "  # compile the keras model\n",
        "  opt = tf.keras.optimizers.Adam(\n",
        "      learning_rate=lr\n",
        "  )\n",
        "\n",
        "  net.compile(loss='CategoricalCrossentropy', optimizer=opt, \n",
        "                metrics=['accuracy'])\n",
        "  return net"
      ],
      "metadata": {
        "id": "Cc9wmG7KDTox"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can visualize the results with a confusion matrix.\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_confusion_matrix(y_classified, y_true, num_classes=4):\n",
        "  # Compute confusion matrix\n",
        "  c_mat = np.zeros((num_classes,num_classes))\n",
        "  for i in range(len(y_true)):\n",
        "    c_mat[y_classified[i], y_true[i] ] += 1\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in c_mat.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in c_mat.flatten()/np.sum(c_mat)]\n",
        "  labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  labels = np.asarray(labels).reshape(c_mat.shape[0], c_mat.shape[1])\n",
        "\n",
        "  plt.figure(figsize=(12,10))\n",
        "  sn.heatmap(c_mat, annot=labels, fmt='', cmap='rocket_r')\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.ylabel('Output Class')\n",
        "  plt.xlabel('Target Class')"
      ],
      "metadata": {
        "id": "O91LTNFgDXOn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints test loss, accuract; plots the confusion matrix of the net\n",
        "# returns score: (test loss, test accuracy)\n",
        "def evaluate_model(net):\n",
        "  # Evaluate the trained model using keras built-in function\n",
        "  score = net.evaluate(X_test, y_test, verbose=1)\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1]) \n",
        "\n",
        "  y_classified = np.argmax(net.predict(X_test), axis=1)\n",
        "  y_true = np.argmax(y_test.to_numpy(), axis=1)\n",
        "  # plot confusion matrix\n",
        "  plot_confusion_matrix(y_classified, y_true)\n",
        "  return score"
      ],
      "metadata": {
        "id": "01q6CPi0DYZd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparemeters\n",
        "nhl = 1 # num_hidden_layers\n",
        "nphl = 5 # neurons_per_hidden_layer\n",
        "lr = 0.001\n",
        "epochs = 1000\n",
        "batches = 10\n",
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = preprocess_data(True)\n",
        "batch_size = math.floor(X_train.shape[0] / batches)\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "net = construct_dnn(neurons_per_hidden_layer=5, num_hidden_layers=2, lr = lr)\n",
        "callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history = net.fit(X_train, y_train, epochs=epochs, verbose=1, batch_size=batch_size, \n",
        "                  validation_data=(X_val,y_val), callbacks=[callback])\n",
        "print(\"nhl: \",nhl, \"nphl:\", nphl, \"lr:\", lr, \"batches\", batches)\n",
        "evaluate_model(net)"
      ],
      "metadata": {
        "id": "UM01KzR6QF_3",
        "outputId": "79d3493e-7962-42d2-b5d8-e491aec6f26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw from .csv\n",
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
            "0    7  5      3    5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00\n",
            "1    7  4     10    2  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00\n",
            "2    7  4     10    6  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00\n",
            "3    8  6      3    5  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00\n",
            "4    8  6      3    7  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...    ...\n",
            "512  4  3      8    7  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44\n",
            "513  2  4      8    7  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29\n",
            "514  7  4      8    7  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16\n",
            "515  1  4      8    6  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00\n",
            "516  6  3     11    2  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00\n",
            "\n",
            "[517 rows x 13 columns]\n",
            "     X  Y  month  day  FFMC    DMC     DC  ISI  temp  RH  wind  rain  size\n",
            "0    7  5      3    5  86.2   26.2   94.3  5.1   8.2  51   6.7   0.0     0\n",
            "1    7  4     10    2  90.6   35.4  669.1  6.7  18.0  33   0.9   0.0     0\n",
            "2    7  4     10    6  90.6   43.7  686.9  6.7  14.6  33   1.3   0.0     0\n",
            "3    8  6      3    5  91.7   33.3   77.5  9.0   8.3  97   4.0   0.2     0\n",
            "4    8  6      3    7  89.3   51.3  102.2  9.6  11.4  99   1.8   0.0     0\n",
            "..  .. ..    ...  ...   ...    ...    ...  ...   ...  ..   ...   ...   ...\n",
            "509  5  4      8    5  91.0  166.9  752.6  7.1  21.1  71   7.6   1.4     1\n",
            "510  6  5      8    5  91.0  166.9  752.6  7.1  18.2  62   5.4   0.0     1\n",
            "512  4  3      8    7  81.6   56.7  665.6  1.9  27.8  32   2.7   0.0     2\n",
            "513  2  4      8    7  81.6   56.7  665.6  1.9  21.9  71   5.8   0.0     3\n",
            "514  7  4      8    7  81.6   56.7  665.6  1.9  21.2  70   6.7   0.0     3\n",
            "\n",
            "[517 rows x 13 columns]\n",
            "0    247\n",
            "1     90\n",
            "2     90\n",
            "3     90\n",
            "Name: size, dtype: int64\n",
            "\n",
            "separated features from labels\n",
            "     X  Y  month  day  FFMC    DMC     DC  ISI  temp  RH  wind  rain\n",
            "0    7  5      3    5  86.2   26.2   94.3  5.1   8.2  51   6.7   0.0\n",
            "1    7  4     10    2  90.6   35.4  669.1  6.7  18.0  33   0.9   0.0\n",
            "2    7  4     10    6  90.6   43.7  686.9  6.7  14.6  33   1.3   0.0\n",
            "3    8  6      3    5  91.7   33.3   77.5  9.0   8.3  97   4.0   0.2\n",
            "4    8  6      3    7  89.3   51.3  102.2  9.6  11.4  99   1.8   0.0\n",
            "..  .. ..    ...  ...   ...    ...    ...  ...   ...  ..   ...   ...\n",
            "509  5  4      8    5  91.0  166.9  752.6  7.1  21.1  71   7.6   1.4\n",
            "510  6  5      8    5  91.0  166.9  752.6  7.1  18.2  62   5.4   0.0\n",
            "512  4  3      8    7  81.6   56.7  665.6  1.9  27.8  32   2.7   0.0\n",
            "513  2  4      8    7  81.6   56.7  665.6  1.9  21.9  71   5.8   0.0\n",
            "514  7  4      8    7  81.6   56.7  665.6  1.9  21.2  70   6.7   0.0\n",
            "\n",
            "[517 rows x 12 columns]\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "509    1\n",
            "510    1\n",
            "512    2\n",
            "513    3\n",
            "514    3\n",
            "Name: size, Length: 517, dtype: int64\n",
            "\n",
            "post normalization!\n",
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "110  4  4      3    5  0.776805  0.059190  0.057934  0.043088  0.380795   \n",
            "482  3  4      8    7  0.973742  0.442714  0.679254  0.245961  0.701987   \n",
            "93   8  6      8    7  0.897155  0.484597  0.696024  0.183124  0.529801   \n",
            "455  3  4      7    1  0.967177  0.545517  0.655917  0.292639  0.519868   \n",
            "164  8  5      9    7  0.859956  0.303219  0.816817  0.078995  0.516556   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "366  4  5      9    2  0.890591  0.449637  0.943122  0.217235  0.453642   \n",
            "147  8  3      9    2  0.743982  0.245760  0.778703  0.050269  0.728477   \n",
            "476  4  3      7    4  0.943107  0.286951  0.453970  0.170557  0.827815   \n",
            "60   2  2      3    7  0.851204  0.169263  0.110590  0.165171  0.307947   \n",
            "508  1  2      8    5  0.888403  0.569401  0.873343  0.120287  0.784768   \n",
            "\n",
            "           RH      wind  rain  \n",
            "110  0.317073  0.576471   0.0  \n",
            "482  0.280488  0.576471   0.0  \n",
            "93   0.317073  0.470588   0.0  \n",
            "455  0.378049  0.211765   0.0  \n",
            "164  0.609756  0.152941   0.0  \n",
            "..        ...       ...   ...  \n",
            "366  0.256098  0.529412   0.0  \n",
            "147  0.134146  0.317647   0.0  \n",
            "476  0.134146  0.047059   0.0  \n",
            "60   0.268293  0.576471   0.0  \n",
            "508  0.292683  0.317647   0.0  \n",
            "\n",
            "[310 rows x 12 columns]\n",
            "110    0\n",
            "482    1\n",
            "93     0\n",
            "455    0\n",
            "164    1\n",
            "      ..\n",
            "366    1\n",
            "147    1\n",
            "476    1\n",
            "60     0\n",
            "508    0\n",
            "Name: size, Length: 310, dtype: int64\n",
            "\n",
            "X_val shape:\n",
            "(65, 12)\n",
            "X_test shape:\n",
            "(63, 12)\n",
            "X_train shape:\n",
            "(186, 12)\n",
            "\n",
            "X_train\n",
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    3  4      7    3  0.908096  0.454136  0.601149  0.136445  0.397351   \n",
            "1    4  4      3    5  0.776805  0.059190  0.057934  0.043088  0.380795   \n",
            "2    8  6      8    7  0.897155  0.484597  0.696024  0.183124  0.529801   \n",
            "3    3  4      9    7  0.919037  0.421253  0.789023  0.145422  0.672185   \n",
            "4    3  6      9    7  0.919037  0.421253  0.789023  0.145422  0.496689   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "181  9  4      6    6  0.877462  0.203184  0.286971  0.161580  0.738411   \n",
            "182  9  6      8    4  0.901532  0.851506  0.874751  0.105925  0.605960   \n",
            "183  1  3      8    5  0.995624  0.538595  0.733787  0.195691  0.837748   \n",
            "184  9  4      9    2  0.743982  0.245760  0.778703  0.050269  0.731788   \n",
            "185  1  4      8    3  0.903720  0.654206  0.736484  0.132855  0.586093   \n",
            "\n",
            "           RH      wind  rain  \n",
            "0    0.500000  0.364706   0.0  \n",
            "1    0.317073  0.576471   0.0  \n",
            "2    0.317073  0.470588   0.0  \n",
            "3    0.304878  0.529412   0.0  \n",
            "4    0.500000  0.047059   0.0  \n",
            "..        ...       ...   ...  \n",
            "181  0.402439  0.258824   0.0  \n",
            "182  0.500000  0.211765   0.0  \n",
            "183  0.146341  0.423529   0.0  \n",
            "184  0.231707  0.258824   0.0  \n",
            "185  0.402439  0.364706   0.0  \n",
            "\n",
            "[186 rows x 12 columns]\n",
            "size_0    59\n",
            "size_1    54\n",
            "size_2    38\n",
            "size_3    35\n",
            "dtype: int64\n",
            "Epoch 1/1000\n",
            "11/11 [==============================] - 1s 21ms/step - loss: 1.4720 - accuracy: 0.2903 - val_loss: 1.4563 - val_accuracy: 0.2769\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4238 - accuracy: 0.2903 - val_loss: 1.4259 - val_accuracy: 0.2769\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4061 - accuracy: 0.3065 - val_loss: 1.4117 - val_accuracy: 0.2923\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3970 - accuracy: 0.2957 - val_loss: 1.4056 - val_accuracy: 0.2923\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3911 - accuracy: 0.3011 - val_loss: 1.4014 - val_accuracy: 0.2462\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3867 - accuracy: 0.2903 - val_loss: 1.3975 - val_accuracy: 0.2154\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3830 - accuracy: 0.3226 - val_loss: 1.3946 - val_accuracy: 0.2308\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3803 - accuracy: 0.3172 - val_loss: 1.3912 - val_accuracy: 0.2769\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3788 - accuracy: 0.3172 - val_loss: 1.3875 - val_accuracy: 0.2769\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3771 - accuracy: 0.3226 - val_loss: 1.3848 - val_accuracy: 0.2615\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3751 - accuracy: 0.3333 - val_loss: 1.3838 - val_accuracy: 0.2769\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3738 - accuracy: 0.3387 - val_loss: 1.3828 - val_accuracy: 0.2769\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3724 - accuracy: 0.3441 - val_loss: 1.3810 - val_accuracy: 0.2769\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3714 - accuracy: 0.3387 - val_loss: 1.3798 - val_accuracy: 0.2769\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3703 - accuracy: 0.3387 - val_loss: 1.3795 - val_accuracy: 0.2769\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3694 - accuracy: 0.3333 - val_loss: 1.3789 - val_accuracy: 0.2615\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3686 - accuracy: 0.3333 - val_loss: 1.3776 - val_accuracy: 0.2615\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3679 - accuracy: 0.3333 - val_loss: 1.3772 - val_accuracy: 0.2615\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3669 - accuracy: 0.3280 - val_loss: 1.3770 - val_accuracy: 0.2615\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3663 - accuracy: 0.3280 - val_loss: 1.3766 - val_accuracy: 0.2769\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3656 - accuracy: 0.3333 - val_loss: 1.3764 - val_accuracy: 0.2769\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3651 - accuracy: 0.3333 - val_loss: 1.3756 - val_accuracy: 0.2769\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3643 - accuracy: 0.3333 - val_loss: 1.3750 - val_accuracy: 0.2769\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3637 - accuracy: 0.3333 - val_loss: 1.3746 - val_accuracy: 0.2923\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3632 - accuracy: 0.3333 - val_loss: 1.3745 - val_accuracy: 0.2769\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3626 - accuracy: 0.3333 - val_loss: 1.3739 - val_accuracy: 0.2923\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3623 - accuracy: 0.3333 - val_loss: 1.3734 - val_accuracy: 0.2923\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3618 - accuracy: 0.3333 - val_loss: 1.3728 - val_accuracy: 0.2923\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3615 - accuracy: 0.3387 - val_loss: 1.3723 - val_accuracy: 0.3077\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3609 - accuracy: 0.3441 - val_loss: 1.3720 - val_accuracy: 0.2923\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3603 - accuracy: 0.3441 - val_loss: 1.3724 - val_accuracy: 0.3077\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.3387 - val_loss: 1.3715 - val_accuracy: 0.3077\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3601 - accuracy: 0.3441 - val_loss: 1.3706 - val_accuracy: 0.3385\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3595 - accuracy: 0.3387 - val_loss: 1.3699 - val_accuracy: 0.2923\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3594 - accuracy: 0.3441 - val_loss: 1.3702 - val_accuracy: 0.3077\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3589 - accuracy: 0.3441 - val_loss: 1.3706 - val_accuracy: 0.3077\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3582 - accuracy: 0.3441 - val_loss: 1.3695 - val_accuracy: 0.3077\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3580 - accuracy: 0.3495 - val_loss: 1.3696 - val_accuracy: 0.3077\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3575 - accuracy: 0.3441 - val_loss: 1.3691 - val_accuracy: 0.3077\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3571 - accuracy: 0.3387 - val_loss: 1.3689 - val_accuracy: 0.3077\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3567 - accuracy: 0.3441 - val_loss: 1.3689 - val_accuracy: 0.3077\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.3441 - val_loss: 1.3690 - val_accuracy: 0.3077\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3564 - accuracy: 0.3441 - val_loss: 1.3690 - val_accuracy: 0.3077\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3560 - accuracy: 0.3387 - val_loss: 1.3687 - val_accuracy: 0.3077\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3557 - accuracy: 0.3387 - val_loss: 1.3679 - val_accuracy: 0.3231\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3551 - accuracy: 0.3333 - val_loss: 1.3678 - val_accuracy: 0.3077\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3552 - accuracy: 0.3333 - val_loss: 1.3676 - val_accuracy: 0.3077\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3544 - accuracy: 0.3280 - val_loss: 1.3686 - val_accuracy: 0.3077\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3548 - accuracy: 0.3441 - val_loss: 1.3680 - val_accuracy: 0.3077\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3545 - accuracy: 0.3441 - val_loss: 1.3678 - val_accuracy: 0.3385\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3540 - accuracy: 0.3387 - val_loss: 1.3674 - val_accuracy: 0.3077\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3540 - accuracy: 0.3333 - val_loss: 1.3677 - val_accuracy: 0.3077\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3536 - accuracy: 0.3387 - val_loss: 1.3676 - val_accuracy: 0.3077\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3535 - accuracy: 0.3333 - val_loss: 1.3677 - val_accuracy: 0.3077\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3530 - accuracy: 0.3333 - val_loss: 1.3682 - val_accuracy: 0.3077\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3528 - accuracy: 0.3333 - val_loss: 1.3685 - val_accuracy: 0.3077\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3524 - accuracy: 0.3333 - val_loss: 1.3681 - val_accuracy: 0.3077\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3521 - accuracy: 0.3387 - val_loss: 1.3681 - val_accuracy: 0.3077\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3521 - accuracy: 0.3387 - val_loss: 1.3675 - val_accuracy: 0.3077\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3519 - accuracy: 0.3387 - val_loss: 1.3671 - val_accuracy: 0.3077\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3517 - accuracy: 0.3495 - val_loss: 1.3675 - val_accuracy: 0.3077\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3516 - accuracy: 0.3441 - val_loss: 1.3675 - val_accuracy: 0.2923\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3514 - accuracy: 0.3441 - val_loss: 1.3674 - val_accuracy: 0.2923\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3514 - accuracy: 0.3387 - val_loss: 1.3679 - val_accuracy: 0.2923\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3507 - accuracy: 0.3441 - val_loss: 1.3675 - val_accuracy: 0.2923\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3505 - accuracy: 0.3441 - val_loss: 1.3676 - val_accuracy: 0.2923\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3503 - accuracy: 0.3441 - val_loss: 1.3684 - val_accuracy: 0.2923\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3503 - accuracy: 0.3441 - val_loss: 1.3677 - val_accuracy: 0.2923\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.3502 - accuracy: 0.3441 - val_loss: 1.3681 - val_accuracy: 0.2923\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3498 - accuracy: 0.3441 - val_loss: 1.3677 - val_accuracy: 0.3077\n",
            "nhl:  1 nphl: 5 lr: 0.001 batches 10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3353 - accuracy: 0.4127\n",
            "Test loss: 1.3352653980255127\n",
            "Test accuracy: 0.4126984179019928\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc2593e3b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3352653980255127, 0.4126984179019928]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bcvu_gzYDaex",
        "outputId": "6d010547-0d99-4363-a4cc-6881bcce04b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    }
  ]
}