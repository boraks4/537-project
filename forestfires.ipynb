{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestfires.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boraks4/539-project/blob/main/forestfires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credits to https://stackoverflow.com/a/57539179\n",
        "def connect_github_and_imports():\n",
        "  import os\n",
        "  from getpass import getpass\n",
        "  import urllib\n",
        "\n",
        "  user = input('User name: ')\n",
        "  password = getpass('Password: ')\n",
        "  password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "  cmd_string = 'git clone https://{0}:{1}@github.com/boraks4/539-project.git'.format(user, password)\n",
        "\n",
        "  os.system(cmd_string)\n",
        "  cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "  %cd 539-project\n",
        "connect_github_and_imports()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "merjZ6yJcTtX",
        "outputId": "2aed71fb-71f4-4f70-af4f-58bcac6e66ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User name: TheAlexSannikov\n",
            "Password: ··········\n",
            "/content/539-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(X, y, label):\n",
        "  cnn = CondensedNearestNeighbour(random_state=0) \n",
        "  X_res, y_res = cnn.fit_resample(X, y) \n",
        "  return X_res, pd.get_dummies(y_res, prefix=label)\n",
        "\n",
        "# splits: train, test, validatate at 60/20/20 division\n",
        "def preprocess_data(print_ = False, splits = (.6,.2,.2)):\n",
        "  # read from file; convert dates to category\n",
        "  fires = pd.read_csv('forestfires.csv', sep=',', header=0)\n",
        "  fires.month=fires.month.map({'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12})\n",
        "  fires.day=fires.day.map({'mon':1,'tue':2,'wed':3,'thu':4,'fri':5,'sat':6,'sun':7})\n",
        "  if print_:\n",
        "    print(\"raw from .csv\")\n",
        "    print(fires)\n",
        "  \n",
        "  # group the data based on fire size\n",
        "  zeros = fires[fires['area'] == 0]\n",
        "  zeros = zeros.assign(size=0)\n",
        "\n",
        "  no_zeros = fires[fires['area'] != 0]\n",
        "  no_zeros = no_zeros.assign(size=pd.qcut(no_zeros['area'], 3, labels=[1, 2, 3]))\n",
        "      \n",
        "  fires_quant = pd.concat([zeros, no_zeros])\n",
        "  fires_quant = fires_quant.drop(['area'], axis=1)\n",
        "  if(print_):\n",
        "    print(fires_quant)\n",
        "    print(fires_quant['size'].value_counts())\n",
        "  \n",
        "  # separate the labels from the feature set\n",
        "  X = fires_quant.iloc[:,:-1]\n",
        "  y = fires_quant.iloc[:,-1]\n",
        "  if(print_):\n",
        "    print(\"\\nseparated features from labels\")\n",
        "    print(X)\n",
        "    print(y)\n",
        "  \n",
        "  # partition into train, validate, test sets\n",
        "  X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=splits[0], random_state=0, shuffle=True, stratify=y)\n",
        "  X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, train_size=(splits[1] / (splits[1] + splits[2])), random_state=0, shuffle=True, stratify=y_temp)\n",
        "\n",
        "    # normalize data\n",
        "  scale_cols = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']\n",
        "\n",
        "  scaler = MinMaxScaler((0, 1)).fit(X_train[scale_cols])\n",
        "  X_train[scale_cols] = scaler.transform(X_train[scale_cols])\n",
        "  X_test[scale_cols] = scaler.transform(X_test[scale_cols])\n",
        "  X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
        "\n",
        "  if(print_):\n",
        "    print(\"\\npost normalization!\")\n",
        "    print(X_train)\n",
        "    print(y_train)\n",
        "\n",
        "  # account for underfitting\n",
        "  X_train, y_train = pipeline(X_train, y_train, 'size')\n",
        "  X_test, y_test = pipeline(X_test, y_test, 'size')\n",
        "  X_val, y_val = pipeline(X_val, y_val, 'size')\n",
        "\n",
        "  if(print_):\n",
        "    print(X_train)\n",
        "    print(y_train.sum(axis=0))\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test, X_val, y_val\n",
        "\n",
        "preprocess_data(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXGFzApWWEXd",
        "outputId": "f750b5df-e8d4-408e-a88f-c11408028403"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw from .csv\n",
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
            "0    7  5      3    5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00\n",
            "1    7  4     10    2  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00\n",
            "2    7  4     10    6  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00\n",
            "3    8  6      3    5  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00\n",
            "4    8  6      3    7  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...    ...\n",
            "512  4  3      8    7  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44\n",
            "513  2  4      8    7  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29\n",
            "514  7  4      8    7  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16\n",
            "515  1  4      8    6  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00\n",
            "516  6  3     11    2  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00\n",
            "\n",
            "[517 rows x 13 columns]\n",
            "     X  Y  month  day  FFMC    DMC     DC  ISI  temp  RH  wind  rain  size\n",
            "0    7  5      3    5  86.2   26.2   94.3  5.1   8.2  51   6.7   0.0     0\n",
            "1    7  4     10    2  90.6   35.4  669.1  6.7  18.0  33   0.9   0.0     0\n",
            "2    7  4     10    6  90.6   43.7  686.9  6.7  14.6  33   1.3   0.0     0\n",
            "3    8  6      3    5  91.7   33.3   77.5  9.0   8.3  97   4.0   0.2     0\n",
            "4    8  6      3    7  89.3   51.3  102.2  9.6  11.4  99   1.8   0.0     0\n",
            "..  .. ..    ...  ...   ...    ...    ...  ...   ...  ..   ...   ...   ...\n",
            "509  5  4      8    5  91.0  166.9  752.6  7.1  21.1  71   7.6   1.4     1\n",
            "510  6  5      8    5  91.0  166.9  752.6  7.1  18.2  62   5.4   0.0     1\n",
            "512  4  3      8    7  81.6   56.7  665.6  1.9  27.8  32   2.7   0.0     2\n",
            "513  2  4      8    7  81.6   56.7  665.6  1.9  21.9  71   5.8   0.0     3\n",
            "514  7  4      8    7  81.6   56.7  665.6  1.9  21.2  70   6.7   0.0     3\n",
            "\n",
            "[517 rows x 13 columns]\n",
            "0    247\n",
            "1     90\n",
            "2     90\n",
            "3     90\n",
            "Name: size, dtype: int64\n",
            "\n",
            "separated features from labels\n",
            "     X  Y  month  day  FFMC    DMC     DC  ISI  temp  RH  wind  rain\n",
            "0    7  5      3    5  86.2   26.2   94.3  5.1   8.2  51   6.7   0.0\n",
            "1    7  4     10    2  90.6   35.4  669.1  6.7  18.0  33   0.9   0.0\n",
            "2    7  4     10    6  90.6   43.7  686.9  6.7  14.6  33   1.3   0.0\n",
            "3    8  6      3    5  91.7   33.3   77.5  9.0   8.3  97   4.0   0.2\n",
            "4    8  6      3    7  89.3   51.3  102.2  9.6  11.4  99   1.8   0.0\n",
            "..  .. ..    ...  ...   ...    ...    ...  ...   ...  ..   ...   ...\n",
            "509  5  4      8    5  91.0  166.9  752.6  7.1  21.1  71   7.6   1.4\n",
            "510  6  5      8    5  91.0  166.9  752.6  7.1  18.2  62   5.4   0.0\n",
            "512  4  3      8    7  81.6   56.7  665.6  1.9  27.8  32   2.7   0.0\n",
            "513  2  4      8    7  81.6   56.7  665.6  1.9  21.9  71   5.8   0.0\n",
            "514  7  4      8    7  81.6   56.7  665.6  1.9  21.2  70   6.7   0.0\n",
            "\n",
            "[517 rows x 12 columns]\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "509    1\n",
            "510    1\n",
            "512    2\n",
            "513    3\n",
            "514    3\n",
            "Name: size, Length: 517, dtype: int64\n",
            "\n",
            "post normalization!\n",
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "110  4  4      3    5  0.776805  0.059190  0.057934  0.043088  0.380795   \n",
            "482  3  4      8    7  0.973742  0.442714  0.679254  0.245961  0.701987   \n",
            "93   8  6      8    7  0.897155  0.484597  0.696024  0.183124  0.529801   \n",
            "455  3  4      7    1  0.967177  0.545517  0.655917  0.292639  0.519868   \n",
            "164  8  5      9    7  0.859956  0.303219  0.816817  0.078995  0.516556   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "366  4  5      9    2  0.890591  0.449637  0.943122  0.217235  0.453642   \n",
            "147  8  3      9    2  0.743982  0.245760  0.778703  0.050269  0.728477   \n",
            "476  4  3      7    4  0.943107  0.286951  0.453970  0.170557  0.827815   \n",
            "60   2  2      3    7  0.851204  0.169263  0.110590  0.165171  0.307947   \n",
            "508  1  2      8    5  0.888403  0.569401  0.873343  0.120287  0.784768   \n",
            "\n",
            "           RH      wind  rain  \n",
            "110  0.317073  0.576471   0.0  \n",
            "482  0.280488  0.576471   0.0  \n",
            "93   0.317073  0.470588   0.0  \n",
            "455  0.378049  0.211765   0.0  \n",
            "164  0.609756  0.152941   0.0  \n",
            "..        ...       ...   ...  \n",
            "366  0.256098  0.529412   0.0  \n",
            "147  0.134146  0.317647   0.0  \n",
            "476  0.134146  0.047059   0.0  \n",
            "60   0.268293  0.576471   0.0  \n",
            "508  0.292683  0.317647   0.0  \n",
            "\n",
            "[310 rows x 12 columns]\n",
            "110    0\n",
            "482    1\n",
            "93     0\n",
            "455    0\n",
            "164    1\n",
            "      ..\n",
            "366    1\n",
            "147    1\n",
            "476    1\n",
            "60     0\n",
            "508    0\n",
            "Name: size, Length: 310, dtype: int64\n",
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    3  4      7    3  0.908096  0.454136  0.601149  0.136445  0.397351   \n",
            "1    4  4      3    5  0.776805  0.059190  0.057934  0.043088  0.380795   \n",
            "2    8  6      8    7  0.897155  0.484597  0.696024  0.183124  0.529801   \n",
            "3    3  4      9    7  0.919037  0.421253  0.789023  0.145422  0.672185   \n",
            "4    3  6      9    7  0.919037  0.421253  0.789023  0.145422  0.496689   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "181  9  4      6    6  0.877462  0.203184  0.286971  0.161580  0.738411   \n",
            "182  9  6      8    4  0.901532  0.851506  0.874751  0.105925  0.605960   \n",
            "183  1  3      8    5  0.995624  0.538595  0.733787  0.195691  0.837748   \n",
            "184  9  4      9    2  0.743982  0.245760  0.778703  0.050269  0.731788   \n",
            "185  1  4      8    3  0.903720  0.654206  0.736484  0.132855  0.586093   \n",
            "\n",
            "           RH      wind  rain  \n",
            "0    0.500000  0.364706   0.0  \n",
            "1    0.317073  0.576471   0.0  \n",
            "2    0.317073  0.470588   0.0  \n",
            "3    0.304878  0.529412   0.0  \n",
            "4    0.500000  0.047059   0.0  \n",
            "..        ...       ...   ...  \n",
            "181  0.402439  0.258824   0.0  \n",
            "182  0.500000  0.211765   0.0  \n",
            "183  0.146341  0.423529   0.0  \n",
            "184  0.231707  0.258824   0.0  \n",
            "185  0.402439  0.364706   0.0  \n",
            "\n",
            "[186 rows x 12 columns]\n",
            "size_0    59\n",
            "size_1    54\n",
            "size_2    38\n",
            "size_3    35\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
              " 0    3  4      7    3  0.908096  0.454136  0.601149  0.136445  0.397351   \n",
              " 1    4  4      3    5  0.776805  0.059190  0.057934  0.043088  0.380795   \n",
              " 2    8  6      8    7  0.897155  0.484597  0.696024  0.183124  0.529801   \n",
              " 3    3  4      9    7  0.919037  0.421253  0.789023  0.145422  0.672185   \n",
              " 4    3  6      9    7  0.919037  0.421253  0.789023  0.145422  0.496689   \n",
              " ..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
              " 181  9  4      6    6  0.877462  0.203184  0.286971  0.161580  0.738411   \n",
              " 182  9  6      8    4  0.901532  0.851506  0.874751  0.105925  0.605960   \n",
              " 183  1  3      8    5  0.995624  0.538595  0.733787  0.195691  0.837748   \n",
              " 184  9  4      9    2  0.743982  0.245760  0.778703  0.050269  0.731788   \n",
              " 185  1  4      8    3  0.903720  0.654206  0.736484  0.132855  0.586093   \n",
              " \n",
              "            RH      wind  rain  \n",
              " 0    0.500000  0.364706   0.0  \n",
              " 1    0.317073  0.576471   0.0  \n",
              " 2    0.317073  0.470588   0.0  \n",
              " 3    0.304878  0.529412   0.0  \n",
              " 4    0.500000  0.047059   0.0  \n",
              " ..        ...       ...   ...  \n",
              " 181  0.402439  0.258824   0.0  \n",
              " 182  0.500000  0.211765   0.0  \n",
              " 183  0.146341  0.423529   0.0  \n",
              " 184  0.231707  0.258824   0.0  \n",
              " 185  0.402439  0.364706   0.0  \n",
              " \n",
              " [186 rows x 12 columns],      size_0  size_1  size_2  size_3\n",
              " 0         1       0       0       0\n",
              " 1         1       0       0       0\n",
              " 2         1       0       0       0\n",
              " 3         1       0       0       0\n",
              " 4         1       0       0       0\n",
              " ..      ...     ...     ...     ...\n",
              " 181       0       0       0       1\n",
              " 182       0       0       0       1\n",
              " 183       0       0       0       1\n",
              " 184       0       0       0       1\n",
              " 185       0       0       0       1\n",
              " \n",
              " [186 rows x 4 columns],     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
              " 0   1  2      9    4  0.929978  0.465905  0.819163  0.157989  0.668874   \n",
              " 1   4  6      3    7  0.851204  0.169263  0.110590  0.165171  0.278146   \n",
              " 2   1  2      7    5  0.881838  0.271720  0.422657  0.294434  0.417219   \n",
              " 3   7  4      8    5  0.971554  0.777432  0.819514  0.208259  0.698675   \n",
              " 4   6  3      9    1  0.905908  0.263413  0.840155  0.157989  0.629139   \n",
              " .. .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
              " 58  6  4      9    2  0.888403  0.439945  0.802979  0.118492  0.546358   \n",
              " 59  8  6     12    3  0.735230  0.087920  0.406591  0.087971  0.096026   \n",
              " 60  8  4      8    6  0.901532  0.939425  0.951331  0.131059  0.632450   \n",
              " 61  2  2      9    6  0.921225  0.410869  0.781635  0.147217  0.529801   \n",
              " 62  4  4      9    7  0.919037  0.421253  0.789023  0.145422  0.486755   \n",
              " \n",
              "           RH      wind  rain  \n",
              " 0   0.207317  0.152941   0.0  \n",
              " 1   0.353659  0.470588   0.0  \n",
              " 2   0.743902  0.835294   0.0  \n",
              " 3   0.207317  0.258824   0.0  \n",
              " 4   0.182927  0.211765   0.0  \n",
              " ..       ...       ...   ...  \n",
              " 58  0.317073  0.211765   0.0  \n",
              " 59  0.536585  0.835294   0.0  \n",
              " 60  0.329268  0.423529   0.0  \n",
              " 61  0.353659  0.105882   0.0  \n",
              " 62  0.524390  0.047059   0.0  \n",
              " \n",
              " [63 rows x 12 columns],     size_0  size_1  size_2  size_3\n",
              " 0        1       0       0       0\n",
              " 1        1       0       0       0\n",
              " 2        1       0       0       0\n",
              " 3        1       0       0       0\n",
              " 4        1       0       0       0\n",
              " ..     ...     ...     ...     ...\n",
              " 58       0       0       0       1\n",
              " 59       0       0       0       1\n",
              " 60       0       0       0       1\n",
              " 61       0       0       0       1\n",
              " 62       0       0       0       1\n",
              " \n",
              " [63 rows x 4 columns],     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
              " 0   3  4      8    4  0.932166  0.252336  0.537938  0.131059  0.576159   \n",
              " 1   5  4      3    5  0.903720  0.106957  0.081623  0.154399  0.443709   \n",
              " 2   6  5      9    3  0.923414  0.391139  0.902076  0.150808  0.731788   \n",
              " 3   1  2      8    7  0.870897  0.336449  0.730972  0.105925  0.519868   \n",
              " 4   3  4      8    1  0.899344  0.494981  0.703999  0.184919  0.268212   \n",
              " .. .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
              " 60  3  4      9    7  0.877462  0.326411  0.870881  0.197487  0.609272   \n",
              " 61  8  6      9    5  0.890591  0.307719  0.856339  0.122083  0.612583   \n",
              " 62  1  3      9    7  0.888403  0.948079  0.958368  0.120287  0.652318   \n",
              " 63  6  5     12    2  0.765864  0.079612  0.400844  0.039497  0.096026   \n",
              " 64  6  5      4    4  0.680525  0.023191  0.055471  0.041293  0.119205   \n",
              " \n",
              "           RH      wind  rain  \n",
              " 0   0.231707  0.258824   0.0  \n",
              " 1   0.097561  0.635294   0.0  \n",
              " 2   0.121951  0.470588   0.0  \n",
              " 3   0.329268  0.152941   0.0  \n",
              " 4   0.695122  0.152941   0.0  \n",
              " ..       ...       ...   ...  \n",
              " 60  0.463415  0.529412   0.0  \n",
              " 61  0.353659  0.211765   0.0  \n",
              " 62  0.317073  0.364706   0.0  \n",
              " 63  0.085366  0.894118   0.0  \n",
              " 64  0.451220  0.576471   0.0  \n",
              " \n",
              " [65 rows x 12 columns],     size_0  size_1  size_2  size_3\n",
              " 0        1       0       0       0\n",
              " 1        1       0       0       0\n",
              " 2        1       0       0       0\n",
              " 3        1       0       0       0\n",
              " 4        1       0       0       0\n",
              " ..     ...     ...     ...     ...\n",
              " 60       0       0       0       1\n",
              " 61       0       0       0       1\n",
              " 62       0       0       0       1\n",
              " 63       0       0       0       1\n",
              " 64       0       0       0       1\n",
              " \n",
              " [65 rows x 4 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "svgckzvrYDhP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7rx1rzqy25o"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# hyperparameters\n",
        "\n",
        "# optimizer\n",
        "lr = 0.001\n",
        "\n",
        "# model creation\n",
        "num_hidden_layers = 2\n",
        "neurons_per_hidden_layer = 5\n",
        "\n",
        "# model trainin\n",
        "num_epochs = 1000\n",
        "batches = 1\n"
      ],
      "metadata": {
        "id": "nzrcaQTpH4qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import CondensedNearestNeighbour "
      ],
      "metadata": {
        "id": "amoLEWf0NCzc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/55119651/downsampling-for-more-than-2-classes\n",
        "# def downsample(X, y, label):\n",
        "#   data = pd.concat([X, y], axis=1)\n",
        "#   g = data.groupby(label, group_keys=False)\n",
        "#   balanced = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()))).reset_index(drop=True)\n",
        "#   return balanced.iloc[:, :-1], balanced.iloc[:, -1]\n",
        "\n",
        "\n",
        "batch_size = math.floor(X_train.shape[0] / batches)\n",
        "print(batch_size)"
      ],
      "metadata": {
        "id": "jlB1FP7kDRWI",
        "outputId": "b610ea93-d475-4fb9-8df0-f7fa54c4e42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain\n",
            "0    3  4      7    3  91.9  133.6  520.5   8.0  14.2  58   4.0   0.0\n",
            "1    4  4      3    5  85.9   19.5   57.3   2.8  13.7  43   5.8   0.0\n",
            "2    8  6      8    7  91.4  142.4  601.4  10.6  18.2  43   4.9   0.0\n",
            "3    3  4      9    7  92.4  124.1  680.7   8.5  22.5  42   5.4   0.0\n",
            "4    3  4      8    7  91.4  142.4  601.4  10.6  11.6  87   4.5   0.0\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...\n",
            "176  5  4      8    2  95.1  141.3  605.8  17.7  26.4  34   3.6   0.0\n",
            "177  9  4      6    6  90.5   61.1  252.6   9.4  24.5  50   3.1   0.0\n",
            "178  1  3      8    5  95.9  158.0  633.6  11.3  27.5  29   4.5   0.0\n",
            "179  9  4      9    2  84.4   73.4  671.9   3.2  24.3  36   3.1   0.0\n",
            "180  5  4      2    5  85.2    4.9   15.8   6.3   7.5  46   8.0   0.0\n",
            "\n",
            "[181 rows x 12 columns]\n",
            "size_0    60\n",
            "size_1    54\n",
            "size_2    34\n",
            "size_3    33\n",
            "dtype: int64\n",
            "     X  Y  month  day      FFMC       DMC        DC       ISI      temp  \\\n",
            "0    3  4      7    3  0.908096  0.453911  0.604255  0.136445  0.345324   \n",
            "1    4  4      3    5  0.776805  0.055517  0.056738  0.043088  0.327338   \n",
            "2    8  6      8    7  0.897155  0.484637  0.699882  0.183124  0.489209   \n",
            "3    3  4      9    7  0.919037  0.420740  0.793617  0.145422  0.643885   \n",
            "4    3  4      8    7  0.897155  0.484637  0.699882  0.183124  0.251799   \n",
            "..  .. ..    ...  ...       ...       ...       ...       ...       ...   \n",
            "176  5  4      8    2  0.978118  0.480796  0.705083  0.310592  0.784173   \n",
            "177  9  4      6    6  0.877462  0.200768  0.287589  0.161580  0.715827   \n",
            "178  1  3      8    5  0.995624  0.539106  0.737943  0.195691  0.823741   \n",
            "179  9  4      9    2  0.743982  0.243715  0.783215  0.050269  0.708633   \n",
            "180  5  4      2    5  0.761488  0.004539  0.007683  0.105925  0.104317   \n",
            "\n",
            "           RH      wind  rain  \n",
            "0    0.506329  0.364706   0.0  \n",
            "1    0.316456  0.576471   0.0  \n",
            "2    0.316456  0.470588   0.0  \n",
            "3    0.303797  0.529412   0.0  \n",
            "4    0.873418  0.423529   0.0  \n",
            "..        ...       ...   ...  \n",
            "176  0.202532  0.317647   0.0  \n",
            "177  0.405063  0.258824   0.0  \n",
            "178  0.139241  0.423529   0.0  \n",
            "179  0.227848  0.258824   0.0  \n",
            "180  0.354430  0.835294   0.0  \n",
            "\n",
            "[181 rows x 12 columns]\n",
            "     size_0  size_1  size_2  size_3\n",
            "0         1       0       0       0\n",
            "1         1       0       0       0\n",
            "2         1       0       0       0\n",
            "3         1       0       0       0\n",
            "4         1       0       0       0\n",
            "..      ...     ...     ...     ...\n",
            "176       0       0       0       1\n",
            "177       0       0       0       1\n",
            "178       0       0       0       1\n",
            "179       0       0       0       1\n",
            "180       0       0       0       1\n",
            "\n",
            "[181 rows x 4 columns]\n",
            "181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "47OG36GcDSHu",
        "outputId": "d460a3b8-278b-4671-96d9-ff55060845eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(181, 12)\n",
            "(60, 12)\n",
            "(63, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the model"
      ],
      "metadata": {
        "id": "ucjs_rHzc6PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define the keras model\n",
        "# N_input - neurons_per_hidden_layer - N_labels configuration, relu and sigmoid activation for the \n",
        "# hidden layer and output layer respectively\n",
        "\n",
        "def construct_dnn(neurons_per_hidden_layer, num_hidden_layers, lr):\n",
        "  input_dim = 12 # Is this correct?\n",
        "  num_classes = 4\n",
        "\n",
        "  net = tf.keras.models.Sequential()\n",
        "  net.add(tf.keras.layers.Dense(units=neurons_per_hidden_layer, input_dim=input_dim, activation = 'relu')) # input layer\n",
        "  for l in range(num_hidden_layers):\n",
        "    net.add(tf.keras.layers.Dense(units=neurons_per_hidden_layer, activation = 'relu')) # deep layer\n",
        "  net.add(tf.keras.layers.Dense(units=num_classes, activation='softmax')) # output layer\n",
        "\n",
        "  # compile the keras model\n",
        "  opt = tf.keras.optimizers.Adam(\n",
        "      learning_rate=lr\n",
        "  )\n",
        "\n",
        "  net.compile(loss='CategoricalCrossentropy', optimizer=opt, \n",
        "                metrics=['accuracy'])\n",
        "  return net"
      ],
      "metadata": {
        "id": "Cc9wmG7KDTox"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# hyperparemeters\n",
        "nhl = 2 # num_hidden_layers\n",
        "nphl = 5 # neurons_per_hidden_layer\n",
        "lr = 0.001\n",
        "epochs = 1000\n",
        "batches = 1\n",
        "\n",
        "batch_size = math.floor(X_train.shape[0] / batches)\n",
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = preprocess_data()\n",
        "# fit the keras model on the dataset\n",
        "net = construct_dnn(neurons_per_hidden_layer=5, num_hidden_layers=2, lr = lr)\n",
        "callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history = net.fit(X_train, y_train, epochs=epochs, verbose=1, batch_size=batch_size, \n",
        "                  validation_data=(X_val,y_val), callbacks=[callback])"
      ],
      "metadata": {
        "id": "UM01KzR6QF_3",
        "outputId": "2b9dafca-c86f-41a7-b8a9-dc1f6c159df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9582 - accuracy: 0.3172 - val_loss: 2.0003 - val_accuracy: 0.3385\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1.9312 - accuracy: 0.3172 - val_loss: 1.9718 - val_accuracy: 0.3385\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.9050 - accuracy: 0.3172 - val_loss: 1.9443 - val_accuracy: 0.3385\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.8798 - accuracy: 0.3172 - val_loss: 1.9181 - val_accuracy: 0.3385\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.8553 - accuracy: 0.3172 - val_loss: 1.8927 - val_accuracy: 0.3385\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.8317 - accuracy: 0.3172 - val_loss: 1.8685 - val_accuracy: 0.3385\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8091 - accuracy: 0.3172 - val_loss: 1.8452 - val_accuracy: 0.3385\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.7872 - accuracy: 0.3172 - val_loss: 1.8226 - val_accuracy: 0.3385\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.7661 - accuracy: 0.3172 - val_loss: 1.8009 - val_accuracy: 0.3385\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.7457 - accuracy: 0.3172 - val_loss: 1.7804 - val_accuracy: 0.3385\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.7261 - accuracy: 0.3172 - val_loss: 1.7606 - val_accuracy: 0.3385\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.7072 - accuracy: 0.3172 - val_loss: 1.7415 - val_accuracy: 0.3385\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.6892 - accuracy: 0.3172 - val_loss: 1.7239 - val_accuracy: 0.3385\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.6720 - accuracy: 0.3172 - val_loss: 1.7070 - val_accuracy: 0.3385\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.6557 - accuracy: 0.3172 - val_loss: 1.6908 - val_accuracy: 0.3385\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.6401 - accuracy: 0.3172 - val_loss: 1.6754 - val_accuracy: 0.3385\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.6253 - accuracy: 0.3172 - val_loss: 1.6615 - val_accuracy: 0.3385\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.6113 - accuracy: 0.3172 - val_loss: 1.6483 - val_accuracy: 0.3385\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.5981 - accuracy: 0.3172 - val_loss: 1.6358 - val_accuracy: 0.3385\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.5856 - accuracy: 0.3172 - val_loss: 1.6240 - val_accuracy: 0.3385\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.5739 - accuracy: 0.3172 - val_loss: 1.6127 - val_accuracy: 0.3385\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.5629 - accuracy: 0.3172 - val_loss: 1.6020 - val_accuracy: 0.3385\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.5525 - accuracy: 0.3172 - val_loss: 1.5923 - val_accuracy: 0.3385\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.5428 - accuracy: 0.3172 - val_loss: 1.5830 - val_accuracy: 0.3385\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.5336 - accuracy: 0.3172 - val_loss: 1.5743 - val_accuracy: 0.3385\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.5249 - accuracy: 0.3172 - val_loss: 1.5660 - val_accuracy: 0.3385\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.5166 - accuracy: 0.3172 - val_loss: 1.5583 - val_accuracy: 0.3385\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.5088 - accuracy: 0.3172 - val_loss: 1.5509 - val_accuracy: 0.3385\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.5014 - accuracy: 0.3172 - val_loss: 1.5439 - val_accuracy: 0.3385\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4946 - accuracy: 0.3172 - val_loss: 1.5373 - val_accuracy: 0.3385\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4881 - accuracy: 0.3172 - val_loss: 1.5310 - val_accuracy: 0.3231\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.4819 - accuracy: 0.3118 - val_loss: 1.5251 - val_accuracy: 0.3231\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4760 - accuracy: 0.3065 - val_loss: 1.5194 - val_accuracy: 0.3077\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4705 - accuracy: 0.3065 - val_loss: 1.5139 - val_accuracy: 0.3231\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4655 - accuracy: 0.2957 - val_loss: 1.5087 - val_accuracy: 0.3231\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4608 - accuracy: 0.3011 - val_loss: 1.5037 - val_accuracy: 0.3231\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4564 - accuracy: 0.3118 - val_loss: 1.4989 - val_accuracy: 0.3231\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4523 - accuracy: 0.2957 - val_loss: 1.4946 - val_accuracy: 0.3231\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4485 - accuracy: 0.2742 - val_loss: 1.4907 - val_accuracy: 0.3385\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4450 - accuracy: 0.2849 - val_loss: 1.4870 - val_accuracy: 0.2923\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4416 - accuracy: 0.2903 - val_loss: 1.4834 - val_accuracy: 0.3077\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.4383 - accuracy: 0.3065 - val_loss: 1.4799 - val_accuracy: 0.3077\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4352 - accuracy: 0.3011 - val_loss: 1.4765 - val_accuracy: 0.3077\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.4321 - accuracy: 0.3226 - val_loss: 1.4733 - val_accuracy: 0.3077\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4292 - accuracy: 0.3387 - val_loss: 1.4701 - val_accuracy: 0.3077\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4264 - accuracy: 0.3387 - val_loss: 1.4669 - val_accuracy: 0.3077\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.4237 - accuracy: 0.3333 - val_loss: 1.4638 - val_accuracy: 0.2923\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4213 - accuracy: 0.3387 - val_loss: 1.4608 - val_accuracy: 0.2923\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4190 - accuracy: 0.3333 - val_loss: 1.4580 - val_accuracy: 0.2923\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4168 - accuracy: 0.3226 - val_loss: 1.4552 - val_accuracy: 0.2923\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4147 - accuracy: 0.3226 - val_loss: 1.4524 - val_accuracy: 0.2769\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4126 - accuracy: 0.3118 - val_loss: 1.4498 - val_accuracy: 0.2769\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4106 - accuracy: 0.3118 - val_loss: 1.4473 - val_accuracy: 0.2769\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4087 - accuracy: 0.3065 - val_loss: 1.4448 - val_accuracy: 0.2769\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4069 - accuracy: 0.3011 - val_loss: 1.4424 - val_accuracy: 0.2615\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4052 - accuracy: 0.3011 - val_loss: 1.4402 - val_accuracy: 0.2769\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4035 - accuracy: 0.3011 - val_loss: 1.4380 - val_accuracy: 0.2769\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4018 - accuracy: 0.3065 - val_loss: 1.4360 - val_accuracy: 0.2769\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4002 - accuracy: 0.3065 - val_loss: 1.4340 - val_accuracy: 0.2923\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3986 - accuracy: 0.3011 - val_loss: 1.4322 - val_accuracy: 0.2923\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3971 - accuracy: 0.3065 - val_loss: 1.4305 - val_accuracy: 0.2769\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3957 - accuracy: 0.3118 - val_loss: 1.4289 - val_accuracy: 0.2769\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3944 - accuracy: 0.3172 - val_loss: 1.4274 - val_accuracy: 0.2769\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3931 - accuracy: 0.3172 - val_loss: 1.4259 - val_accuracy: 0.2769\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3918 - accuracy: 0.3172 - val_loss: 1.4244 - val_accuracy: 0.2769\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3906 - accuracy: 0.3226 - val_loss: 1.4230 - val_accuracy: 0.2769\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3895 - accuracy: 0.3226 - val_loss: 1.4217 - val_accuracy: 0.2769\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3885 - accuracy: 0.3387 - val_loss: 1.4203 - val_accuracy: 0.2769\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3875 - accuracy: 0.3333 - val_loss: 1.4190 - val_accuracy: 0.2769\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3865 - accuracy: 0.3333 - val_loss: 1.4179 - val_accuracy: 0.2769\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.3857 - accuracy: 0.3441 - val_loss: 1.4167 - val_accuracy: 0.2769\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3848 - accuracy: 0.3441 - val_loss: 1.4157 - val_accuracy: 0.2769\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3841 - accuracy: 0.3495 - val_loss: 1.4147 - val_accuracy: 0.2769\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3833 - accuracy: 0.3495 - val_loss: 1.4137 - val_accuracy: 0.2769\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3826 - accuracy: 0.3548 - val_loss: 1.4127 - val_accuracy: 0.2769\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3818 - accuracy: 0.3495 - val_loss: 1.4118 - val_accuracy: 0.2769\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3810 - accuracy: 0.3548 - val_loss: 1.4112 - val_accuracy: 0.2769\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3803 - accuracy: 0.3548 - val_loss: 1.4105 - val_accuracy: 0.2769\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3795 - accuracy: 0.3495 - val_loss: 1.4099 - val_accuracy: 0.3077\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3788 - accuracy: 0.3441 - val_loss: 1.4093 - val_accuracy: 0.3077\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3781 - accuracy: 0.3441 - val_loss: 1.4088 - val_accuracy: 0.3077\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3775 - accuracy: 0.3441 - val_loss: 1.4083 - val_accuracy: 0.2923\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3769 - accuracy: 0.3441 - val_loss: 1.4077 - val_accuracy: 0.2923\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3763 - accuracy: 0.3495 - val_loss: 1.4073 - val_accuracy: 0.2923\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3757 - accuracy: 0.3602 - val_loss: 1.4068 - val_accuracy: 0.3077\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3752 - accuracy: 0.3548 - val_loss: 1.4063 - val_accuracy: 0.3077\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3746 - accuracy: 0.3441 - val_loss: 1.4058 - val_accuracy: 0.3231\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3741 - accuracy: 0.3602 - val_loss: 1.4054 - val_accuracy: 0.2923\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3736 - accuracy: 0.3548 - val_loss: 1.4051 - val_accuracy: 0.2923\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3731 - accuracy: 0.3548 - val_loss: 1.4047 - val_accuracy: 0.3077\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3727 - accuracy: 0.3602 - val_loss: 1.4045 - val_accuracy: 0.3077\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3722 - accuracy: 0.3710 - val_loss: 1.4042 - val_accuracy: 0.3077\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3718 - accuracy: 0.3602 - val_loss: 1.4039 - val_accuracy: 0.3231\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3713 - accuracy: 0.3441 - val_loss: 1.4037 - val_accuracy: 0.3077\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3709 - accuracy: 0.3441 - val_loss: 1.4035 - val_accuracy: 0.2923\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3704 - accuracy: 0.3495 - val_loss: 1.4032 - val_accuracy: 0.2923\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3700 - accuracy: 0.3441 - val_loss: 1.4029 - val_accuracy: 0.3231\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3695 - accuracy: 0.3495 - val_loss: 1.4027 - val_accuracy: 0.3231\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3691 - accuracy: 0.3602 - val_loss: 1.4025 - val_accuracy: 0.3385\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3687 - accuracy: 0.3548 - val_loss: 1.4022 - val_accuracy: 0.3385\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3684 - accuracy: 0.3495 - val_loss: 1.4019 - val_accuracy: 0.3385\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3681 - accuracy: 0.3441 - val_loss: 1.4016 - val_accuracy: 0.3385\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3679 - accuracy: 0.3495 - val_loss: 1.4013 - val_accuracy: 0.3385\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3676 - accuracy: 0.3441 - val_loss: 1.4009 - val_accuracy: 0.3385\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3673 - accuracy: 0.3441 - val_loss: 1.4005 - val_accuracy: 0.3385\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3671 - accuracy: 0.3441 - val_loss: 1.4001 - val_accuracy: 0.3385\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3668 - accuracy: 0.3441 - val_loss: 1.3997 - val_accuracy: 0.3385\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3666 - accuracy: 0.3441 - val_loss: 1.3993 - val_accuracy: 0.3385\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3664 - accuracy: 0.3441 - val_loss: 1.3989 - val_accuracy: 0.3385\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3662 - accuracy: 0.3441 - val_loss: 1.3986 - val_accuracy: 0.3385\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3660 - accuracy: 0.3441 - val_loss: 1.3983 - val_accuracy: 0.3538\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3658 - accuracy: 0.3441 - val_loss: 1.3979 - val_accuracy: 0.3538\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3656 - accuracy: 0.3441 - val_loss: 1.3976 - val_accuracy: 0.3538\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3654 - accuracy: 0.3441 - val_loss: 1.3973 - val_accuracy: 0.3538\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3653 - accuracy: 0.3441 - val_loss: 1.3971 - val_accuracy: 0.3538\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3651 - accuracy: 0.3441 - val_loss: 1.3968 - val_accuracy: 0.3538\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3649 - accuracy: 0.3441 - val_loss: 1.3965 - val_accuracy: 0.3538\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3648 - accuracy: 0.3441 - val_loss: 1.3963 - val_accuracy: 0.3538\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3646 - accuracy: 0.3441 - val_loss: 1.3961 - val_accuracy: 0.3538\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3645 - accuracy: 0.3441 - val_loss: 1.3958 - val_accuracy: 0.3538\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3643 - accuracy: 0.3441 - val_loss: 1.3956 - val_accuracy: 0.3538\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.3642 - accuracy: 0.3441 - val_loss: 1.3954 - val_accuracy: 0.3538\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3641 - accuracy: 0.3441 - val_loss: 1.3952 - val_accuracy: 0.3538\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3639 - accuracy: 0.3441 - val_loss: 1.3950 - val_accuracy: 0.3538\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3638 - accuracy: 0.3441 - val_loss: 1.3948 - val_accuracy: 0.3538\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3636 - accuracy: 0.3441 - val_loss: 1.3946 - val_accuracy: 0.3538\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3635 - accuracy: 0.3495 - val_loss: 1.3944 - val_accuracy: 0.3538\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3634 - accuracy: 0.3495 - val_loss: 1.3943 - val_accuracy: 0.3538\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3633 - accuracy: 0.3495 - val_loss: 1.3941 - val_accuracy: 0.3538\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3631 - accuracy: 0.3495 - val_loss: 1.3940 - val_accuracy: 0.3538\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3630 - accuracy: 0.3495 - val_loss: 1.3939 - val_accuracy: 0.3538\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3629 - accuracy: 0.3495 - val_loss: 1.3938 - val_accuracy: 0.3538\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3628 - accuracy: 0.3495 - val_loss: 1.3937 - val_accuracy: 0.3538\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3626 - accuracy: 0.3495 - val_loss: 1.3936 - val_accuracy: 0.3538\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3625 - accuracy: 0.3441 - val_loss: 1.3935 - val_accuracy: 0.3538\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3624 - accuracy: 0.3441 - val_loss: 1.3934 - val_accuracy: 0.3538\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3623 - accuracy: 0.3441 - val_loss: 1.3933 - val_accuracy: 0.3538\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3622 - accuracy: 0.3441 - val_loss: 1.3932 - val_accuracy: 0.3538\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.3620 - accuracy: 0.3441 - val_loss: 1.3930 - val_accuracy: 0.3538\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3619 - accuracy: 0.3441 - val_loss: 1.3929 - val_accuracy: 0.3538\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3618 - accuracy: 0.3495 - val_loss: 1.3927 - val_accuracy: 0.3538\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3617 - accuracy: 0.3495 - val_loss: 1.3926 - val_accuracy: 0.3538\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3616 - accuracy: 0.3495 - val_loss: 1.3925 - val_accuracy: 0.3538\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3615 - accuracy: 0.3441 - val_loss: 1.3923 - val_accuracy: 0.3538\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3614 - accuracy: 0.3441 - val_loss: 1.3922 - val_accuracy: 0.3538\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3613 - accuracy: 0.3441 - val_loss: 1.3920 - val_accuracy: 0.3538\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.3612 - accuracy: 0.3441 - val_loss: 1.3919 - val_accuracy: 0.3538\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3611 - accuracy: 0.3441 - val_loss: 1.3918 - val_accuracy: 0.3538\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.3610 - accuracy: 0.3441 - val_loss: 1.3917 - val_accuracy: 0.3538\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3609 - accuracy: 0.3441 - val_loss: 1.3916 - val_accuracy: 0.3538\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3608 - accuracy: 0.3387 - val_loss: 1.3915 - val_accuracy: 0.3538\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3607 - accuracy: 0.3387 - val_loss: 1.3915 - val_accuracy: 0.3538\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3606 - accuracy: 0.3387 - val_loss: 1.3914 - val_accuracy: 0.3538\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3605 - accuracy: 0.3387 - val_loss: 1.3914 - val_accuracy: 0.3538\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3604 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3603 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3602 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3601 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3600 - accuracy: 0.3387 - val_loss: 1.3912 - val_accuracy: 0.3538\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3599 - accuracy: 0.3387 - val_loss: 1.3912 - val_accuracy: 0.3538\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3598 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3597 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3596 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3596 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3595 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3594 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.3593 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3592 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3591 - accuracy: 0.3387 - val_loss: 1.3913 - val_accuracy: 0.3538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can visualize the results with a confusion matrix.\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_confusion_matrix(y_classified, y_true, num_classes=4):\n",
        "  # Compute confusion matrix\n",
        "  c_mat = np.zeros((num_classes,num_classes))\n",
        "  for i in range(len(y_true)):\n",
        "    c_mat[y_classified[i], y_true[i] ] += 1\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in c_mat.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in c_mat.flatten()/np.sum(c_mat)]\n",
        "  labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  labels = np.asarray(labels).reshape(c_mat.shape[0], c_mat.shape[1])\n",
        "\n",
        "  plt.figure(figsize=(12,10))\n",
        "  sn.heatmap(c_mat, annot=labels, fmt='', cmap='rocket_r')\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.ylabel('Output Class')\n",
        "  plt.xlabel('Target Class')"
      ],
      "metadata": {
        "id": "O91LTNFgDXOn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints test loss, accuract; plots the confusion matrix of the net\n",
        "# returns score: (test loss, test accuracy)\n",
        "def evaluate_model(net):\n",
        "  # Evaluate the trained model using keras built-in function\n",
        "  score = net.evaluate(X_test, y_test, verbose=1)\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1]) \n",
        "\n",
        "  y_classified = np.argmax(net.predict(X_test), axis=1)\n",
        "  y_true = np.argmax(y_test.to_numpy(), axis=1)\n",
        "  # plot confusion matrix\n",
        "  plot_confusion_matrix(y_classified, y_true)\n",
        "  return score"
      ],
      "metadata": {
        "id": "01q6CPi0DYZd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bcvu_gzYDaex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}