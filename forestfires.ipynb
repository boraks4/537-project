{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestfires.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boraks4/539-project/blob/main/forestfires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credits to https://stackoverflow.com/a/57539179\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/boraks4/539-project.git'.format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "merjZ6yJcTtX",
        "outputId": "8358842b-937a-4a75-9772-0c49248dc5e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User name: TheAlexSannikov\n",
            "Password: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 539-project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dMW3uMDa4bW",
        "outputId": "a4785c44-b2f2-4c6e-9a39-ed6d07b26b37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/539-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "svgckzvrYDhP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = pd.read_csv('forestfires.csv', sep=',', header=0)\n",
        "# TODO: Is this the encoding we want for months, days?\n",
        "fires.month=fires.month.map({'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12})\n",
        "fires.day=fires.day.map({'mon':1,'tue':2,'wed':3,'thu':4,'fri':5,'sat':6,'sun':7}) \n",
        "print(fires)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Iaed6PPYT_R",
        "outputId": "d7412c1c-e4ea-44ff-cba5-67c94817f337"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
            "0    7  5      3    5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00\n",
            "1    7  4     10    2  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00\n",
            "2    7  4     10    6  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00\n",
            "3    8  6      3    5  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00\n",
            "4    8  6      3    7  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...    ...\n",
            "512  4  3      8    7  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44\n",
            "513  2  4      8    7  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29\n",
            "514  7  4      8    7  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16\n",
            "515  1  4      8    6  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00\n",
            "516  6  3     11    2  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00\n",
            "\n",
            "[517 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = []\n",
        "for a in fires['area']:\n",
        "  if a > 50:\n",
        "    label.append(3) # 'catastrophic'\n",
        "  elif a > 10: \n",
        "    label.append(2) # 'large'\n",
        "  elif a > 0:\n",
        "    label.append(1) # 'medium'\n",
        "  else:\n",
        "    label.append(0) # 'small'\n",
        "fires['classification'] = label\n",
        "fires = fires.drop(['area'], axis=1)\n",
        "pd.options.display.max_columns = len(fires.columns)\n",
        "pd.options.display.width = 100\n",
        "print(fires)"
      ],
      "metadata": {
        "id": "kopGlpGvv5kJ",
        "outputId": "cc7fc2ef-d341-45c6-814c-90e03d2c4730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  classification\n",
            "0    7  5      3    5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0               0\n",
            "1    7  4     10    2  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0               0\n",
            "2    7  4     10    6  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0               0\n",
            "3    8  6      3    5  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2               0\n",
            "4    8  6      3    7  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0               0\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...             ...\n",
            "512  4  3      8    7  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0               1\n",
            "513  2  4      8    7  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0               3\n",
            "514  7  4      8    7  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0               2\n",
            "515  1  4      8    6  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0               0\n",
            "516  6  3     11    2  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0               0\n",
            "\n",
            "[517 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paste in hw8 solution"
      ],
      "metadata": {
        "id": "S7v1o-A_BazT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7rx1rzqy25o"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = fires.iloc[:,:-1]\n",
        "print(X)\n",
        "y = label\n",
        "print(len(y))"
      ],
      "metadata": {
        "id": "KuYJ7JkDDMK6",
        "outputId": "b77489ab-ea78-4f30-9139-06977efea789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain\n",
            "0    7  5      3    5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0\n",
            "1    7  4     10    2  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0\n",
            "2    7  4     10    6  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0\n",
            "3    8  6      3    5  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2\n",
            "4    8  6      3    7  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...\n",
            "512  4  3      8    7  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0\n",
            "513  2  4      8    7  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0\n",
            "514  7  4      8    7  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0\n",
            "515  1  4      8    6  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0\n",
            "516  6  3     11    2  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0\n",
            "\n",
            "[517 rows x 12 columns]\n",
            "517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "unnecessary, already one-hot starting with 0\n",
        "cats = np.unique(y)\n",
        "# reformmat y label so starts at 0 for one-hot encoding\n",
        "y = y - cats[0]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "W47hS7daDQId",
        "outputId": "43de6622-9d55-49bf-9576-2f0dd1dce669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nunnecessary, already one-hot starting with 0\\ncats = np.unique(y)\\n# reformmat y label so starts at 0 for one-hot encoding\\ny = y - cats[0]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# hyperparameters\n",
        "\n",
        "# splitting data\n",
        "splits = (.6,.2,.2) # train, test, validatate at 60/20/20 division\n",
        "rand_state = 0\n",
        "\n",
        "# model creation\n",
        "num_hidden_layers = 1\n",
        "neurons_per_hidden_layer = 4\n",
        "\n",
        "# model trainin\n",
        "num_epochs = 100\n",
        "batch_size = math.floor(X_train.shape[0] / 10)\n",
        "print(batch_size)"
      ],
      "metadata": {
        "id": "nzrcaQTpH4qv",
        "outputId": "bd8ec7ed-1ec1-42cd-a11a-5c2e1cfe35da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make one-hot\n",
        "y_oh = keras.utils.to_categorical(y) \n",
        "\n",
        "# partition into train, validate, test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y_oh, train_size=splits[0], random_state=rand_state, shuffle=True, stratify=y_oh)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, train_size=(splits[1] / (splits[1] + splits[2])), random_state=rand_state, shuffle=True, stratify=y_temp)\n",
        "print(X_train)"
      ],
      "metadata": {
        "id": "jlB1FP7kDRWI",
        "outputId": "0633bd8e-1cce-48c3-9dd6-ac89602ce600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     X  Y  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain\n",
            "396  4  3      9    7  90.5   96.7  750.5  11.4  20.4  55   4.9   0.0\n",
            "465  2  2      2    6  79.5    3.6   15.3   1.8   4.6  59   0.9   0.0\n",
            "347  5  4      9    5  92.1   99.0  745.3   9.6  10.1  75   3.6   0.0\n",
            "163  8  6      9    6  92.5  121.1  674.4   8.6  17.8  56   1.8   0.0\n",
            "1    7  4     10    2  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0\n",
            "..  .. ..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...\n",
            "339  2  4      9    1  91.6  108.4  764.0   6.2  20.4  41   1.8   0.0\n",
            "340  2  5      9    1  91.6  108.4  764.0   6.2  19.3  44   2.2   0.0\n",
            "378  6  5      3    4  90.9   18.9   30.6   8.0   8.7  51   5.8   0.0\n",
            "15   6  5      9    5  93.3  141.2  713.9  13.9  22.9  44   5.4   0.0\n",
            "46   5  6      9    1  90.9  126.5  686.5   7.0  14.7  70   3.6   0.0\n",
            "\n",
            "[310 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "47OG36GcDSHu",
        "outputId": "f4babf17-6f2b-4509-a1de-cb55327a92b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(310, 12)\n",
            "(104, 12)\n",
            "(103, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Preprocessing - normaization?"
      ],
      "metadata": {
        "id": "00mPJfUPRYUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X.shape[1]\n",
        "num_classes = 4\n",
        "# define the keras model\n",
        "# N_input - neurons_per_hidden_layer - N_labels configuration, relu and sigmoid activation for the \n",
        "# hidden layer and output layer respectively\n",
        "\n",
        "#TODO: dynamic number of layers :)\n",
        "net = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=neurons_per_hidden_layer, input_dim=input_dim, activation = 'relu'), # input layer\n",
        "     tf.keras.layers.Dense(units=neurons_per_hidden_layer, activation = 'relu'), # deep layer\n",
        "    tf.keras.layers.Dense(units=num_classes, activation='softmax') # output layer\n",
        "    ])"
      ],
      "metadata": {
        "id": "Cc9wmG7KDTox"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the keras model\n",
        "net.compile(loss='CategoricalCrossentropy', optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QPzedSr2DUmS"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the keras model on the dataset\n",
        "history = net.fit(X_train, y_train, epochs=num_epochs, verbose=1, batch_size=batch_size, validation_data=(X_val,y_val))"
      ],
      "metadata": {
        "id": "UM01KzR6QF_3",
        "outputId": "0fbdb65d-154b-41e5-c632-fecbf8e7f5d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 26ms/step - loss: 6.1901 - accuracy: 0.3581 - val_loss: 4.8200 - val_accuracy: 0.3654\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6151 - accuracy: 0.3742 - val_loss: 3.6054 - val_accuracy: 0.3942\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.4051 - accuracy: 0.3419 - val_loss: 2.7419 - val_accuracy: 0.3654\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6416 - accuracy: 0.3903 - val_loss: 2.1752 - val_accuracy: 0.3462\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1959 - accuracy: 0.3774 - val_loss: 1.8537 - val_accuracy: 0.3462\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9275 - accuracy: 0.3742 - val_loss: 1.6726 - val_accuracy: 0.3846\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7591 - accuracy: 0.3613 - val_loss: 1.5863 - val_accuracy: 0.4038\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6557 - accuracy: 0.3774 - val_loss: 1.5349 - val_accuracy: 0.3942\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5918 - accuracy: 0.3968 - val_loss: 1.5018 - val_accuracy: 0.3846\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5445 - accuracy: 0.4097 - val_loss: 1.4777 - val_accuracy: 0.3750\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5166 - accuracy: 0.4129 - val_loss: 1.4545 - val_accuracy: 0.3750\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4904 - accuracy: 0.4161 - val_loss: 1.4340 - val_accuracy: 0.3750\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4678 - accuracy: 0.4194 - val_loss: 1.4167 - val_accuracy: 0.4038\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4496 - accuracy: 0.4194 - val_loss: 1.4031 - val_accuracy: 0.3942\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4298 - accuracy: 0.4194 - val_loss: 1.3911 - val_accuracy: 0.3942\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4125 - accuracy: 0.4194 - val_loss: 1.3796 - val_accuracy: 0.3942\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3978 - accuracy: 0.4161 - val_loss: 1.3677 - val_accuracy: 0.3942\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3824 - accuracy: 0.4194 - val_loss: 1.3556 - val_accuracy: 0.3942\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3685 - accuracy: 0.4161 - val_loss: 1.3447 - val_accuracy: 0.3942\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3568 - accuracy: 0.4194 - val_loss: 1.3348 - val_accuracy: 0.4231\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3460 - accuracy: 0.4226 - val_loss: 1.3263 - val_accuracy: 0.4231\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3371 - accuracy: 0.4290 - val_loss: 1.3194 - val_accuracy: 0.4135\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3286 - accuracy: 0.4290 - val_loss: 1.3132 - val_accuracy: 0.4231\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3205 - accuracy: 0.4290 - val_loss: 1.3075 - val_accuracy: 0.4327\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3139 - accuracy: 0.4323 - val_loss: 1.3022 - val_accuracy: 0.4327\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3079 - accuracy: 0.4419 - val_loss: 1.2976 - val_accuracy: 0.4327\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3015 - accuracy: 0.4452 - val_loss: 1.2930 - val_accuracy: 0.4327\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2965 - accuracy: 0.4484 - val_loss: 1.2885 - val_accuracy: 0.4423\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2911 - accuracy: 0.4548 - val_loss: 1.2843 - val_accuracy: 0.4423\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2865 - accuracy: 0.4516 - val_loss: 1.2799 - val_accuracy: 0.4423\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2822 - accuracy: 0.4516 - val_loss: 1.2758 - val_accuracy: 0.4423\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2780 - accuracy: 0.4581 - val_loss: 1.2721 - val_accuracy: 0.4423\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2739 - accuracy: 0.4581 - val_loss: 1.2686 - val_accuracy: 0.4423\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2701 - accuracy: 0.4613 - val_loss: 1.2653 - val_accuracy: 0.4519\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2664 - accuracy: 0.4613 - val_loss: 1.2619 - val_accuracy: 0.4519\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2626 - accuracy: 0.4645 - val_loss: 1.2588 - val_accuracy: 0.4519\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2591 - accuracy: 0.4645 - val_loss: 1.2556 - val_accuracy: 0.4519\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2556 - accuracy: 0.4645 - val_loss: 1.2527 - val_accuracy: 0.4519\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2525 - accuracy: 0.4613 - val_loss: 1.2498 - val_accuracy: 0.4519\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2496 - accuracy: 0.4645 - val_loss: 1.2469 - val_accuracy: 0.4519\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2464 - accuracy: 0.4645 - val_loss: 1.2443 - val_accuracy: 0.4519\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2433 - accuracy: 0.4645 - val_loss: 1.2418 - val_accuracy: 0.4519\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2408 - accuracy: 0.4645 - val_loss: 1.2391 - val_accuracy: 0.4519\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2378 - accuracy: 0.4677 - val_loss: 1.2367 - val_accuracy: 0.4519\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2353 - accuracy: 0.4677 - val_loss: 1.2343 - val_accuracy: 0.4519\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2328 - accuracy: 0.4677 - val_loss: 1.2319 - val_accuracy: 0.4519\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2302 - accuracy: 0.4645 - val_loss: 1.2296 - val_accuracy: 0.4519\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2281 - accuracy: 0.4645 - val_loss: 1.2273 - val_accuracy: 0.4519\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2254 - accuracy: 0.4645 - val_loss: 1.2251 - val_accuracy: 0.4519\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2232 - accuracy: 0.4677 - val_loss: 1.2229 - val_accuracy: 0.4519\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2210 - accuracy: 0.4677 - val_loss: 1.2209 - val_accuracy: 0.4519\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2189 - accuracy: 0.4677 - val_loss: 1.2189 - val_accuracy: 0.4519\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2167 - accuracy: 0.4677 - val_loss: 1.2168 - val_accuracy: 0.4519\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2148 - accuracy: 0.4677 - val_loss: 1.2149 - val_accuracy: 0.4519\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2127 - accuracy: 0.4677 - val_loss: 1.2131 - val_accuracy: 0.4519\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2108 - accuracy: 0.4710 - val_loss: 1.2111 - val_accuracy: 0.4519\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2091 - accuracy: 0.4677 - val_loss: 1.2093 - val_accuracy: 0.4519\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2071 - accuracy: 0.4677 - val_loss: 1.2077 - val_accuracy: 0.4519\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2054 - accuracy: 0.4677 - val_loss: 1.2060 - val_accuracy: 0.4519\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2037 - accuracy: 0.4677 - val_loss: 1.2044 - val_accuracy: 0.4615\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2021 - accuracy: 0.4677 - val_loss: 1.2026 - val_accuracy: 0.4615\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2004 - accuracy: 0.4677 - val_loss: 1.2012 - val_accuracy: 0.4615\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1990 - accuracy: 0.4677 - val_loss: 1.1995 - val_accuracy: 0.4615\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1973 - accuracy: 0.4677 - val_loss: 1.1981 - val_accuracy: 0.4712\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1959 - accuracy: 0.4677 - val_loss: 1.1965 - val_accuracy: 0.4808\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1943 - accuracy: 0.4677 - val_loss: 1.1951 - val_accuracy: 0.4808\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1930 - accuracy: 0.4645 - val_loss: 1.1938 - val_accuracy: 0.4808\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1917 - accuracy: 0.4645 - val_loss: 1.1925 - val_accuracy: 0.4808\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1904 - accuracy: 0.4613 - val_loss: 1.1913 - val_accuracy: 0.4808\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1890 - accuracy: 0.4645 - val_loss: 1.1899 - val_accuracy: 0.4808\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1877 - accuracy: 0.4645 - val_loss: 1.1886 - val_accuracy: 0.4808\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1866 - accuracy: 0.4645 - val_loss: 1.1874 - val_accuracy: 0.4808\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1853 - accuracy: 0.4645 - val_loss: 1.1863 - val_accuracy: 0.4808\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1842 - accuracy: 0.4645 - val_loss: 1.1851 - val_accuracy: 0.4808\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1830 - accuracy: 0.4645 - val_loss: 1.1841 - val_accuracy: 0.4808\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1819 - accuracy: 0.4645 - val_loss: 1.1831 - val_accuracy: 0.4808\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1809 - accuracy: 0.4677 - val_loss: 1.1819 - val_accuracy: 0.4808\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1797 - accuracy: 0.4613 - val_loss: 1.1809 - val_accuracy: 0.4808\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1787 - accuracy: 0.4645 - val_loss: 1.1799 - val_accuracy: 0.4808\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1777 - accuracy: 0.4645 - val_loss: 1.1788 - val_accuracy: 0.4808\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1768 - accuracy: 0.4645 - val_loss: 1.1778 - val_accuracy: 0.4808\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1758 - accuracy: 0.4645 - val_loss: 1.1769 - val_accuracy: 0.4808\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1749 - accuracy: 0.4645 - val_loss: 1.1760 - val_accuracy: 0.4808\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1740 - accuracy: 0.4645 - val_loss: 1.1751 - val_accuracy: 0.4808\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1730 - accuracy: 0.4645 - val_loss: 1.1743 - val_accuracy: 0.4808\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1722 - accuracy: 0.4645 - val_loss: 1.1734 - val_accuracy: 0.4808\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1714 - accuracy: 0.4645 - val_loss: 1.1726 - val_accuracy: 0.4808\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1705 - accuracy: 0.4677 - val_loss: 1.1718 - val_accuracy: 0.4808\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1697 - accuracy: 0.4677 - val_loss: 1.1709 - val_accuracy: 0.4808\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1689 - accuracy: 0.4677 - val_loss: 1.1701 - val_accuracy: 0.4808\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1681 - accuracy: 0.4710 - val_loss: 1.1694 - val_accuracy: 0.4808\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1674 - accuracy: 0.4742 - val_loss: 1.1686 - val_accuracy: 0.4808\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1667 - accuracy: 0.4710 - val_loss: 1.1678 - val_accuracy: 0.4808\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1660 - accuracy: 0.4742 - val_loss: 1.1672 - val_accuracy: 0.4808\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1652 - accuracy: 0.4742 - val_loss: 1.1665 - val_accuracy: 0.4712\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1645 - accuracy: 0.4742 - val_loss: 1.1658 - val_accuracy: 0.4712\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1639 - accuracy: 0.4742 - val_loss: 1.1652 - val_accuracy: 0.4712\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1633 - accuracy: 0.4742 - val_loss: 1.1645 - val_accuracy: 0.4712\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1626 - accuracy: 0.4742 - val_loss: 1.1638 - val_accuracy: 0.4712\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1621 - accuracy: 0.4742 - val_loss: 1.1632 - val_accuracy: 0.4712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can visualize the results with a confusion matrix.\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_confusion_matrix(y_classified, y_true):\n",
        "  # Compute confusion matrix\n",
        "  c_mat = np.zeros((num_classes,num_classes))\n",
        "  for i in range(len(y_true)):\n",
        "    c_mat[y_classified[i], y_true[i] ] += 1\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in c_mat.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in c_mat.flatten()/np.sum(c_mat)]\n",
        "  labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  labels = np.asarray(labels).reshape(c_mat.shape[0], c_mat.shape[1])\n",
        "\n",
        "  plt.figure(figsize=(12,10))\n",
        "  sn.heatmap(c_mat, annot=labels, fmt='', cmap='rocket_r')\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.ylabel('Output Class')\n",
        "  plt.xlabel('Target Class')"
      ],
      "metadata": {
        "id": "O91LTNFgDXOn"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the trained model using keras built-in function\n",
        "score = net.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1]) \n",
        "\n",
        "y_classified = np.argmax(net.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "# plot confusion matrix\n",
        "plot_confusion_matrix(y_classified, y_true)"
      ],
      "metadata": {
        "id": "01q6CPi0DYZd",
        "outputId": "a26f5dcf-095b-4e56-8cba-d28ff6e4c16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1651 - accuracy: 0.4660\n",
            "Test loss: 1.1650930643081665\n",
            "Test accuracy: 0.4660194218158722\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bcvu_gzYDaex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}